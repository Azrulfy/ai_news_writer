{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feedparser and beautifulsoup4 - A learning notebook\n",
    "The purpose of this notebook is to allow me to learn how to use the `feedparser` and `BeautifulSoup4` modules. Currently, my plan is to use this module to collect all of my AI related news feeds so in my `ai_news_writer` application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_news_feeds = [\n",
    "    {\"name\": \"AI Trends\", \"url\": \"https://www.aitrends.com/feed/\"},\n",
    "#     {\"name\": \"Science Daily\", \"url\": \"https://www.sciencedaily.com/rss/computers_math/artificial_intelligence.xml\"},\n",
    "    {\"name\": \"MIT News - Artificial Intelligence\", \"url\": \"http://news.mit.edu/rss/topic/artificial-intelligence2\"},\n",
    "    {\"name\": \"reddit artificial\", \"url\": \"https://www.reddit.com/r/artificial/.rss\"},\n",
    "    {\"name\": \"Chatbots Magazine - Medium\", \"url\": \"https://chatbotsmagazine.com/feed\"},\n",
    "    {\"name\": \"Towards Data Science - Medium\", \"url\": \"https://towardsdatascience.com/feed\"},\n",
    "    {\"name\": \"Chatbots Life - Medium\", \"url\": \"https://chatbotslife.com/feed\"},\n",
    "    {\"name\": \"AWS Machine Learning Blog\", \"url\": \"https://aws.amazon.com/blogs/machine-learning/feed/\"},\n",
    "    {\"name\": \"Artificial Intelligence - IBM Developer\",\n",
    "     \"url\": \"https://developer.ibm.com/patterns/category/artificial-intelligence/feed/\"},\n",
    "    {\"name\": \"Lex Fridman - Artificial Intelligence (AI)\", \"url\": \"https://lexfridman.com/category/ai/feed/\"},\n",
    "    {\"name\": \"reddit singularity\", \"url\": \"https://www.reddit.com/r/singularity/.rss?format=xml\"},\n",
    "    {\"name\": \"Archie.AI - Medium\", \"url\": \"https://medium.com/feed/archieai\"},\n",
    "    {\"name\": \"The Official NVIDIA Blog\", \"url\": \"http://feeds.feedburner.com/nvidiablog\"},\n",
    "    {\"name\": \"OpenAI Blog\", \"url\": \"https://openai.com/blog/rss/\"},\n",
    "    {\"name\": \"VentureBeat\", \"url\": \"http://feeds.feedburner.com/venturebeat/SZYF?format=xml\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feedparser and RSS feeds in general\n",
    "\n",
    "I've not worked with RSS feeds before, so once again, this is a learning opportunity...\n",
    "\n",
    "Currently, we're taking a look at the `feedparser` module and we're going to try and figure out how this works. It seems that there are two formats we'll have to contend with and those are **RSS** and **ATOM**. It does appear that both of these formats are mixed in the sources defined above. We'll need to take a look at each source and try to figure out if we can determine its type in the payload somehow, but we're getting a little ahead of ourselves...\n",
    "\n",
    "Let's import `feedparser` and get started. We'll also need to use the `requests` module to actually download the feeds and save the `xml` files so we can work locally.\n",
    "\n",
    "In order to get around an issue I ran into with reddit, I'm going to add an import to `time` so I can put a sleep statement in place in-between all of our calls. This should get around the issue with being flagged as a *bot* as mentioned below (Yes, I'm reconning this document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got our import, let's:\n",
    "* loop through the defined collection\n",
    "* call `requests.get` to grab each of the feeds\n",
    "* create a new file based on the source of the feed\n",
    "* save the contents of the feed to a file\n",
    "* sleep for a few seconds before moving to the next item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feed_source in ai_news_feeds:\n",
    "    feed = requests.get(feed_source['url'])\n",
    "    \n",
    "    with open(f\"data/{feed_source['name']}.xml\", \"wb+\") as file:\n",
    "        file.write(feed.content)\n",
    "        file.close()\n",
    "    \n",
    "    # Going to sleep for 3 seconds between calls just to be safe\n",
    "    time.sleep(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the feeds in each of the files\n",
    "\n",
    "Now that we've captured our feeds, we need to try and figure out their contents. As I mentioned before, it seems like we're going to have to deal with **RSS** and **ATOM** feed formats, so I guess the first thing we should do is try to figure that out based on the contents of the file.\n",
    "\n",
    "I *believe* we have both file formats in the first two list items (*AI Trends* and *Science Daily*). Based on my previous tests, *AI Trends* seems to work perfectly with `feedparser` and it has `content`, but the one from *Science Daily* does not have `content` items and throws an exception when iterating through its collection of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_trends = feedparser.parse('data/AI Trends.xml')\n",
    "archie_ai = feedparser.parse('data/Archie.AI - Medium.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notes and Important Information**: It appears I was wrong about *Science Daily* and I'm not getting anything back from them (so I changed this \"experiment\" to use Archie.AI instead). It could be because I am a *bot* and they've cut me off. I will try again at a later date. I also got an error from *r/artificial* because they flagged me as a bot and I had too many requests. I'll need to work through that as well. Fun stuff we'll have to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feed': {'title': 'AI Trends',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'AI Trends'},\n",
       "  'links': [{'href': 'https://www.aitrends.com/feed/',\n",
       "    'rel': 'self',\n",
       "    'type': 'application/rss+xml'},\n",
       "   {'rel': 'alternate',\n",
       "    'type': 'text/html',\n",
       "    'href': 'https://www.aitrends.com'}],\n",
       "  'link': 'https://www.aitrends.com',\n",
       "  'subtitle': 'The Business and Technology of Enterprise AI',\n",
       "  'subtitle_detail': {'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'The Business and Technology of Enterprise AI'},\n",
       "  'updated': 'Fri, 18 Oct 2019 11:03:27 +0000',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=11, tm_min=3, tm_sec=27, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "  'language': 'en',\n",
       "  'sy_updateperiod': 'hourly',\n",
       "  'sy_updatefrequency': '1',\n",
       "  'generator_detail': {'name': 'https://wordpress.org/?v=4.9.8'},\n",
       "  'generator': 'https://wordpress.org/?v=4.9.8'},\n",
       " 'entries': [{'title': 'Data Privacy Clashing with Demand for Data to Power AI Applications',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Data Privacy Clashing with Demand for Data to Power AI Applications'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/data-privacy-and-security/data-privacy-clashing-with-demand-for-data-to-power-ai-applications/'}],\n",
       "   'link': 'https://www.aitrends.com/data-privacy-and-security/data-privacy-clashing-with-demand-for-data-to-power-ai-applications/',\n",
       "   'published': 'Thu, 17 Oct 2019 21:30:40 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=21, tm_min=30, tm_sec=40, tm_wday=3, tm_yday=290, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'Data Privacy and Security',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Ethics and Social Issues', 'scheme': None, 'label': None},\n",
       "    {'term': 'Machine Learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'ai in business', 'scheme': None, 'label': None},\n",
       "    {'term': 'data security and privacy', 'scheme': None, 'label': None},\n",
       "    {'term': 'ethics and social issues', 'scheme': None, 'label': None},\n",
       "    {'term': 'machine learning', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18136',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff Your data has value, but unlocking it for your own benefit is challenging. Understanding how valuable data are collected and approved for use can help you to get there. Two primary means for differentiating audiences by their data collection methods are site-authenticated data collection and people-based data collection, suggested a recent [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff Your data has value, but unlocking it for your own benefit is challenging. Understanding how valuable data are collected and approved for use can help you to get there. Two primary means for differentiating audiences by their data collection methods are site-authenticated data collection and people-based data collection, suggested a recent [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By AI Trends Staff</em></p>\\n<p>Your data has value, but unlocking it for your own benefit is challenging. Understanding how valuable data are collected and approved for use can help you to get there.</p>\\n<p>Two primary means for differentiating audiences by their data collection methods are site-authenticated data collection and people-based data collection, suggested a recent piece in <a href=\"https://www.bulletinhealthcare.com/yes-data-is-the-new-oil/\">BulletinHealthcare</a> written by Justin Fadgen, chief corporate development officer for the firm.</p>\\n<p>Site-authenticated data are sourced from individual authentication events, such as when a user completes an online form, and generally agrees to a privacy policy that includes a data use agreement. User data are then be combined with other data sources that add meaning, becoming the basis of advertising targeting for instance. In marketing for healthcare, this is the National Provider Identifier (NPI), a 10-digit numeric identifier for covered healthcare providers under HIPAA.</p>\\n<p>People-based data collection does not come from a registration, but from a variety of sources that could include data licensing, research, and manual verification. These data can be loaded onto a data management platform, which aggregates data from various sources into likely groups using data science. The goal is to provide an anonymized ID to individual users. These then can be individually targeted.</p>\\n<p>People-based data may not be friendly to individual-level reporting, also called physician-level reporting. This is because no privacy policy has stipulated how the data are to be used.</p>\\n<p><strong>National Health Service of England Seeking to Monetize Data</strong></p>\\n<p>Efforts to monetize patient data of the National Health Service (NHS) of England further emphasizes the value of your data. Sensyne Health, a for-profit company, is working to get divisions of the NHS to put patient information into a database. The NHS has 71 years of patient data. In recent years, it has worked to collect patient DNA data for research.</p>\\n<p>Sensyne’s initial goal, according to an account from <a href=\"https://www.bloomberg.com/news/articles/2019-07-18/a-former-science-minister-wants-to-fund-the-nhs-by-selling-patient-data\">Bloomberg</a>, is to gather information on five million NHS patients. Ultimately, said Paul Drayson, the former UK science minister who founded Sensyne, the company hopes to get access to all 55 million members of NHS. EY consultants estimate those data might be worth $12 billion annually, money NHS could apply to patient care and health. Sensyne has so far signed up six of 150 hospital divisions in the NHS. Each division, or trust, receives Sensyne shares worth some $3 million.</p>\\n<p>The potential value is of interest to the UK government, especially with Brexit injecting more uncertainty into the economy. “How the NHS works with the global life sciences industry is key to the health of the nation,” Drayson stated.</p>\\n<p>Other groups are looking data as a business model. Intermountain Healthcare of Salt Lake City recently announced a partnership with Amgen to study the genomes of half a million patients. Israel is working on commercializing its patient health records in a $300 million program. Nebula Genomics is among companies who broker individual patient DNA data to buyers in the health industry.</p>\\n<p><strong>GDPR in European Union Enhances Individual Privacy Protection</strong></p>\\n<p>New privacy laws in Europe increase protections on patient information. According to polls, UK residents are willing to share data if it is invested back into healthcare, but they worry it will get into the wrong hands. Any citizen has the right to block sales of her or her data.</p>\\n<p>The General Data Protection Regulation (GDPR) that went into effect in the European Union in May 2018 specified some rules around data permissions. Customers must now confirm that they want to be contacted, according to an account in <a href=\"https://www.superoffice.com/blog/gdpr-marketing/\">SuperOffice</a>. A default checkbox that automatically opts a customer in will not comply; opt-in needs to be a deliberate choice. SuperOffice has modified its web forms as a result.</p>\\n<p>The GDPR says the customer has the “right to be forgotten,” to have outdated or inaccurate information removed. This gives individuals a way to gain more control over how their data are collected and used. This can be implemented with an unsubscribe link in email messages, and links to customer profiles that allow users to manage their email preferences.</p>\\n<p>Fines for violation of GDPR privacy rules can be hefty, including $90,000 to a company that sent email to 3.3 million customers that had opted out of its lists.</p>\\n<p>As companies pursuing AI and machine learning solutions race to get the data needed to make their applications work, we can see some challenging moments.</p>\\n<p><strong>Contribute Your Face to Google Database, Earn $5</strong></p>\\n<p>For instance, seeking to ensure its facial recognition image database is more diverse, Google recently began offering black homeless people in Atlanta $5 vouchers to submit their faces to the database, according to an account in <a href=\"https://www.theregister.co.uk/2019/10/06/ai_roundup_041019/\">TheRegister</a>.</p>\\n<p>With images of white men dominating its database, Google hired contractors to offer vouchers to people to record their faces. The temporary agency Randstad was told to target people with darker skin. Some were homeless living on the streets in Atlanta. Participants may not have been explicitly told what their images would be used for. When the word got out, it did not go over well in some circles. Atlanta City Attorney Nina Hickson wrote a letter to Google’s chief legal officer Kent Walker, asking the company to explain why the company was targeting “vulnerable populations” in Atlanta. The project was suspended. Google wanted to use the dataset to train a facial biometric system that can unlock its upcoming Pixel 4 smartphone.</p>\\n<p>See the source posts in <a href=\"https://www.bulletinhealthcare.com/yes-data-is-the-new-oil/\">BulletinHealthcare</a>, <a href=\"https://www.bloomberg.com/news/articles/2019-07-18/a-former-science-minister-wants-to-fund-the-nhs-by-selling-patient-data\">Bloomberg</a>, <a href=\"https://www.superoffice.com/blog/gdpr-marketing/\">SuperOffice</a> and <a href=\"https://www.theregister.co.uk/2019/10/06/ai_roundup_041019/\">TheRegister</a>.</p>'}]},\n",
       "  {'title': 'Startup Pavilion at AI World Showcases Innovation and Promise',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Startup Pavilion at AI World Showcases Innovation and Promise'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-world-2019/startup-pavilion-at-ai-world-showcases-innovation-and-promise/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-world-2019/startup-pavilion-at-ai-world-showcases-innovation-and-promise/',\n",
       "   'published': 'Thu, 17 Oct 2019 21:30:35 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=21, tm_min=30, tm_sec=35, tm_wday=3, tm_yday=290, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI and Business Strategy',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'AI World 2019', 'scheme': None, 'label': None},\n",
       "    {'term': 'Startups', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI and business strategy', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI and IT services', 'scheme': None, 'label': None},\n",
       "    {'term': 'ai in business', 'scheme': None, 'label': None},\n",
       "    {'term': 'startups', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18139',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff The AI World Conference &#38; Expo in Boston, Oct. 23-25, will include a Startup Pavilion of companies showing innovation, promise and creativity as they pursue business opportunities in new ventures in AI and machine learning. Here is a brief profile of each of the startups: The AI Network of Ridgeway Partners [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff The AI World Conference &#38; Expo in Boston, Oct. 23-25, will include a Startup Pavilion of companies showing innovation, promise and creativity as they pursue business opportunities in new ventures in AI and machine learning. Here is a brief profile of each of the startups: The AI Network of Ridgeway Partners [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By AI Trends Staff</em></p>\\n<p>The AI World Conference &amp; Expo in Boston, Oct. 23-25, will include a Startup Pavilion of companies showing innovation, promise and creativity as they pursue business opportunities in new ventures in AI and machine learning.</p>\\n<p>Here is a brief profile of each of the startups:</p>\\n<p><strong>The AI Network of </strong><a href=\"https://ridgewaypartners.com/\"><strong>Ridgeway Partners</strong></a></p>\\n<p>The <strong>AI Network</strong> was created by Ridgeway Partners, a global executive and board recruiting firm. The AI Network is a talent marketplace which uses AI to connect companies to the best\\xa0 early-stage AI and data science talent. The firm has offices in New York, Boston, London and Hong Kong. Most of the recruiting work is based in the US and Europe, and the firm has completed assignments in Africa, the Middle East and Asia.</p>\\n<p><a href=\"https://aireverie.com/\"><strong>AI.Reverie</strong></a></p>\\n<p><strong>AI.Reverie</strong> is a simulation platform that trains AI to understand the world. Our platform offers tools to leverage the power of synthetic data to significantly improve the performance of mission critical vision algorithms. The firm recently announced a strategic partnership and investment from In-Q-Tel, the not-for-profit strategic investor that works to deliver innovative technology to US intelligence and defense agencies.The firm’s website describes its team as, “Idea generators and problem solvers with a passion for creating a better world with AI.” The company’s services include the creation of virtual worlds with animation and the ability to run simulations that produce synthetic data.</p>\\n<p><a href=\"https://ainfinitylabs.com/\"><strong>AInfinity</strong></a></p>\\n<p><strong>AInfinity </strong>specializes in cutting-edge technology solutions that combine Artificial Intelligence and ITOps capabilities. Drawing on the industry knowledge and expertise of its parent company, Atlas Systems, AInfinity has launched an end-to-end solution focused on predicting IT infrastructure (OS, Network, DB, Middleware) issues and resolving them using its rich knowledge library. The AInfinity Knowledge Library includes runbooks,, use cases, business rules, workflow orchestration, and proven best practices for resolving a wide range of IT issues.</p>\\n<p><a href=\"https://bauglobal.com/\">BAU Global</a></p>\\n<p><strong>The BAU Global Education Network</strong> is comprised of higher education institutions spread around the world. This international network welcomes students from across the globe to study at a number of locations. Students and graduates of BAU Global form an academic community that spans many countries on four continents: North America, Europe, Africa, and Asia. BAU Global universities offer nearly two hundred undergraduate, graduate and doctoral programs in architecture, art, business administration, communication, design, economics, education, engineering, health sciences, information technology, law, medicine, and social sciences.</p>\\n<p>BAU Global develops global citizens who are committed to values that benefit the entire world. The institutions in this network not only meet the standards set forth by the accreditation bodies in their home countries, but are also highly ranked in the disciplines they offer.</p>\\n<p><a href=\"https://www.campteksoftware.com/\">CampTek</a></p>\\n<p><strong>CampTek Software</strong> is an RPA SaaS Provider offering a wide array of services to assist you anywhere on your RPA Journey. Our team of certified experts focus on Bot development, Bot Support and Hosted Support.\\xa0 With over 15 years of experience supporting and developing RPA applications, we are the choice. CampTek’s Software solutions include: Center of Excellence (COE), robot development, SaaS hosting and support, Windows and website automation, Citrix and remote desktop automation, support for Legacy Character-based systems, custom component creation and governance and architecture capabilities.</p>\\n<p><a href=\"https://www.capestart.com/\">CapeStart</a></p>\\n<p><strong>CapeStart</strong> is an outsourced data preparation services and software development firm that gives data-driven organizations the ability to offload tedious data tasks with confidence. Our mission is to provide you with reliable, knowledgeable and affordable solutions for resourcing your big data, machine learning, and artificial intelligence projects. The firm’s campus is Nagercoil, India helps to support the development work. CapeStart is engaged in over 50 active projects for its clients in a range of industries, according to its website. One client hired CapeStart to measure the ROI of its public relations activities, by monitoring the media and performing services including data extraction, sentiment analysis and document transcription.</p>\\n<p><a href=\"https://www.capice.cloud/\"><strong>Capice</strong></a></p>\\n<p><strong>Capice</strong> offers machine learning for everyone, suggesting no technical training or programming background is required to create business models. The Capice AI services including algorithms are available via an API interface. The client provides the training data, as audio, video or text. The Caprice tools are used to address business problems using classification and prediction.</p>\\n<p><a href=\"https://daivergent.com/\"><strong>Daivergent</strong></a></p>\\n<p><strong>Daivergent</strong>, a Public Benefit Corporation, hires workers with autism and developmental disabilities. The firm offers: dedicated project managers with experience in ata and technology fields; a US-based workforce, sourced from universities and agencies in the US; handling of requests of any scale; performance guarantees. The Daivergent platform has a remote user base of 850 candidates and 18 corporate clients. The firm offers employees online training in programming languages including Python and SQL, graphic design, 3-D modeling and marketing, to help bolster career growth. The company works closely with agencies including AHRC in New York City, a nonprofit providing workshops, day treatment programs and job training for people with intellectual and developmental disabilities.</p>\\n<p><a href=\"https://firefly.ai/\"><strong>Firefly.ai</strong></a></p>\\n<p><strong>Firefly.ai</strong> puts the power of artificial intelligence in the hands of any business that aims to predict its future. With our automated machine learning platform, analysts can easily build predictive models to enhance every business decision. Clients engage in the following steps: prepare and analyze data, train hundreds of models, design visual reports and deploy the models. Predictive models offered include demand analysis, predictive maintenance, investment optimization, risk mitigation, sales forecasting and customer segmentation. Firefly.ai targets ordinary business users by offering easy access to AI and machine learning.</p>\\n<p><a href=\"https://www.jaxon.ai/\"><strong>Jaxon.ai</strong></a></p>\\n<p>The best way to improve the accuracy of machine learning models is to increase the amount of labeled data ingested and/or re-label existing data, according to <strong>Jaxon.ai</strong>. Normally it takes months and massive amounts of manpower to get deep learning models trained with meaningful volumes of datasets. By the time the data is labeled, it is frequently already outdated. Jaxon aims to eliminate this bottleneck and allowing models to be updated continuously.</p>\\n<p>With self-adjusting pipelines, Jaxon is said to adapt to each organization’s nuanced data and domain-specific terminology. Training sets are created using existing data, as well as new text streaming in from online and internal sources. Jaxon labels can train any text-based predictive model and can be used for document classification, recommenders, chatbots, customer insights and trend detection.</p>\\n<p><a href=\"https://kyndi.com/\"><strong>Kyndi</strong></a></p>\\n<p><strong>Kyndi </strong>offers an Explainable AI product and Intelligent Process Automation software platform for use by government, pharmaceutical, and financial services organizations. The product addresses the “black box” of Deep Learning, which restricts their use in regulated industries. The Kyndi platform scores the provenance and origin of each document it processes. Its Explainable AI software can be used with robotic process automation (RPA) tools to analyze text and automate inefficient workflows.</p>\\n<p><a href=\"https://lazarusfin.com/\"><strong>Lazarus Enterprises</strong></a></p>\\n<p><strong>Lazarus </strong>uses patient health data to improve early cancer detection. By using its clinical decision support tools, physicians are said to be able to improve their diagnostic accuracy from 76% all the way up to 93%. The company uses deep learning and accesses millions of patient records. The company’s business model is to sell test and subscriptions for physicians and hospitals, and selling anonymous datasets to insurance companies and research companies.</p>\\n<p><a href=\"https://liquidtechnology.net/\"><strong>Liquid Technologies</strong></a></p>\\n<p><strong>LiquidTechnology </strong>is a nationwide provider of IT Asset Management Services. The company specializes in performing data center clean-outs, de-installations, consolidations and moves. The firm’s core competencies include: IT asset purchasing &amp; brokerage, project management, compliant data destruction, chain of custody/ reverse logistics, as well as e-Stewards and R2 compliant e-Waste recycling.</p>\\n<p><a href=\"https://www.ontoforce.com/\"><strong>Ontoforce</strong></a></p>\\n<p><strong>ONTOFORCE </strong>offers to help customers transform siloed data into smart-linked data ecosystems to empower data-driven decision making. The company’s linked data platform DISQOVER builds intelligent links between internal and external data sources, turning data into smart data. The software is installed on-premise or in the cloud. The company employs semantic search technology to help find insights into data. DISQOVER Public is a free resource with links to 145 different public data sources in biomedicine, enabling users to learn about the technology.</p>\\n<p><a href=\"https://www.openmetrik.com/\"><strong>Openmetrik</strong></a></p>\\n<p><strong>Openmetrick </strong>works to automated three activities critical to business success: end-to-end digitization of analytics, enterprise data government and business process virtualization. The firm seeks to disrupt the IT industry by cutting the chaos of current fragmented IT tools, and to eliminate mundate, IT-resource intensive methods. Its software platform, dubbed GRIP, offers business intelligence, performance measurement and business process integration. The company’s Integration Metrics Platform secured a US patent in June 2018 enabling what the company calls the digitization of performance measurement, or a centralized metrics playbook.</p>\\n<p><a href=\"https://perceptimed.com/\"><strong>PerceptiMed</strong></a></p>\\n<p><strong>PerceptiMed’s </strong>advanced pharmacy automation technologies reduce prescription errors and improve pharmacy workflow productivity ─ from fill to will call. PerceptiMed’s identRx<img src=\"https://s.w.org/images/core/emoji/11/72x72/2122.png\" alt=\"™\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /> uses artificial intelligence for pill verification, ensuring every pill placed into a prescription is correct and simultaneously serves as an ultra-accurate pill counter. IdentRx supports remote verification for telepharmacy. The products are designed to eliminate human errors in medication dispensing in pharmacies, long-term care facilities and hospitals.</p>\\n<p><a href=\"https://roborus.ai/\"><strong>Roborus</strong></a></p>\\n<p><strong>Roborus</strong> offers AI-based kiosks that employ facial recognition to automatically identify customers in cafes, restaurants, and retail shops. The software platform uses face recognition technology to classify customers&#8217; data such as facial ID, gender, age, and 7 different moods. The machine learning system can provide guests with personalized services and is able to, for example, recommend specific menu items based on customer profile. The software gathers and analyzes data such as number of visits, consumption patterns and average spending, helping clients to enhance marketing efforts and increase sales.</p>\\n<p><a href=\"https://www.talentseer.com/\"><strong>TalentSeer</strong></a></p>\\n<p><strong>TalentSeer </strong>uses AI to provide integrated talent acquisition, market research, and career mentorship services. With an engaged AI community and deep domain knowledge, TalentSeer has helped over 100 high tech companies from autonomous driving, to finance, and healthcare at various growth stages to build strong teams. AI engineers are overloaded with repetitive pitch messages. The firm employs insight-based and influence-based recruiting techniques, to produce insights on industry, business and career development.</p>\\n<p><a href=\"https://www.tfir.io/\"><strong>TFiR </strong></a></p>\\n<p><strong>TFiR</strong> is an abbreviation for The Fourth Industrial Revolution. The company publishes news, analysis, interviews, op-eds and tutorials covering emerging technologies and open source. The coverage addresses new technologies, new business models, tech culture and their impact on society. A recent newsletter issue included an update from Richard Stallman, the open source software movement activist and self-described “Chief GNUisance.” Stallman announced the GNU Project’s goals, principles and policies will make incremental and not radical changes. TFiR targets CXOs, developers/operators and enthusiasts, according to its website.</p>\\n<p>For more information, see <a href=\"https://aiworld.com/sponsors\">AI World Sponsors. </a></p>'}]},\n",
       "  {'title': 'Machine Learning Embodying Fear and AI Autonomous Cars',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Machine Learning Embodying Fear and AI Autonomous Cars'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-insider/machine-learning-embodying-fear-and-ai-autonomous-cars/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-insider/machine-learning-embodying-fear-and-ai-autonomous-cars/',\n",
       "   'published': 'Thu, 17 Oct 2019 21:30:27 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=21, tm_min=30, tm_sec=27, tm_wday=3, tm_yday=290, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI Trends Insider on Autonomy',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Robotics', 'scheme': None, 'label': None},\n",
       "    {'term': 'Self Driving Cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI Trends Insider', 'scheme': None, 'label': None},\n",
       "    {'term': 'autonomous cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'robot cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'robot taxis', 'scheme': None, 'label': None},\n",
       "    {'term': 'robotics', 'scheme': None, 'label': None},\n",
       "    {'term': 'self driving cars', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18133',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider [Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/] Fear is considered one of the fundamental elements of emotion. It seems as though humans and pretty much all animals are prone to fear. Fear [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider [Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/] Fear is considered one of the fundamental elements of emotion. It seems as though humans and pretty much all animals are prone to fear. Fear [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Lance Eliot, the AI Trends Insider</em></p>\\n<p><em>[Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: </em><a href=\"https://forbes.com/sites/lanceeliot/\"><em>https://forbes.com/sites/lanceeliot/</em></a><em>]</em></p>\\n<p>Fear is considered one of the fundamental elements of emotion.</p>\\n<p>It seems as though humans and pretty much all animals are prone to fear.</p>\\n<p>Fear can be based on a real situation, such as you might be standing in front of a hungry lion and so you naturally are bound to be fearful of it, or fear might be based on a perceived danger that is not necessarily directly evident, such as walking down a dark alley and being inherently suspicious that something bad might happen to you.</p>\\n<p>Typically, there is a physical response in a human or animal when experiencing fear.</p>\\n<p>You have likely been on a roller coaster and in anticipation of that big drop up ahead your heart rate goes up, you feel your body tensing, your mind might become laser focused and you can’t think of anything other than the circumstance that you are facing.</p>\\n<p>Humans have an ability to detect fear on others, including via facial expression analysis (someone’s face gets tense), the person might clench their teeth and make fists with their hands, etc. Of course, animals can also detect fear, of which I’m guessing you’ve had cases whereby a dog sensed your fear, maybe smelling your perspiration, and either took advantage of your fearful state or in some instances maybe even tried to reduce it.</p>\\n<p>Responding to fear can be as simple as the classic fight-or-flight kind of response.</p>\\n<p>If you fear something, you might decide to stand your ground and fight it. Alternatively, you might instead decide to run from whatever is causing the fear. Regrettably, sometimes while in the grip of fear we make bad choices. It could be that you should have chosen to run away from an angry bear rather than trying to confront it. Maybe trying to run away from an approaching ball of fire would have been better handled by trying to shelter in place.</p>\\n<p>There are other options beyond just fight-or-flight, including one that can be the worst of them all, freezing up.</p>\\n<p>Sometimes the fear is so overwhelming that trying to ascertain what to do is beyond our mental capacity at the moment, and thus we become frozen in fear. Though it might be possible that being frozen will work out okay in the given situation, generally some response is more likely to be successful than no response at all.</p>\\n<p><strong>Fear Plausibility</strong></p>\\n<p>Another twist to fear is that it can be considered plausible or implausible (some would say valid or invalid).</p>\\n<p>Last year, there was a Chinese space station that was going to fall to earth and supposedly no one could predict where it would ultimately land.</p>\\n<p>I had a colleague that told me he was fearful it could land on him.</p>\\n<p>I tried to point out that the vast majority of the globe is water and so the odds were high that it would fall into the water and not strike anyone in particular.</p>\\n<p>Even if it fell over land, I pointed out that by being inside a structure such as a building, it would seem unlikely he’d get hit and killed.</p>\\n<p>The odds that he would be outside and be struck by it were likely much less odds than say winning the multi-state lotto (I realize he’d rather win the lotto than get hit by the space station). I suggested he buy the multi-state lotto ticket, the payout was around $500 million, and that maybe he’d win the lotto and get hit by the space station at the same time (those are some amazing odds!).</p>\\n<p>Anyway, sometimes fear is in our minds, but not due to an actual fearful situation per se.</p>\\n<p>We can convince ourselves to be fearful.</p>\\n<p>In that sense, fear is definitely a dual-edged sword.</p>\\n<p>Fear provides us with a vital survival technique. When utilized poorly, it can cause us to damage ourselves as based on a false believe that something dangerous is going to happen, when let’s say there’s really no chance of it happening at all.</p>\\n<p>Some would refer to this as an unfounded fear.</p>\\n<p>A fascinating recent study examined fear and described an angle that most would not have thought of.</p>\\n<p>We all know that you are bound to be fearful of a predator.</p>\\n<p>The field mouse is fearful of the swooping hawk. The prey is fearful of the predator, and rightfully so.</p>\\n<p>This particular study pointed out that animals tend to avoid eating feces or munching on a carcass that has gone bad.</p>\\n<p>Those aren’t predators, so why fear them?</p>\\n<p>It’s because we are fearful of getting infections or disease, and seem to realize that we need to avoid circumstances that might involve getting infected by some untoward bacteria.</p>\\n<p><strong>Nature Versus Nurture</strong></p>\\n<p>How do animals know about this?</p>\\n<p>In the nature-versus-nurture debate, are we programmed in our DNA to avoid things that might infect us, or do we only learn over time by either watching others, or by being taught, or by getting an infection and surviving it such that we realize not to do that again?</p>\\n<p>If you see a hawk diving at you, it’s a pretty obvious aspect that maybe you should avoid letting it get you. But, seeing a juicy carcass, when you are starving, and opting to avoid eating it, because you somehow know that hours or maybe days later you might get sick, and might die, now that’s an interesting aspect of fear.</p>\\n<p>You need to connect a later-on consequence to something that at the moment seems benign.</p>\\n<p>The researchers described a landscape of fear.</p>\\n<p>Animals will avoid drinking contaminated water.</p>\\n<p>Animals will avoid eating a carcass when it seems too far gone.</p>\\n<p>Animals will even graze away from an area that had a carcass, as though realizing that whatever is bad about the carcass could be spread locally beyond just the carcass. Animals tend to flee from biting ticks or try to get the ticks off their bodies.</p>\\n<p>Within the landscape of fear, animals are able to detect infection threats. Either instinctively or in a learned manner, animals weigh the risks associated with the threats and try to achieve various levels of safety.</p>\\n<p>For any of you interested in population dynamics and ecological aspects, you’d likely find this view of predator avoidance and infection avoidance of keen fascination.</p>\\n<p><strong>Fear Landscape And Autonomous Cars</strong></p>\\n<p>What does this have to do with AI self-driving driverless autonomous cars?</p>\\n<p>At the Cybernetic AI Self-Driving Car Institute, we are developing an aspect of AI systems for self-driving cars that involves leveraging a landscape of fear regarding driving cars.</p>\\n<p>Allow me a moment to elaborate on this somewhat surprising approach.</p>\\n<p>As a human driver, you presumably already have a fear of hitting another car.</p>\\n<p>You likely are fearful that you might hit a pedestrian.</p>\\n<p>You probably also have a fear that other drivers are going to hit your car.</p>\\n<p>You might have a fear that your car will fail on you, such as being on the freeway and all of a sudden it conks out and you are stranded in the middle of the busy freeway in a stalled car. It is possible you have a fear that the roadway will be unusable or impassable.</p>\\n<p>The other day I drove up to the local mountains and reached a point that the paved road turned to packed dirt, which then became loose dirt, which then became muddy due to recent rains. My car almost got stuck in the middle-of-nowhere in an impassable road (I was driving just a conventional car and not an off-the-road vehicle).</p>\\n<p>All of the above fears as a human driver are plausible.</p>\\n<p>They are founded on a reasonable belief that those things could happen.</p>\\n<p>We daily harness those fears while driving our cars. Some drivers though make driving mistakes as based on a fear that is either unfounded or at least that doesn’t actually materialize.</p>\\n<p>I was in a car one day with a young driver that notably never made a left turn. He seemed to avoid to the extreme making a left turn.</p>\\n<p>Now, we all know that left turns can be dangerous, and even some of the shipping companies such as UPS are using GPS systems that try to minimize the number of left turns. But, this was left turn paranoia.</p>\\n<p>In talking with the driver, he shared with me a sad story of his family having gotten into a car crash while making a left turn, so he vowed that it would never happen again, which he figured by not making left turns would pretty much guarantee it. I did not have the heart to point out that his now heightened frequency of right turns, being done to make-up for not making left turns, might well have balanced out the risks of making a lesser number of left turns.</p>\\n<p>His fear of left turns would not have been apparent or visible unless you were observing him, as I had, while a passenger in the car.</p>\\n<p>If you had asked him about his driving approach, I doubt he would have volunteered that he won’t make left turns. An outside observer might not have noticed it either, unless you were following him like a secret agent.</p>\\n<p>Our fears then can be hidden from view.</p>\\n<p>Likewise, when I mentioned that you are fearful of getting into a car crash and fearful of your car faltering, it’s not something that you probably would have voiced if I had asked you about it.</p>\\n<p>The word “fear” in our society has various connotations, generally being less flattering to the person that embodies the fear. What, you were fearful of riding that roller coaster, you’re a chicken! Society seems to pressure us to hide our fears and tend to not admit to them.</p>\\n<p>For AI purposes, some believe that if we are to achieve true AI, and be able to make computer systems that can do what humans do, we need to replicate as much as possible whatever humans do.</p>\\n<p>If humans rely on emotions, we must then incorporate emotions into computer systems to achieve true AI.</p>\\n<p>There is a counter-argument that maybe we don’t need emotions to have intelligence, and so we can strip away some aspects of humans and yet still arrive at fully intelligent systems.</p>\\n<p>Others say that our intelligence is intertwined with our emotions and you cannot separate them out and yet still have intelligence. Having a no emotions AI system would not end-up being fully intelligent as it has lost an essential component that is wrapped inextricably into intelligence, they would assert.</p>\\n<p>Whether you stand on one side or the other of the debate about emotion and intelligence, I think we could say that fear is something that does make sense for an intelligent being to possess. If you are willing to consider fear as a form of mathematical calculation about the perceived dangers and risks, we certainly should have that same kind of capability built into our AI systems.</p>\\n<p>As such, an AI self-driving car should make use of fear.</p>\\n<p>That being said, I am not talking about the kind of “the sky is falling” kind of fear. I am referring to the notion of fear as a methodical means to try and determine risks and dangers, and seek actions to reduce those risks and try to achieve greater chances of safety.</p>\\n<p><strong>Example Of No Fear Producing Dangers</strong></p>\\n<p>I was in a car with a colleague that likes expensive cars and loves to drive fast (I would say recklessly, while he would say just fast).</p>\\n<p>We were on the freeway in the leftmost lane, the fast lane.</p>\\n<p>Our exit to get off the freeway was fast approaching. He gunned his engine and at the last moment darted across all of the lanes of traffic, having lined up small gaps in each lane, including darting in front of a very large truck hauling a tanker of gasoline.</p>\\n<p>Did we make it to the exit ramp? Yes.</p>\\n<p>Did we hit any cars or trucks? No.</p>\\n<p>In my mind, I was quite fearful when I realized what he was going to try and do. He said that he had no fear because he had done this action many times and he “knew” that he could pull this one off.</p>\\n<p>For an AI self-driving car, suppose it found itself in a similar situation.</p>\\n<p>You might argue with me that the self-driving car would have been better prepared and would have gradually made its way over to the exit and not needed to leap toward it. But, suppose I told you that the occupant in the self-driving car had suddenly told the self-driving car that they wanted it to make that next exit.</p>\\n<p>Thus, the self-driving car had little time to take the more gradual path to get to the exit.</p>\\n<p>You could say that the AI should have refused to make the exit.</p>\\n<p>The AI should have said that the occupant had been late in asking and so it was tough luck, and that instead the AI would route the self-driving car to the next exit and then via side streets make its way back to where that earlier exit had been.</p>\\n<p>This brings up an important aspect about AI self-driving cars, namely, what is the nature of the driving approach that we want our self-driving cars to have?</p>\\n<p>You might want the AI to do exactly what the “reckless” human driver had done, and have gone for it in terms of making a last gasp dive to the freeway exit. Why is the gradual approach better than the dive for it approach? You might assert that the gradual approach is certainly safer. By what proof do you claim this?</p>\\n<p>In fact, those that believe we will have a Utopian world of all self-driving cars, which I’ve pointed out is unlikely and that at least for many decades we will have a mix of both human driven cars and self-driving cars, but if we do have all self-driving cars then presumably the dive to the exit would be as safe as any other maneuver.</p>\\n<p>The self-driving car that wanted to dive to the exit could alert all the other self-driving cars nearby, via V2V (vehicle-to-vehicle communications), and the pathway that otherwise randomly had formed for the human driver might now become a designed path instead (based on the cooperation of the other self-driving cars).</p>\\n<p>We could end-up with extremely aggressive AI self-driving cars.</p>\\n<p>It all depends on how we program the AI and also what the AI is learning.</p>\\n<p><strong>Machine Learning Subtly Captures Fear</strong></p>\\n<p>Let’s consider the Machine Learning aspects of fear.</p>\\n<p>Suppose you have an AI self-driving car that is learning about driving by observing traffic situations and trying to find patterns to the driving behavior, of which then the AI will adopt those same driving behaviors.</p>\\n<p>In a traffic environment of reasonable human drivers that give proper way to other drivers and abide by legal speeds, the machine learning would find those patterns and presumably be a monkey-see monkey-do and perform driving in the same manner. We have artificial neural networks that indeed do this.</p>\\n<p>Imagine driving in the chaotic streets of New York City at rush hour. Cars cut each other off. Cars drive within inches of other cars. Cars won’t let other cars into their lanes. It’s a dog eat dog world there. Without knowing the drivers, themselves, and by only looking at the outcomes of their driving, we have a different picture of what driving is all about.</p>\\n<p>Deriving a pattern to driving behavior would be quite a contrast to a traffic environment of a more safety conscious wider-margins-for-error kinds of drivers.</p>\\n<p>Thus, a neural network or other kind of machine learning will indirectly embody “fear” as it is embodied in the driving behavior of those that the system is learning from. We are not in this case of a machine learning approach explicitly calling out fear and making it part of the AI system as a separate component, and instead it is being captured via the behavior of the driving going on that is being used to pattern after.</p>\\n<p>In one case, the fear of the drivers has led to more collegian driving outcomes, while in the other case the lesser sense of fear leads to cars that nearly hit or actually do include fender benders.</p>\\n<p>We could though be more explicit about the fear aspects.</p>\\n<p>The AI self-driving car has sensors that collect data for purposes of sensing the world around the self-driving car, and that data is then fed into the sensor fusion. The sensor fusion tries to figure out from the sensor data what is usable and what might not be, such as having a camera lens that is obscured by dirt and needing to rely instead on a radar that is able to detect that same area that the camera would. The sensor fusion then feeds into a virtual world model that depicts the existing and ongoing state of the surroundings and the self-driving car too.</p>\\n<p>Based on the virtual world model, the AI needs to derive an action plan of what to do next with the self-driving car. If the situation involves accelerating to get between cars that are to the right of the self-driving car, this is then issued as commands to the controls of the self-driving car. As is the steering command to direct the self-driving car over into the next lane. And so on.</p>\\n<p>It is within these AI action plans that we are immersing a healthy dose of fear.</p>\\n<p>You want the self-driving car to be “fearful” of hitting other cars.</p>\\n<p>You want it to be “fearful” of having other drivers hit the self-driving car.</p>\\n<p>These are part of the algorithms of deriving the action plans.</p>\\n<p>If the AI isn’t instructed or hasn’t learned to not hit other cars, it would likely come up with action plans that inevitably would be intentionally hitting other cars. Indeed, if you have ever watched a simulation that is used to train self-driving cars, you’ll see that the self-driving car action plans at first involve hitting other cars, but there is a points mechanism that helps the AI to realize that hitting other cars is not a good thing to do.</p>\\n<p>By the use of Machine Learning, we are putting an “instinctive” landscape of fear into the AI of the self-driving car, and this is augmented by an explicitly taught landscape of fear by programming the AI code accordingly.</p>\\n<p>Since we are on the topic of fear and AI self-driving cars, I should take a moment to also discuss a whole different aspect about fears and AI self-driving cars.</p>\\n<p>There are humans that are fearful of being occupants in AI self-driving cars.</p>\\n<p>I’ve discussed this at length in various forums and pointed out that though the media at times makes it seem that these are unfounded fears, I assert that people are right to have a healthy dose of fear about riding in today’s AI self-driving cars. Notice that I use the word “today’s” because I don’t want to suggest that we will always be fearful of riding in self-driving cars and instead differentiating that the existing crop of self-driving cars have yet to earn the right to have a low level of fear for occupants.</p>\\n<p>On a similar vein, some humans are fearful about having AI self-driving cars on our roadways.</p>\\n<p>This is due to a concern that the self-driving cars might hit other cars and strike pedestrians. Once again, I say these people are well justified in such a fear today. AI self-driving cars have yet to provide ample evidence to warrant our being fearless about how these self-driving cars might behave. I don’t believe this will be forever and just want to emphasize that it’s a condition of the state-of-the-art of what exists today.</p>\\n<p>Returning back to my mainstay points about including fear into AI self-driving cars, I would want any self-driving car to have a reasonable fear of human drivers.</p>\\n<p>Yes, that’s right, be fearful of human drivers. In the same manner that you or I are watching out for other human drivers, and we are leveraging our “fear” to gauge how we drive, it stands to reason that we want the AI self-driving cars to do the same. It needs to be a reasoned fear, and not an unfounded fear.</p>\\n<p>As they say, once the AI has mastered the landscape of fear, the only fear it should have, will be fear itself.</p>\\n<p><em>Copyright 2019 Dr. Lance Eliot </em></p>\\n<p><em>This content is originally posted on AI Trends.</em></p>\\n<p><a href=\"http://ai-selfdriving-cars.libsyn.com/website\"><img class=\"alignnone size-medium wp-image-17417\" src=\"https://www.aitrends.com/wp-content/uploads/2019/06/selfdrivingcarspodcastv2-300x150-300x150.jpg\" alt=\"\" width=\"300\" height=\"150\" /></a></p>'}]},\n",
       "  {'title': 'AI Being Used to Confront, Mediate Climate Change',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'AI Being Used to Confront, Mediate Climate Change'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-in-science/ai-being-used-to-confront-mediate-climate-change/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-in-science/ai-being-used-to-confront-mediate-climate-change/',\n",
       "   'published': 'Thu, 17 Oct 2019 21:30:24 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=21, tm_min=30, tm_sec=24, tm_wday=3, tm_yday=290, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI in Science', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI Research', 'scheme': None, 'label': None},\n",
       "    {'term': 'Machine Learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI in science', 'scheme': None, 'label': None},\n",
       "    {'term': 'ai research', 'scheme': None, 'label': None},\n",
       "    {'term': 'machine learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'predictive analytics', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18130',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />AI is being applied to the biggest challenge facing the planet &#8211; climate change. Early results are encouraging. Machine learning can be deployed in energy production, CO2 removal, education, solar geoengineering and finance, among 13 relevant answers according to a paper titled “Tackling Climate Change with Machine Learning, present at a workshop in June as [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />AI is being applied to the biggest challenge facing the planet &#8211; climate change. Early results are encouraging. Machine learning can be deployed in energy production, CO2 removal, education, solar geoengineering and finance, among 13 relevant answers according to a paper titled “Tackling Climate Change with Machine Learning, present at a workshop in June as [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p>AI is being applied to the biggest challenge facing the planet &#8211; climate change. Early results are encouraging.</p>\\n<p>Machine learning can be deployed in energy production, CO2 removal, education, solar geoengineering and finance, among 13 relevant answers according to a paper titled “Tackling Climate Change with Machine Learning, present at a workshop in June as a way to focus research, according to David Rolnick, a postdoctoral fellow at the University of Pennsylvania and one of the authors.</p>\\n<p>“It’s surprising how many problems in machine learning can meaningfully contribute to,” said Rolnick, quoted in an account in <a href=\"https://www.nationalgeographic.com/environment/2019/07/artificial-intelligence-climate-change/\">National Geographic</a>. Possible outcomes include more energy-efficient buildings, new low-carbon materials, better monitoring of deforestation and greener transportation.</p>\\n<p>Three specific areas where AI research could focus were suggested: better climate predictions, showing the effects of extreme weather and measuring where the carbon is coming from.</p>\\n<p>Climate predictions can be enhanced by climate informatics, a discipline at the intersection of data science and climate science. It covers a range of topics including extreme events, reconstructing of past climate conditions, and large-scale models to be used for predictions. Climate modeling is progressing, with complex climate simulations having potential to unlock new insights.</p>\\n<p>One project is using machine learning algorithms to combine the predictions of some 30 climate models used by the Intergovernmental Panel on Climate Change.</p>\\n<p>Researchers at the Montreal Institute for Learning Algorithms (MILA), Microsoft and ConscientAI Labs are using General Adversarial Networks (GANs) to simulate what homes will look like after being damaged by rising sea levels and more intense storms. Plans include release of an app to show individuals what their neighborhoods and homes might look like with different climate change scenarios.</p>\\n<p><strong>Banking Industry Also Studying Climate Change</strong></p>\\n<p>A London-based not-for-profit consultancy called Caron Tracker is researching the impact of climate change on financial markets. It generates data by monitoring coal plant emissions with satellite imagery. Carbon Tracker is working to fulfill a UN goal of preventing new coal plants from being built by 2020. A grant from Google is expanding the effort to include emissions from natural gas plants, to help identify where pollution is coming from.</p>\\n<p>“This can be used worldwide in places that aren’t monitoring,” said Durand D’souza, a data scientist at Carbon Tracker. “And we don’t have to ask permission.”</p>\\n<p>Climate Change AI is an organization of volunteers from academia and industry discussing how computational science can mitigate climate change. Participants include Andrew Ng, co-founder of Google Brain, Deis Hassabis, a founder of DeepMind and Jennifer Chayes, managing director at Microsoft Research, according to an account in <a href=\"https://www.bbva.com/en/artificial-intelligence-an-ally-against-climate-change/\">BBVA</a>, serving the banking sector.</p>\\n<p>AI is seen as helping improve the energy sector, where automated distribution networks can perform real-time smart assessments to fine tune supply and demand of electricity. Smart homes and intelligent operations and logistics in the construction industry, have the potential to lower the carbon footprint. Algorithms and machine learning make it possible to anticipate electricity demand of a city or a manufacturing plan months in advance. Power can potentially be distributed to small local populations more efficiently as a result.</p>\\n<p>Google operates a fleet of wind farms in the US. Algorithms developed by Alphabet’s Deepmind researchers are able to predict wind farm energy 36 hours in advance, using advanced weather forecast technologies, now available.</p>\\n<p>In transportation and logistics, data from the Intergovernmental Panel on Climate Change (IPCC) shows that between 1970 and 2004, the sector increased its greenhouse emissions by 120 percent. The potential is there for transportation companies to more accurately predict demand and avoid risks. DHL, the global logistics services provider, has developed software that can juggle up to 58 parameters to define optimal schedules for cargo airplanes days in advance. This should result in few flights.</p>\\n<p><strong>UK Government Backing New Doctoral Research on Climate Change</strong></p>\\n<p>The UK government is backing more research into climate change at Cambridge University, with a new doctoral training program on the Application of AI to the Study of Environmental Risks, to be led by Prof. Simon Redfern, head of the Department of Earth Sciences.</p>\\n<p>The scientific community has access to larger datasets than ever before to help conduct this research. “These datasets represent a transformation in the way we can study and understand the Earth and environment, as we assess and find solutions to environmental risk,” said Redfern in an account in <a href=\"https://liwaiwai.com/2019/08/26/using-artificial-intelligence-to-avert-environmental-catastrophe/\">liwaiwai.com</a>, a site aimed at programmers. “Such huge datasets pose their own challenges, however, and new methods need to be developed to tap their potential and to use this information to guide our path away from environmental catastrophe.”</p>\\n<p>Projects underway include the use of satellite observations to chart the distribution and pathways of whales through oceans, large datasets to understand biodiversity changes in woodland habitats, machine learning to understand earthquake risk,and the use of drones to monitor hazards at active volcanoes.</p>\\n<p>See the source posts at <a href=\"https://www.nationalgeographic.com/environment/2019/07/artificial-intelligence-climate-change/\">National Geographic</a>,\\xa0 <a href=\"https://www.bbva.com/en/artificial-intelligence-an-ally-against-climate-change/\">BBVA</a> and <a href=\"https://liwaiwai.com/2019/08/26/using-artificial-intelligence-to-avert-environmental-catastrophe/\">liwaiwai.com</a>.</p>'}]},\n",
       "  {'title': 'Executive Interview: Dr. Angeli Moeller, AI Program Lead, Bayer Pharmaceuticals',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Executive Interview: Dr. Angeli Moeller, AI Program Lead, Bayer Pharmaceuticals'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/executive-interview/executive-interview-dr-angeli-moeller-ai-program-lead-bayer-pharmaceuticals/'}],\n",
       "   'link': 'https://www.aitrends.com/executive-interview/executive-interview-dr-angeli-moeller-ai-program-lead-bayer-pharmaceuticals/',\n",
       "   'published': 'Thu, 17 Oct 2019 21:30:20 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=17, tm_hour=21, tm_min=30, tm_sec=20, tm_wday=3, tm_yday=290, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'Executive Interviews', 'scheme': None, 'label': None},\n",
       "    {'term': 'Health Care', 'scheme': None, 'label': None},\n",
       "    {'term': 'Machine Learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'ethics and social issues', 'scheme': None, 'label': None},\n",
       "    {'term': 'health care', 'scheme': None, 'label': None},\n",
       "    {'term': 'machine learning', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18142',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />Focus is on AI as a tool that guides in the detection of diseases; lighthouse projects showing results; public-private partnerships helping with access to needed data Dr. Angeli Moeller has two roles at Bayer Pharmaceuticals, she co-leads the artificial intelligence work stream and is responsible for the research digital investment strategy. Before joining Bayer she [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />Focus is on AI as a tool that guides in the detection of diseases; lighthouse projects showing results; public-private partnerships helping with access to needed data Dr. Angeli Moeller has two roles at Bayer Pharmaceuticals, she co-leads the artificial intelligence work stream and is responsible for the research digital investment strategy. Before joining Bayer she [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p>Focus is on AI as a tool that guides in the detection of diseases; lighthouse projects showing results; public-private partnerships helping with access to needed data</p>\\n<p><em>Dr. Angeli Moeller has two roles at Bayer Pharmaceuticals, she co-leads the artificial intelligence work stream and is responsible for the research digital investment strategy. Before joining Bayer she worked as a data scientist for translational medicine at Thomson Reuters and researcher at Cancer Research UK and the Max Delbrück Center for Molecular Medicine.</em></p>\\n<p><em>As a keen proponent of pre-competitive collaboration, she also sits on the executive committee of the </em><a href=\"https://www.theaaih.org/\"><em>Alliance for Artificial Intelligence in Healthcare (AAIH)</em></a><em> and on the investment committee of the </em><a href=\"https://www.pistoiaalliance.org/\"><em>Pistoia Alliance.</em></a></p>\\n<p><em>Moeller </em><em>is driving work at Bayer to employ AI to help get the right treatment to the right patient at the right time. Bayer Pharmaceuticals invests in lighthouse initiatives that use AI to drive top-line and bottom-line growth, while accelerating digital transformation. She recently spent a few minutes talking to AI Trends Editor John P. Desmond.</em></p>\\n<p><strong>Could you describe your responsibilities at Bayer?</strong></p>\\n<p>The IT business partnering team I lead is in the pharmaceutical research area, and it is responsible for the digital investments in both the pre-clinical area and investments that cover cross-R&amp;D projects. I took on that role in May last year, at which time I was also appointed co-lead of our artificial intelligence work stream for the entire pharmaceuticals division, a role I share with a colleague from the strategy team, Michael Heinke. The scope of the AI workstream encompasses R&amp;D, medical affairs and pharmacovigilance, commercial and product supply. The projects are run by several empowered teams working across our value chain, strongly supported by external partnerships, and enabled by our parallel data architecture workstream.</p>\\n<figure id=\"attachment_18143\" style=\"width: 200px\" class=\"wp-caption alignleft\"><img class=\"size-medium wp-image-18143\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AngelieMoller-2-200x300.jpg\" alt=\"\" width=\"200\" height=\"300\" /><figcaption class=\"wp-caption-text\">Dr. Angeli Moeller, AI Program Lead, Bayer Pharmaceuticals</figcaption></figure>\\n<p><strong>You have concentrations in your career in molecular biology, protein chemistry, and cell biology for example. What impact is new AI technologies having on those areas of research?</strong></p>\\n<p>When I started my PhD at Edinburgh University, I was doing lab work coupled with informatics. We were getting so much data from our phage-display methods we were only able to make predictions leveraging bioinformatics. Subsequently in my post-doc, the value of predictions made possible through machine learning became increasingly critical. You can call it artificial intelligence or you can call it machine learning. At the time, it became clear to everyone working in molecular biology that you couldn&#8217;t just study molecular biology. You had to also be working in data science or informatics.</p>\\n<p>The rise of AI in research has been triggered by two big trends. Firstly, that lab automation now creates datasets so large that we can make increasingly accurate predictions with methodologies like machine learning, because we now have the compute power needed. The other trend, which is driving things forward is translational research. For molecular biology, protein biochemistry and cell biology, it can be limiting to treat research as a sequential process, for instance to start <em>in vitro</em> then go into animal studies or human studies. During my time in academia we increasingly began building predictions from <em>in vivo </em>experiments and clinical studies, using meta-analysis across investigations conducted in the past. Although the need to validate predictions is still the critical next step.</p>\\n<p>The rise of translational medicine and machine learning has completely changed the way that we can look at molecular biology and protein biochemistry. For example, in the first year of my PhD I looked at interactions between two or three proteins in detail whereas in my postdoc we worked on modeling the human chemical synapse and predicting protein-protein interactions. The parameters modelled came from mouse knock-out studies, genome-wide association studies, high-throughput cell line screening and only through integration of these varied data sets were we able to model the thousands of complex interactions at a single synapse. Now add to that a model of all synapses across the brain, at various timepoints in different states of activation and we can really start to tackle some interesting medical questions.</p>\\n<p><strong>Could you describe one or more of the initiatives using AI to drive growth at Bayer?</strong></p>\\n<p>Within Bayer, we have a series of AI projects with the shared objective of getting new medicines to patients more quickly and efficiently. To achieve this goal, our projects tackle various aspect of the value chain from drug development, to clinical development, to market access, to product supply, to commercial, to providing information to health care professionals and enabling reimbursement.</p>\\n<p>One example is our CTEPH app, which got a breakthrough device designation from the FDA. It is based on an artificial neural network.</p>\\n<p><em>[Ed. Note: Chronic Thromboembolic Pulmonary Hypertension (CTEPH) Pattern Recognition was given a </em><a href=\"https://media.bayer.com/baynews/baynews.nsf/id/FDA-grants-breakthrough-device-designation-artificial-intelligence-software-CTEPH-pattern\"><em>Breakthrough Device Designation </em></a><em>in December 2018 by the FDA.]</em></p>\\n<p>CTEPH is an indication where patients have blood clots forming in their lungs. It manifests in symptoms where you have high blood pressure, shortness of breath or you feel very fatigued. These are also symptoms of other diseases so it can be very difficult to diagnose. But using our algorithm, which runs on the CT images of patients, we aim to detect very early whether or not patients are suffering from CTEPH. And then if they are suffering from CTEPH to make sure they get on the right treatment very quickly. For us it&#8217;s all about getting the right medicine to the right patient as quickly and as efficiently as possible.</p>\\n<p>The second example is in the heart failure and stroke area. We have a collaboration with Sensyne, a startup operating in the UK, and the goal is to use data from several National Health Service Trusts to identify new biomarkers in heart failure and stroke. The team is exploring a range of machine learning approaches across those data sets.</p>\\n<p><strong>What are some of the challenges you face in applying AI to healthcare in your research areas?</strong></p>\\n<p>One key challenge is education. Many people fear that artificial intelligence will take away choice from patients and doctors. It’s important to us that AI is used as a tool that guides us in the detection of diseases and makes treatment recommendations. But in the end, the control over which treatments are given to which patients is still something that patients and their doctor decide together, using more accurate information to make that decision.</p>\\n<p>We want to provide the most accurate information for the researchers who are developing the drugs, the doctors who are testing the drugs and prescribing the drugs, and for the patients who are being treated by the medicines. We don&#8217;t want to take away control of making decisions from anyone. And I think there it&#8217;s really important when we put the applications into clinical practice or into hospitals that we&#8217;re very careful to make sure that it&#8217;s used in the right way. So that in the end, the control of the decision-making processes is still with the doctor and their patient.</p>\\n<p><strong>Are there any other challenges?</strong></p>\\n<p>Getting access to the data we need is a very big challenge. For machine learning to be meaningful, you need very large data sets. However, we’re using a number of approaches that mean we don&#8217;t have to clean and curate the data sets to the extent we did in the past. Additionally, federated learning means that we can now train our models on data that is stored in different locations without moving the data. We train an algorithm behind the firewall of different data owners who ensure the security and integrity of the data, this allows the model to improve its predictive power using the data without having to put all the datasets together. Which is very important because for most patient data, it has to stay in a very secure local environment.</p>\\n<p>But just trying to find enough data can be a daunting challenge. What’s going to be very important is establishing public-private partnerships, B2B partnerships, and academic partnerships, which will make safe access to data possible. This will drive forward innovative disease research using artificial intelligence.</p>\\n<p><strong>What is the role of the Alliance for AI in healthcare that you helped to found?</strong></p>\\n<p>The Alliance is dealing with exactly the challenge I mentioned earlier around education. Our core focus is to do that together with policy makers and academic thought leaders.</p>\\n<p>We founded the Alliance because we wanted to stop this from being a competitive approach, and make it a pre-competitive approach where different companies work together to do what is in the best interest of the patients who can benefit from this new technology. That’s why within the AAIH you have large pharma and tech companies working together with university partners and biotech to try and tackle these issues.</p>\\n<p>Our education committee works with member companies to create internships for students who want to move into AI in healthcare and to provide educational material useful for doctors who are starting to think about how they can use AI-based applications.</p>\\n<p><strong>How has the role of IT changed, if at all, since the growth of AI technology at Bayer?</strong></p>\\n<p>I work in IT. At some companies people would have asked “why is this person working in the IT department?” The answer is that at Bayer, IT teams must understand how emerging technologies can best be applied to meet the needs of the business, in my case the pharmaceutical division, therefore an increasing number of our hires have a data-science background often coupled with experience in an area of pharma, e.g. commercial, product supply or R&amp;D. Our pharma IT organization works in cross-disciplinary teams that include cloud-engineers, data scientists, biosample experts, bioinformaticians, clinical data managers, just to name a few.</p>\\n<p><strong>How far along is it the digitization of pharma, would you say?</strong></p>\\n<p>As an industry… it&#8217;s an interesting question. When I was at Thomson Reuters, which was only three years ago, I had clients which made up five of the largest pharmaceutical companies in the world. Now I sit in the Pistoia Alliance, in which 19 of the top pharma companies work together on pre-competitive projects. So based on those observation points, I’d say it&#8217;s very uneven. Some pharma companies are further ahead than others. Many have focused in certain areas and certain parts of the pharmaceutical process and not in others. I would say that, compared to other industries, we&#8217;re still just entering our digital journey, but I think some of us have understood that we must move at a highly accelerated rate to enact our digital transformation.</p>\\n<p><strong>Are you able to find the people you need to get the AI work done at Bayer? What do you look for in new hires?</strong></p>\\n<p>We are making really good hires, I have had the opportunity to work with new employees with extraordinary talent in the last year. But the market for data scientists is very competitive. There are not enough highly skilled machine learning experts in the world right now. This is why we’re working on the pipeline of talent coming out of universities, e. g. with internships we are creating with the Alliance for AI in Healthcare.</p>\\n<p>We are also able to offer very good packages, which makes us an attractive employer. On a personal note, I&#8217;m the mother of a young child and I like to keep a healthy work-life balance. This is what Bayer has to offer and that helps us to attract talent.</p>\\n<p>Another important point is that if you&#8217;re working on AI in healthcare, you always have a strong motivation for what you&#8217;re doing. Here we are implementing AI to help keep people healthy or to fight diseases like cancer. This makes a difference in comparison to pure tech companies.</p>\\n<p>Most of our lighthouse case work on artificial intelligence is in cardiovascular disease and oncology right now. Many people have a loved one affected by diseases in these areas. For instance, my own family has a very high incidence of serious cardiac events. A lot of our work in artificial intelligence is still in early research stages, but knowing we’re working to have a positive impact on diagnosis and treatment is very rewarding.</p>\\n<p><strong>Do you have any advice for young people interested in a career in AI for what they should study if they&#8217;re students, or if they&#8217;re early career where they should concentrate?</strong></p>\\n<p>For young people entering their career, it&#8217;s critical to invest in your hard skills, e.g. statistics and programming. For people who have done that and are now looking to expand in their career in industry, it’s necessary to also demonstrate business understanding. If I look at my job today, it also involves discussions on financial impact, population health economics and a broader understanding of how a strategy for artificial intelligence can be developed. So I think then having more business insight is critical for that further career development. Lucky for me we have a lot of coaches and mentors at Bayer in senior positions who are always ready to support fellow employees developing new skills.</p>\\n<p>Bayer is invested in helping young people start data science careers in healthcare. If any of your readers are interested, we have our job portal, we&#8217;re very active on LinkedIn, and we also host a lot of networking events.</p>\\n<p><strong>Is there anything you would like to add?</strong></p>\\n<p>I like to emphasize that we keep the patient at the center because I think it&#8217;s very easy to get swept up in the technology. If we keep the needs of the patient at the center of our strategy, then we’ll stay on the right track.</p>\\n<p>Follow Angeli Moeller on <a href=\"https://de.linkedin.com/in/angelimoeller\">Linked</a><a href=\"https://de.linkedin.com/in/angelimoeller\">In</a>.</p>'}]},\n",
       "  {'title': 'Open Source Cyber-Hacking and AI Autonomous Cars',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Open Source Cyber-Hacking and AI Autonomous Cars'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-insider/open-source-cyber-hacking-and-ai-autonomous-cars/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-insider/open-source-cyber-hacking-and-ai-autonomous-cars/',\n",
       "   'published': 'Tue, 15 Oct 2019 12:04:17 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=15, tm_hour=12, tm_min=4, tm_sec=17, tm_wday=1, tm_yday=288, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI Trends Insider on Autonomy',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Robotics', 'scheme': None, 'label': None},\n",
       "    {'term': 'Self Driving Cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI Trends Insider', 'scheme': None, 'label': None},\n",
       "    {'term': 'autonomous cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'robot cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'robot taxis', 'scheme': None, 'label': None},\n",
       "    {'term': 'robotics', 'scheme': None, 'label': None},\n",
       "    {'term': 'self driving cars', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18122',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider [Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/] You’ve likely had to enter a series of numbers and letters when accessing a web site that wanted “proof” that you are a human being [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider [Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/] You’ve likely had to enter a series of numbers and letters when accessing a web site that wanted “proof” that you are a human being [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Lance Eliot, the AI Trends Insider</em></p>\\n<p><em>[Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: </em><a href=\"https://forbes.com/sites/lanceeliot/\"><em>https://forbes.com/sites/lanceeliot/</em></a><em>]</em></p>\\n<p>You’ve likely had to enter a series of numbers and letters when accessing a web site that wanted “proof” that you are a human being and that you were not some kind of Internet bot. The typical approach involves your visual inspection of a grainy image that contains letters and numbers, and then having to try and figure out what those letters and numbers are.</p>\\n<p>It is intentionally made difficult due to the aspect that the letters and numbers are usually smashed together, and they are often twisted and distorted so as to be hard to discern.</p>\\n<p>These challenge-response tests are known as CAPTCHA, which is an acronym for &#8220;Completely Automated Public Turing test to tell Computers and Humans Apart.”</p>\\n<p>The idea is that if a website wants to keep automated bots from accessing their site, there needs to be some means to differentiate between whether a human is trying to access the web site or whether it is some kind of automation.</p>\\n<p>Humans are quite good at visually being able to discern letters and numbers, and so the CAPTCHA aids in distinguishing whether the response is va a human or a bot. Automated systems have a difficult time trying to ferret out amongst a twisted and distorted mix of letters and numbers the intended indication of what those distinct letters and numbers are.</p>\\n<p>Some people don’t know why the CAPTCHA is being used and are pretty much just irritated by the whole thing.</p>\\n<p>Why do I have to look at this stupid and obviously messed-up list of random letters and numbers, asks those that are not in-the-know.</p>\\n<p>Makers of web sites are at times hesitant to use the CAPTCHA because it could dissuade people from using the web site and decrease the number of potential visitors to their site. But, those pesky automated bots that might otherwise become “false” visitors, meaning that the site might believe them to be actual humans, and also there are potential adverse aspects a bot might do at a web site, and so in the end it often is worthwhile to consider making use of CAPTCHA.</p>\\n<p>Now, you might be puzzled that the CAPTCHA is not readily able to be hacked by automation.</p>\\n<p>One might assume that with the tremendous advances in Artificial Intelligence (AI) in recent times, certainly there must be a means to figure out those grainy images via automation.</p>\\n<p>Well, it depends partially on how strong the CAPTCHA is. If the CAPTCHA makes use of a varied combination of letters and numbers that are really swerved and mushed together, along with varying the height and width of the characters, and if the number of such characters is sizable enough, the ability for an AI system to figure it out is quite limited today.</p>\\n<p>Of course, the worse it is for the AI also means that it is likely harder for humans to figure out too. And, if it gets too hard for humans, you’ll have neither bots nor humans being able to pass the test. That’s not very helpful in that it will simply prevent anyone or anything from succeeding – you might as well close down your web site since it won’t be accessible at all.</p>\\n<p>To properly recognize the CAPTCHA, you need to perform at least three key visual and mental tasks:</p>\\n<p>* Recognition</p>\\n<p>You need to visually examine the image and recognize that there are letters and numbers in it.</p>\\n<p>Any of the characters can be enlarged or shrunk in size, and can be at various angles. They can be stretched or squeezed together. The parts of one character might be merged with the parts of another character. The number of variations is seemingly endless of how the CAPTCHA can obscure conventional letters and numbers.</p>\\n<p>Humans seem to be able to relatively easily handle these invariant recognition aspects, namely that we can very quickly realize the essence of a letter or number shape, in spite of the distortions made to it.</p>\\n<p>* Segmentation</p>\\n<p>If I show you a letter or number and it is displayed on a standalone basis, such as the letter “h” and the letter “e,” you have a much easier time generally of figuring it out.</p>\\n<p>On the other hand, if I merge them with other letters and numbers, such as pushing together the “he” and making each flow into the other directly, it typically becomes harder to discern. The true shape of the letter or number becomes masked by its being merged with other letters and numbers.</p>\\n<p>You need to be able to mentally disentangle the crammed together numbers and letters into a series of distinctive chunks, and within each chunk try to reconstruct what the individual letter or number might be.</p>\\n<p>* Contextual</p>\\n<p>By having multiple letters and numbers, you can often improve your odds of guessing any individual letter or number by considering the context of the characters within the overall image. That being said, many CAPTCHAs don’t use regular words, since it would make things perhaps too easy to guess the individual characters. If the letters were “d” “o” “g” and you were able to guess the first two letters, it might be overly easy to guess the third letter. If instead the letters were “d” “g” “o” then you might not so readily be able to guess the entire set of letters because it does not make into a word that you would normally recognize.</p>\\n<p>There are numerous variations nowadays of CAPTCHA algorithms.</p>\\n<p>Some use just letters and numbers, while some also add into the mix a variety of special characters such as an ampersand and a percentage symbol.</p>\\n<p>You’ve likely also encountered CAPTCHA that ask you to pick images that have something in common. For example, you are presented with six images of a grassy outdoor field, and are asked to mark the images that have a horse shown in the image. These aren’t so easy because the horse will often be obscured or only a small portion of a horse appears in any given image.</p>\\n<p>The reason why the acronym of CAPTCHA mentions a Turing test is that there is a famous test in the field of AI that was proposed by the mathematician Alan Turing about how to determine whether an automated system could exhibit intelligence.</p>\\n<p>The test consists of having a human ask questions or essentially interview another human and a separate AI system, for which the interviewer is not privy beforehand as to which is which, and if the interviewer is unable to tell the difference between the two interviewees, we presumably could declare that the automation has exhibited intelligent behavior.</p>\\n<p>There are some that are critical of this test and don’t believe it to be sufficient per se, but nonetheless it is quite famous and regarded by many as a key test for ascertaining AI.</p>\\n<p>In the case of CAPTCHA, the Turing test approach is being used to see if humans can outwit a bot that might be trying to also pass the same test.</p>\\n<p>Whomever is able to figure out the letters and numbers is considered or assumed to be a human. Thus, if the bot can indeed figure out the CAPTCHA, it momentarily has won this kind of Turing test. I think we would all agree that even if some kind of automation can succeed in winning in a CAPTCHA contest, we would be hard pressed to say that it has exhibited human intelligence. In that sense, this is a small and extremely narrow version of a Turing test and not really what we all truly intend a Turing test to be able to achieve.</p>\\n<p>In fact, because the human is having to essentially prove they are a human by passing a CAPTCHA, some refer to this test as a Reverse Turing test.</p>\\n<p>Here’s why.</p>\\n<p>The limelight of a conventional Turing test is for the automation to prove it has human-like capabilities. In this reverse Turing test, it is up to the human to prove that they are a human and able to perform better than the automation.</p>\\n<p>There is a popular CAPTCHA algorithm used as a plug-in for many WordPress developed websites that is known as “Really Simple CAPTCHA.”</p>\\n<p>In a recent article about it, a developer showed how easy it can be to develop a simple AI system to be able to succeed at cracking the CAPTCHA challenges.</p>\\n<p>The CAPTCHA in this case consisted of a string of 4 characters that used a mixture of four fonts, and it avoided using the letters “o” and “i” to reduce any confusion by the humans that have to try and figure out the CAPTCHA generated images. Notice that by these limitations it becomes a much smaller problem to be solved, in the sense that rather than say using a string of 10 characters and using 25 fonts, and by eliminating some of the letters, the solution space is a lot smaller than otherwise.</p>\\n<p>The developer wanting to crack it used the popular Python programming language, along with the OpenCV set of programs that are freely available for doing image processing, and Keras which is a deep learning program written in Python. He also used TensorFlow, which is Google’s machine learning library of programs (Keras uses TensorFlow). I mention the tools herein to be able to emphasize that the developer used off-the-shelf programming tools. He didn’t need to resort to some “dark web” secretive code to be able to proceed to crack this CAPTCHA.</p>\\n<p>The CAPTCHA program was readily available as open source and therefore the developer could inspect the code at will.</p>\\n<p>He then used the CAPTCHA to generate numerous samples of CAPTCHA images, doing so to create a set of training data. The training data consisted of each generated image and its right answer. This could then allow a pattern-matching system such as an artificial neural network to compare each image to the right answer, and then try to statistically figure out a pattern for being able to go from the seemingly inscrutable image to the desired answer.</p>\\n<p>After doing some transformations on the images, the developer fed the images into a neural network that he setup with two convolutional layers and with two hidden connected layers. According to his article, by just having ten passes through the training data set, the neural network was able to achieve full accuracy. He then tried it with actual new CAPTCHA generated by the “Really Simple CAPTCHA” code, and his efforts paid-off as it was able to figure out the letters and numbers. This particular article caught my eye due to the claim that from the start of this project to the finish it took just 15 minutes of time.</p>\\n<p>Now please keep in mind that this was a very simple kind of CAPTCHA.</p>\\n<p>I don’t want you to get a misleading impression that all CAPTCHA is as easy to crack as this.</p>\\n<p>I assure you that there are CAPTCHAs today that nobody has any kind of AI or any software that can crack it with any kind of assurance or consistency. CAPTCHA is still a relatively good means to try and distinguish between a human and a bot. The CAPTCHA just has to be tough enough to weed out the commonly used methods of cracking the CAPTCHA.\\xa0 By convention, CAPTCHA is normally made available as open source code.</p>\\n<p>Thus, some would say that it increases the chances of being able to crack it.</p>\\n<p>What does this have to do with AI self-driving driverless autonomous cars?</p>\\n<p>At the Cybernetic AI Self-Driving Car Institute, we are using open source software to develop AI self-driving systems, and so are most of the self-driving car makers and tech firms, and this is both a boon and a danger.</p>\\n<p>As discussed about the CAPTCHA algorithm, it was available as open source, meaning that the source code for it was publicly available. Anyone that wanted to look at the source code can do so.</p>\\n<p>By looking at the source code, you can figure out how it works. By figuring out how it works, you are a leg-up on being able to find ways to crack it.</p>\\n<p>If you don’t use open source code, and instead develop your own proprietary code, you can try to keep the source code secret and therefore it is much harder for someone else to figure out how it works.</p>\\n<p>If an attacker does not know how the code works, it becomes much harder to try and crack it. This does not mean it is impossible to crack it, but merely that it is likely going to be harder to crack it.</p>\\n<p>Some refer to the open source approach as a white box method, while the proprietary code approach as a black box method. With a black box method, though you know what comes into and out of it, you don’t know what is going on inside the box to do so. Meanwhile, with a white box method, you know what goes into it and comes out, along with how it is doing its magic too.</p>\\n<p>Today, open source code is prevalent and found in an estimated 95% of all computer servers, along with being used in high profile systems such as the systems that run stock exchanges and the systems that run the International Space Station. Some estimates say that there is at least 30 billion lines of open source code available, but even that number might be understated.</p>\\n<p>Notably, open source is extensively used for AI software and many of the most popular AI packages today are available as open source.</p>\\n<p>Generally, there is an ongoing debate about the use of open source as to whether it is unsafe because of the potential for nefarious hackers to be able to readily inspect the code and find ways to hack it, or whether it is maybe safer than even proprietary software because you can have so many eyes inspecting it.</p>\\n<p>Presumably, something that is open to anyone to inspect can be seen by hundreds, thousands, maybe millions of developers, and that such a large number of reviewers will ensure that the open source code is safe and sound to use.</p>\\n<p>One caveat about using open source is the classic use-it-and-forget-it aspect that arises for many developers that decide to use open source code in their own systems.</p>\\n<p>Developers will go ahead and wrap the open source into a system they are building, and pretty much move on to other things. Meanwhile, if a hole is spotted in the publicly posted open source, and if there is a fix applied to the hole, the developer that grabbed the open source at an earlier time might not be aware of the need to apply the fix in their instance. This can happen readily by the aspect that the developer forgets they used that particular open source, or maybe they don’t become aware of the fix, or they no longer have anything to do with the developed proprietary code and others that are maintaining it don’t know that it includes the open source portions.</p>\\n<p>One of the most infamous cases of open source being exploited consists of the Heartbleed computer security hole that was discovered in the OpenSSL cryptographic source code.</p>\\n<p>In OpenSSL, there is a part of the code that sends a so-called heartbeat request from one system to another system. This is an important program that is used by most web sites to ensure a secure connection, such as for doing your online banking.</p>\\n<p>When making the request, the requesting system would normally send a message of one size, let’s say 10 characters in size, and expect to get back the same message also of 10 characters in size. Turns out that if the requesting system sent a message that asked to get back 300 characters but only sent 10 characters, the system providing the response would be misled into sending back 300 characters &#8212; of which, 290 of those characters might contain something sensitive from that system inadvertently. In programming parlance, this is often referred to as a buffer over-read problem.</p>\\n<p>In 2014, this hole immediately became headline news once it was pointed out.</p>\\n<p>The significance of the hole was that it made zillions of interacting systems that were thought to be secure to potentially not be so secure.</p>\\n<p>The clever name of “heart bleed” was given to this security hole, since it is related to the heartbeat portion of the systems and was now essentially bleeding out secure info. The hole was quickly plugged, and the matter was logged into the global registry of Common Vulnerabilities and Exposures (CVE) database for everyone to know about. Nonetheless, many did not right away apply the fix to their systems, even though they should have done so.</p>\\n<p>Currently, most of the automakers and tech firms are feverishly incorporating all sorts of open source into their AI of their self-driving cars systems.</p>\\n<p>It makes sense to do so, since otherwise you would need to reinvent the wheel on all sorts of software aspects that are needed for a self-driving car.</p>\\n<p>The cost to develop that same open source from scratch would be enormous. And, it would take time, lots of time, in order to create that same code. That’s time that nobody has. Indeed, there is a madcap rush today to achieve a true self-driving car, and no one developing self-driving cars wants to be left behind due to writing code that they could otherwise easily and freely get.</p>\\n<p>We do need to ask some serious questions about this.</p>\\n<p>Does the use of open source in the AI and the other software of the self-driving cars mean that we are laying ourselves bare for a substantial and really ugly security problem down-the-road, so to speak?</p>\\n<p>Some would say, yes.</p>\\n<p>Are there nefarious hackers that are right now inspecting the self-driving car open source code and looking for exploits?</p>\\n<p>Some would say, yes.</p>\\n<p>If they are looking for exploits, there’s not much reason right now for them to reveal those holes, and so they presumably would wait until the day comes that there are enough self-driving cars on the roads to make it worthwhile to use such an exploit. Plus, once self-driving cars do become popular, it is likely to attract hackers at that time to begin inspecting the open source code, hopeful of finding some adverse “golden nugget” of a hole.</p>\\n<p>This open source conundrum exists for all aspects of self-driving cars, including:</p>\\n<ul>\\n<li>Sensors – open source software for sensor device control and use</li>\\n<li>Sensor Fusion – open source software for sensor fusion</li>\\n<li>Virtual World Model – open source software for virtual world modeling</li>\\n<li>Action Planning – open source software for creating AI action plans</li>\\n<li>Controls Activation – open source software to activate the car controls</li>\\n<li>Tactical AI – open source software for self-driving car tactical AI</li>\\n<li>Strategic AI – open source software for self-driving car strategic AI</li>\\n<li>Self-Aware AI – open source software for self-driving car self-aware AI</li>\\n</ul>\\n<p>Depending upon how a particular car maker or tech firm is building their self-driving car, each element is likely to either have open source in it, or be based upon some open source.</p>\\n<p>It is incumbent upon the self-driving car industry to realize the potential for exposures and risks due to the use of open source.</p>\\n<p>Self-driving car developers need to be make sure they are closely inspecting their open source code and not just blindly making use of it.</p>\\n<p>Any patches or fixes need to be kept on top of. We need more audits of the open source code that is being used in self-driving cars. And, overall, we need more eyeballs on reviewing the open source code that underlies self-driving cars. As mentioned earlier, it is hoped that the more “good” eyeballs involved will mean that any holes or issues will be caught and fixed before the “bad” eyeballs find them and exploit those holes.</p>\\n<p>If the bad eyeballs have their way, it will be not so much a CAPTCHA as a GOTCHA.</p>\\n<p><em>Copyright 2019 Dr. Lance Eliot </em></p>\\n<p><em>This content is originally posted on AI Trends.</em></p>\\n<p><a href=\"http://ai-selfdriving-cars.libsyn.com/website\"><img class=\"alignnone size-medium wp-image-17417\" src=\"https://www.aitrends.com/wp-content/uploads/2019/06/selfdrivingcarspodcastv2-300x150-300x150.jpg\" alt=\"\" width=\"300\" height=\"150\" /></a></p>'}]},\n",
       "  {'title': 'AI Has Changed the Game for Service Providers',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'AI Has Changed the Game for Service Providers'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-it-services/ai-has-changed-the-game-for-service-providers/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-it-services/ai-has-changed-the-game-for-service-providers/',\n",
       "   'published': 'Thu, 10 Oct 2019 21:30:43 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=10, tm_hour=21, tm_min=30, tm_sec=43, tm_wday=3, tm_yday=283, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI and Business Strategy',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'AI and IT Services', 'scheme': None, 'label': None},\n",
       "    {'term': 'Software Development', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI and business strategy', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI and IT services', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI application deployment', 'scheme': None, 'label': None},\n",
       "    {'term': 'data science', 'scheme': None, 'label': None},\n",
       "    {'term': 'software development', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18108',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By John P. Desmond, AI Trends Editor AI has changed the game for service providers. Client companies now expect the service provider will deliver on the promise of AI for them, or help them get moving in the right direction. We spoke about trends in AI and services to executives of two service providers recently: [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By John P. Desmond, AI Trends Editor AI has changed the game for service providers. Client companies now expect the service provider will deliver on the promise of AI for them, or help them get moving in the right direction. We spoke about trends in AI and services to executives of two service providers recently: [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By John P. Desmond, AI Trends Editor</em></p>\\n<p>AI has changed the game for service providers. Client companies now expect the service provider will deliver on the promise of AI for them, or help them get moving in the right direction. We spoke about trends in AI and services to executives of two service providers recently: Asheesh Mehra, co-founder and CEO of AntWorks; and Prabhdeep (PD) Singh, VP of AI at UiPath.</p>\\n<p>AntWorks, founded in 2015, is an AI and intelligent automation company, with a platform that understands every data type. The company digitizes every bit of information from a wide range of industries. Mehra is co-founder and group CEO; his background includes seven years at Infosys working in business process outsourcing in Asia Pacific, Japan, and the Middle East. The company offers the ANTstein intelligent automation. It supports robotic process automation support, intuitive machine learning, and natural language modeling capabilities.</p>\\n<p>UiPath of New York City is an AI enterprise software company known for AI, machine learning, and Robotic Process Automation. The company was recently positioned in the upper right Leaders quadrant in Gartner Magic Quadrant for Robotic Process Automation Software.\\xa0 Prabhdeep (PD) Singh, VP of AI at UiPath, was at Microsoft for nearly 10 years before coming to UiPath a year ago. He led the product and business teams for the Microsoft Sales Intelligence AI solution.</p>\\n<p>Mehra and Singh were interviewed separately by AI Trends Editor John P. Desmond.</p>\\n<p><strong>How has AI changed the game for service providers?</strong></p>\\n<p><strong>Asheesh Mehra, co-founder and CEO of AntWorks</strong>: Some customers expect AI to be a magic wand that can start delivering results overnight. However, an AI engine is not magic. It needs training at the back end before it can start performing an action. It can start learning from the representative data set that is received over a few months. Then it can start its machine learning capability to help make intelligent decisions, or start predicting or inferring dependent of the representative data set it has seen over the months it has been deployed at an enterprise.</p>\\n<p>So, is it changing expectations of customers? The answer is absolutely, yes. Some expectations are realistic, and some expectations are unrealistic. Is it impacting the end customer of enterprises? It is. In some ways it&#8217;s impacting them by making their lives, their day-to-day jobs a lot easier because it is now a helping hand, or a joint force with the human. When you put both together, you get a far superior outcome.</p>\\n<figure id=\"attachment_18146\" style=\"width: 198px\" class=\"wp-caption alignleft\"><img class=\" wp-image-18146\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AshofAntWorks-2.jpg\" alt=\"\" width=\"198\" height=\"297\" /><figcaption class=\"wp-caption-text\">Asheesh Mehra, co-founder and CEO, AntWorks</figcaption></figure>\\n<p><strong>Prabhdeep (PD) Singh, VP of AI at UiPath: </strong>The way the older service providers would typically solve business problems would be to have a human sitting in some back room doing this stuff for you manually. But now the automation has reached a stage—and the set of technologies that are available to us have reached a stage—where you can optimize pretty much every and any business process. If you remember, the name of the game for these BPO [Business Process Outsourcing] providers was to get down the cost. That&#8217;s why you couldn&#8217;t run call centers here in the US, because the cost of employing humans was just too high.</p>\\n<p>That&#8217;s when people started going to places like India, Vietnam, and all these other places where you had English-speaking populations, but it was much cheaper to hire people. It was more of this cost optimization, cost-cutting exercise. With AI and automation coming in, there is a paradigm shift happening in the sense that you can actually increase the productivity of those humans and drive down the costs even more. We talk about this in almost every conference that I&#8217;ve gone to. If you look at the workforce productivity for the US over the last decade, it has pretty much plateaued. After we had a saturation of PCs, pretty much for all and every knowledge worker. And now in order to increase the productivity of those information workers in the workforce, you need more of AI and automation. We are seeing that, and many of our customers are getting monetary and productivity gains by automating and deploying AI in their business processes.</p>\\n<p><strong>Is AI delivering?</strong></p>\\n<p><strong>Mehra of AntWorks</strong>: That&#8217;s a very loaded and very difficult question to answer. Yes, it&#8217;s delivering in certain spaces and in certain areas. I think AI is over-hyped and not delivering in certain other cases. If I had to use an example from the insurance world, I think AI is delivering on its promise for processing claims, being for your health, or your house, or your car. It is delivering there. There is room for AI to be improved and enhanced to deliver the outcome it is promising in some other industries, such as financial services.</p>\\n<p>If I was to summarize that, I&#8217;d put the bar right in the center and say depending on the use case and depending on the industry segment, AI is delivering; and for where AI is not delivering, it has not been exposed and trained enough in those spaces.</p>\\n<p><strong>Singh of UiPath</strong>: When AI works, it&#8217;s magical. I&#8217;ve seen it work in both large companies and small startups. I&#8217;ve seen it save lives. I worked on systems that can do things like readmission prediction. It can predict if a patient is going to come back within 30 days, and the doctors can look at it and say, &#8220;Okay, let&#8217;s not discharge this patient right now.&#8221; If you have a system like that, you&#8217;re actually saving lives, because you&#8217;re not sending really sick patients home where adverse things can happen to them. You&#8217;re also saving money, because if you look at the Medicare/Medicaid guidelines, if the patient comes back within 30 days, the government is not going to reimburse you for the readmission.</p>\\n<figure id=\"attachment_18110\" style=\"width: 200px\" class=\"wp-caption alignright\"><img class=\"size-full wp-image-18110\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/9-10PDSingh-2.jpg\" alt=\"\" width=\"200\" height=\"200\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/9-10PDSingh-2.jpg 200w, https://www.aitrends.com/wp-content/uploads/2019/10/9-10PDSingh-2-120x120.jpg 120w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><figcaption class=\"wp-caption-text\">Prabhdeep (PD) Singh, VP of AI at UiPath</figcaption></figure>\\n<p>The problem right now in the AI industry is what we call the last mile problem. If you look at the AI deployments, only 4% of CIOs have put something in production. Almost 90% to 95% of CIOs want to do something with AI. They know kind of where AI can be useful. Actually putting a system into production is a completely different beast. So once you have a machine learning model that works, you need to put it into production, have it interact with humans, with the existing applications. That&#8217;s where RPA [Robotic Process Automation] is useful, because RPA is the last mile vehicle for all things AI.</p>\\n<p><strong>Are there problems for which AI is not a fit?</strong></p>\\n<p><strong>Mehra of AntWorks:</strong> If you take a step back and ask what is AI, the definition varies. In my view, AI is all about learning and then a machine taking intelligent decisions or providing accurate predictions on the data that it has received. Do we say, &#8220;No&#8221; to customers when we think we or the AI is not equipped? The answer is absolutely, yes. We do say, &#8220;No&#8221; to customers when we think we cannot deliver a particular piece using our machine learning or other algorithms. Because as I said, the expectation might be that AI is a magic wand.</p>\\n<p>The fundamental philosophy at AntWorks is, &#8220;Say no where you have to say it. When you say &#8216;yes&#8217;, get it right the first time.&#8221;</p>\\n<p>Can AI be deployed in every single use case in an enterprise? The answer is no. I don&#8217;t think AI is mature enough to go out there and solve every kind of challenge today that an enterprise experiences. We see a lot of room for the AI engines to be trained to become smarter and more intelligent to deliver to customer expectations.</p>\\n<p><strong>Singh of UiPath: </strong>I will say, the things that are non-digitized are problems that you cannot optimize with AI. You see many AI use cases in sales and marketing, because sales and marketing is highly digital. If an industry has gone through digital transformation, that&#8217;s where AI can be very useful. But if you have antiquated processes, and you actually never digitized, then it&#8217;s a little difficult. For example, if there was a company doing everything paper-based and old school very well, the first process is to get that paper scanned and put it in digital format before you can apply anything intelligent on top of that information.</p>\\n<p><strong>Do AI engagements take more time than the former non-AI way of solving problems?</strong></p>\\n<p><strong>Mehra of AntWorks: </strong>No, absolutely not. One of the whole drivers to make a business case positive is to cut the time it takes to do projects. The whole objective is to speed up the business process and to ensure that accuracy is a lot higher. So does it take more time? The answer is no. If it does take more time, it&#8217;s probably taking a lot more time because not enough training has been done for the engine and it has been deployed prematurely.</p>\\n<p>No different to when you bring a human being into an enterprise, the first four weeks of them coming in or the first three weeks or the first six weeks, is to train that individual on how to perform their job, or how to deliver that outcome. An AI engine is no different. If you expect an AI engine to start delivering the results that you&#8217;re expecting without spending enough time on training the engine, it will not deliver for you.</p>\\n<p>So the marketplace needs to understand how to make your AI or machine learning engine deliver results for you. There are no shortcuts. You need to invest the right amount of time and expose the AI engine to the right amount of representative data for it to deliver results for you.</p>\\n<p><strong>Singh of UiPath: </strong>\\xa0I would say no. If you planned your system correctly, it&#8217;s much easier to solve problems and much more effective to solve problems with AI versus the older way. For example, if you remember the old school real estate agents, there were good agents and there were bad agents. The really good sales people didn&#8217;t need any of these electronic nannies and electronic aids like CRM systems. They were just going in, doing it the old school way, pounding the pavement, being really good at selling stuff.</p>\\n<p>My point is if you have a problem which is highly dependent on human expertise, it will take time to have AI go in and improve it. But if there is a process where you are not realizing the human efficiencies to the maximum, that is where AI can make a big difference.</p>\\n<p><strong>What are your challenges?</strong></p>\\n<p><strong>Mehra of AntWorks: </strong>I have a few challenges today. One of my first challenges is market share. I&#8217;m a four year old company. I&#8217;m against all the names from a competition perspective. They&#8217;ve all been around for longer, have captured a large market share and I&#8217;m playing catch up. So we took time to build the technology and the whole platform out while they were out there selling single technology tool sets. So now it&#8217;s my turn to capture market share.</p>\\n<p>My second challenge is that the understanding level of the buyer varies to a large extent. On a scale of one to 10, a very large percentage of buyers are at three and below. There is a very small percentage of buyers that are in the seven, eight, nine, and 10, from a rating perspective. That starts becoming a challenge because the expectations that they have, and what reality is are a vast distance apart. So we need to deploy larger resources to help educate the marketplace.</p>\\n<p>The third challenge is around the expectation of what AI is. There is just so much hype and white noise in this whole AI space right now. This puts pressure on you as a product company because people dream up things and it becomes a challenge. The minute you start pushing back, and say, &#8220;That&#8217;s not really what we can deliver, or a machine can deploy&#8221;, you start creating a sense of dissatisfaction in the buyer community. But you are being realistic. So, that truly is another challenge for me. Those are the three challenges for me today.</p>\\n<p><strong>Singh of UiPath: </strong>Once you start deploying these systems in an enterprise at a very large scale, a couple of things happen. Enterprise software is a very well-understood area. The people who deploy software and applications in their enterprise, with traditional software applications, have a very well-understood product. With AI applications, it&#8217;s not just a matter of deploying software. AI models work off of data. The data must be clean, the data pipelines need to run properly, and the AI models need to work well. That whole vision is our principle. If, for example, the data shuts off at the input, the model starts behaving completely differently. For example, I had this vision readmission model, and it uses a patient feed which was giving it the economic data of the patient. And so we know that people who are low income patients, they have a higher risk of readmissions, and also if you&#8217;re not getting that feed, the model won&#8217;t be confident enough in making these predictions. It might go completely haywire. So scaling AI is a big challenge.</p>\\n<p>We have a discipline called DevOps to address the way traditional software is handled in the enterprise. What we need is a DevOps equivalent for AI. We in the industry call it MLOps, or machine learning ops. It&#8217;s basically the discipline around practices to manage, deploy, and create these models in a structured way. One of the offerings in our product, AI Fabric, is an MLOps system for the data scientists, who might not really understand enterprise software deployment cycles. We simplify it for them. We say, &#8220;You just create a model, the rest of the stuff on the deployment, DevOps, MLOps side, we will take care of.&#8221; So deploying AI applications in the real world we have seen as a challenge.</p>\\n<p>The third challenge, I would say, is the ROI quantification. The business owner needs to know the impact of putting the machine learning model into production. Is it hurting or improving the overall business? You need a system which can quantify the return on investment when you&#8217;re deploying AI. Typically, you would use BI tools for this. We are working on having an embedded analytics or BI offering, to give customers this ROI visibility. You need that quantification system in place.</p>\\n<p><strong>What does the future hold for your company and for AI in business? Where is it going?</strong></p>\\n<p><strong>Mehra of AntWorks: </strong>John, we&#8217;re super excited. I&#8217;m speaking to you today from a delivery center in Bengal. I&#8217;ve just spent the whole day sitting next to my developers, talking to my product leads and the head of my product, and it&#8217;s just super exciting. It scares me when I look at possibilities that are in store for us over the next six, 12, and 24 months, and just what machines can do if trained correctly or if deployed correctly. I&#8217;m super excited about the next two years also. We&#8217;ve grown more than 350% in the last quarter and a half.</p>\\n<p>I did a Town Hall [in India] this afternoon and the last time I was here a quarter ago, I had, I think, 40 people. Today I addressed 165 people. I&#8217;m hiring people to support customer demand.\\xa0 So, there is a huge amount of potential and growth. Over the next 12-24 months, we are looking at dramatic growth. Automation and AI are in the top three agenda items of every Fortune 500 board today. We are addressing that challenge for those organizations.</p>\\n<p>While there is a huge opportunity, all the organizations in this space need to be responsible to not over commit and under deliver, because that will start taking away the belief in what AI machine learning and automation can do.</p>\\n<p><strong>Singh of UiPath: </strong>I&#8217;ll be honest with you, where we stand right now as a company, as an industry, I see a whole tsunami coming our way. It&#8217;s not a bad tsunami; it&#8217;s a good one. Right now, most of these enterprises, they&#8217;ve just gone through digital transformation. They&#8217;re putting all these new-fangled systems in place. You have Salesforce for your sales system. You have Microsoft office. You have different cloud applications that you put in production. I can name you many companies, for example oil companies, they have completely digitized processes now, for even things like drilling reports. CPG [consumer packaged goods] companies who have digital processes for designing the labels that go on to their products. They also have inventory management systems and logistics management systems.</p>\\n<p>They&#8217;ve just put these systems in place. The next thing, or the next ROI that they want to get out of the digital transformation, is to try machine learning and some automation. They want to try putting AI in some of these processes, to inject some automation and AI, to see if they can make them more efficient. I would say in the post-digital transformation era, the future for RPA and AI looks really great. These will be the technologies that are at the cutting edge of this post-digital transformation age.</p>\\n<p>Learn more at <a href=\"https://www.ant.works/\">AntWorks </a>and at <a href=\"https://www.uipath.com/\">UiPath</a>.</p>'}]},\n",
       "  {'title': 'Advanced Car Safety Systems Using AI Delivering for Motorists Today',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Advanced Car Safety Systems Using AI Delivering for Motorists Today'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-in-business/advanced-car-safety-systems-using-ai-delivering-for-motorists-today/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-in-business/advanced-car-safety-systems-using-ai-delivering-for-motorists-today/',\n",
       "   'published': 'Thu, 10 Oct 2019 21:30:39 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=10, tm_hour=21, tm_min=30, tm_sec=39, tm_wday=3, tm_yday=283, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI in Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI in Industry', 'scheme': None, 'label': None},\n",
       "    {'term': 'Self Driving Cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'ai in business', 'scheme': None, 'label': None},\n",
       "    {'term': 'cloud services', 'scheme': None, 'label': None},\n",
       "    {'term': 'predictive maintenance', 'scheme': None, 'label': None},\n",
       "    {'term': 'self driving cars', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18119',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff Advanced safety systems using AI are being delivered in cars today, whether the customer asks for them or not. This is big business, with the value of AI in automotive manufacturing and cloud services projected to exceed $10.7 billion by 2024. Reaction to the new systems from the auto consumer public [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff Advanced safety systems using AI are being delivered in cars today, whether the customer asks for them or not. This is big business, with the value of AI in automotive manufacturing and cloud services projected to exceed $10.7 billion by 2024. Reaction to the new systems from the auto consumer public [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By AI Trends Staff</em></p>\\n<p>Advanced safety systems using AI are being delivered in cars today, whether the customer asks for them or not. This is big business, with the value of AI in automotive manufacturing and cloud services projected to exceed $10.7 billion by 2024.</p>\\n<p>Reaction to the new systems from the auto consumer public is mostly positive based on reactions seen so far.</p>\\n<p>When a deer jumped in front of a 2017 Subaru Outback being driven in Skokie, Ill, recently, the vehicle came to a complete stop on its own, before the driver could react, according to an account in <a href=\"https://www.consumerreports.org/automotive-technology/car-safety-systems-that-could-save-your-life/\">Consumer Reports</a>, based on a survey of Advanced Driver Assistance Systems (ADAS). &#8220;Without the car&#8217;s automatic emergency braking system, I&#8217;d have hit the deer, no question about it,&#8221; the driver said.</p>\\n<p>Consumer Reports readers were asked about their experiences with ADAS in their vehicles, including forward collision warning (FCW), automatic emergency braking (AEB) and blind spot warning (BSW). Some 57% of respondents reported at least one ADAS feature had prevented them from getting into a crash. The respondents provided data on some 72,000 vehicles.</p>\\n<p>ADAS systems have increased substantially in the last 10 years in cars sold in the US, starting with FCW and AEB, then extending to BSW, lane departure warning (LDW), lane keeping assist (LKA) and more recently, pedestrian detection systems (PDS).</p>\\n<p>Jake Fisher, senior director of auto testing for Consumer Reports, was quoted as saying, &#8220;Our survey results show that in the real world, these systems are creating positive outcomes in situations that only a few short years ago would have ended in costly and tragic results.&#8221;</p>\\n<p>Manufacturers vary on the ADAS features included in new cars, whether they charge extra for them or supply them as standard equipment.</p>\\n<p>Survey respondents had the highest satisfaction with AEB, adaptive cruise control (ACC), and BSW. Respondents were least satisfied with lane-keeping features, owing to &#8220;annoying&#8221; alert chimes, vibrations, or aggressive steering corrections. The dissatisfaction led owners to disable those features more frequently than others.</p>\\n<p>BSW was the feature that drivers credited with most often keeping them out of a crash; 60% said BSW had prevented a collision.</p>\\n<p><strong>General Motors Research with U of Michigan</strong></p>\\n<p>General Motors conducted research on ADAS features with the University of Michigan Transportation Research Institute, that showed several of the features are helping to reduce car crashes in a statistically significant way, according to an account in <a href=\"https://www.greencarcongress.com/driver-assistance-systems/\">Green Car Congress</a>.</p>\\n<p>The study included 3.7 million GM vehicles across 20 different models from 2013 to 2017. Some 15 different ADAS systems were evaluated using police report crash databases from 10 states.</p>\\n<p>Among the findings:</p>\\n<ul>\\n<li>Automatic Emergency Braking (or Forward Automatic Braking) with Forward Collision Alert reduced rear-end striking crashes by 46%.</li>\\n<li>Lane Keep Assist with Lane Departure Warning reduced lane departure-related crashes by 20%.</li>\\n<li>Lane Change Alert with Side Blind Zone Alert reduced lane change crashes by 26%.</li>\\n<li>Rear Vision Camera alone, Rear Park Assist functionality, Rear Cross Traffic Alert (which nearly always includes the two previous backing features) and Reverse Automatic Braking (which includes all the previous backing features) produced, respectively, an estimated 21%, 38%, 52%, and an 81% reduction in backing crashes.</li>\\n<li>IntelliBeam and High-Intensity Discharge headlight features provided 35% and 21% reductions, respectively, in nighttime pedestrian/bicyclist/animal crashes, with a 49% reduction when offered together.</li>\\n</ul>\\n<p>&#8220;The results show that the GM active safety systems evaluated are addressing a wide range of common crashes that cause a staggering amount of injuries, property damage and cost to our customers and society, putting GM well on its way toward a vision of zero crashes,&#8221; said Raymond Kiefer, GM Safety Technical Fellow.</p>\\n<p><strong>Predictive Maintenance, Driver Recognition Coming</strong></p>\\n<p>Related benefits to drivers from AI plugging into the auto world include better ability to do predictive maintenance. Volkswagen and Microsoft announced in October 2018 a partnership to tap the power of Azure IoT, PowerBI and Skype to gather data that could indicate a pending component failure, long before the failure actually happens, according to an account on a blog from <a href=\"https://igniteoutsourcing.com/automotive/artificial-intelligence-in-automotive-industry/\">Ignite</a>, an automotive and AI service provider. Plans are for all vehicles to receive Over the Air (OTA) software updates as well.</p>\\n<p>Driver recognition systems are also making headway. An Israeli automotive computer vision startup, eyeSight, uses AI and deep learning in cameras and sensors that monitor driver behavior. This includes observations of eye gaze, eye openness, and head position. The system can alert the driver to keep eyes on the road, and attempt to wake up the driver if necessary. Contextual controls allow eyeSight to tailor the content of a Heads-Up-Display according to where the driver&#8217;s eyes are focused. Upper body detection reflects the driver&#8217;s posture.</p>\\n<p>Read the source accounts in <a href=\"https://www.consumerreports.org/automotive-technology/car-safety-systems-that-could-save-your-life/\">Consumer Reports</a>, <a href=\"https://www.greencarcongress.com/driver-assistance-systems/\">Green Car Congress</a> and at\\xa0 <a href=\"https://igniteoutsourcing.com/automotive/artificial-intelligence-in-automotive-industry/\">Ignite</a>.</p>'}]},\n",
       "  {'title': 'New AI Model Predicts Clinical Translation Of Biomedical Research',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'New AI Model Predicts Clinical Translation Of Biomedical Research'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/healthcare/new-ai-model-predicts-clinical-translation-of-biomedical-research/'}],\n",
       "   'link': 'https://www.aitrends.com/healthcare/new-ai-model-predicts-clinical-translation-of-biomedical-research/',\n",
       "   'published': 'Thu, 10 Oct 2019 21:30:29 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=10, tm_hour=21, tm_min=30, tm_sec=29, tm_wday=3, tm_yday=283, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'Health Care', 'scheme': None, 'label': None},\n",
       "    {'term': 'Machine Learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'Predictive Analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI in healthcare', 'scheme': None, 'label': None},\n",
       "    {'term': 'data analysis', 'scheme': None, 'label': None},\n",
       "    {'term': 'health care', 'scheme': None, 'label': None},\n",
       "    {'term': 'machine learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'predictive analytics', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18116',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Benjamin Ross, Editor, AI Trends The US National Institutes of Health (NIH)&#8217;s Office of Portfolio Analysis (OPA) has developed a machine learning model that predicts whether a scientific advance is likely to translate to the clinic. The model, described in a recent study published in PLOS Biology (DOI:https://doi.org/10.1371/journal.pbio.3000416), determines the likelihood that a research [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Benjamin Ross, Editor, AI Trends The US National Institutes of Health (NIH)&#8217;s Office of Portfolio Analysis (OPA) has developed a machine learning model that predicts whether a scientific advance is likely to translate to the clinic. The model, described in a recent study published in PLOS Biology (DOI:https://doi.org/10.1371/journal.pbio.3000416), determines the likelihood that a research [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Benjamin Ross, Editor, AI Trends</em></p>\\n<p>The US National Institutes of Health (NIH)&#8217;s Office of Portfolio Analysis (OPA) has developed a machine learning model that predicts whether a scientific advance is likely to translate to the clinic. The model, described in a recent study published in <em>PLOS Biology</em> (DOI:https://doi.org/10.1371/journal.pbio.3000416), determines the likelihood that a research article will be cited by a future clinical trial or guideline, which OPA labels as early indicators of translational progress.</p>\\n<p>Developed by OPA Director George Santangelo and colleagues, the model qualifies predictions using a novel metric called &#8220;Approximate Potential to Translate&#8221; (APT). &#8220;We found that distinct knowledge flow trajectories are linked to papers that either succeed or fail to influence clinical research,&#8221; the study&#8217;s authors write. &#8220;Translational progress in biomedicine can therefore be assessed and predicted&#8230; based on information conveyed by the scientific community&#8217;s early reaction to a paper.&#8221;</p>\\n<p>The development of APT values comes as the NIH launches the second version of its <em>iCite</em> tool, a web application that provides a panel of bibliometric information for journal publications within a defined analysis group. The APT values will be freely and publicly available as new components of <em>iCite</em>.</p>\\n<p>Clinical research is a long, arduous process, the authors say, possibly taking decades for a discovery to translate into improvements in human health. This presents challenges when assessing and guiding the translation of the bench-to-bedside process.</p>\\n<p>Santangelo tells <em>AI Trends</em> that machine learning presented an opportunity to get a better read on the likelihood that papers would move into the clinic.</p>\\n<p>&#8220;The work started to develop in terms of seeing if we could find a method that would give us an earlier read on what to expect from different parts of the biomedical research landscape in terms of citation by clinical trials or guidelines as evidence that things were moving into the clinic.&#8221;</p>\\n<p>As the team began to apply their APT values to existing data, Santangelo says nuanced patterns began to emerge as key predictors for translational progress.</p>\\n<p>&#8220;I think the most important one that we focus on is the diversity of interest from across the fundamental to clinical research axis,&#8221; he says. &#8220;When people across that axis — from fundamental scientists often in the same field as the work that&#8217;s being published, all the way to people in the clinic — show an interest in the form of citations in those papers, then the likelihood of eventual citation by a clinical trial or guideline is quite high.&#8221;</p>\\n<p>These indicators have proven to be effective, Santangelo and his colleagues argue, writing that &#8220;as little as 2 years [post publication] data yield accurate predictions about a paper&#8217;s eventual citation by a clinical article.&#8221;</p>\\n<p>&#8220;We can now get a sense of what&#8217;s happening in the literature without as dramatic a censoring effect [a condition in which the value of a measurement is only partially known], which allows us to be more forward looking in understanding what areas of research are more likely to draw interest from clinically-focused scientists,&#8221; Santangelo says.</p>\\n<p><strong>Breaking Down The Paywall</strong></p>\\n<p>In addition to APT values, the <em>iCite</em> webtool will offer the NIH&#8217;s Open Citation Collection (NIH-OCC), a free public access database for biomedical research. The database currently comprises over 420 million citation links, with additional citations accumulating monthly.</p>\\n<p>Santangelo says the database offers a solution to proprietary, restrictive, and often costly licensing agreements that have been a barrier to collaborative research.</p>\\n<p>&#8220;These days there really isn&#8217;t a good justification for keeping [this data] behind a paywall, especially with the issues of data quality,&#8221; says Santangelo. &#8220;We recognized early on that, if we were publishing something, we were using a proprietary source for the raw data, and that others would not be able to calculate the values without working with us on a subset of the data. That never sat easy with us.&#8221;</p>\\n<p>The NIH-OCC offers researchers the chance to access the raw data. &#8220;There&#8217;s no better check on data quality than that,&#8221; Santangelo says.</p>\\n<p>In a Community Page article in <em>PLOS Biology</em> (DOI:https://doi.org/10.1371/journal.pbio.3000385), Santangelo and his co-authors say the NIH-OCC dataset has been generated from unrestricted data sources such as MedLine, PubMed Central, and CrossRef, as well as &#8220;data from a machine learning pipeline that identifies, extracts, resolves, and disambiguates authors in references from full-text articles available on the internet.&#8221;</p>\\n<p>Santangelo says there&#8217;s a standing invitation for data sharing. &#8220;We&#8217;re data sponges,&#8221; he says. &#8220;We&#8217;ll take data from wherever we can find it.&#8221;</p>\\n<p>Learn more at <a href=\"https://dpcpsi.nih.gov/opa\">Office of Portfolio Analysis.</a></p>'}]},\n",
       "  {'title': 'Robust Ugly Zone Scenarios For AI Autonomous Cars',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Robust Ugly Zone Scenarios For AI Autonomous Cars'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://www.aitrends.com/ai-insider/robust-ugly-zone-scenarios-for-ai-autonomous-cars/'}],\n",
       "   'link': 'https://www.aitrends.com/ai-insider/robust-ugly-zone-scenarios-for-ai-autonomous-cars/',\n",
       "   'published': 'Thu, 10 Oct 2019 21:30:27 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=10, tm_hour=21, tm_min=30, tm_sec=27, tm_wday=3, tm_yday=283, tm_isdst=0),\n",
       "   'authors': [{'name': 'Benjamin Ross'}],\n",
       "   'author': 'Benjamin Ross',\n",
       "   'author_detail': {'name': 'Benjamin Ross'},\n",
       "   'tags': [{'term': 'AI Trends Insider on Autonomy',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Robotics', 'scheme': None, 'label': None},\n",
       "    {'term': 'Self Driving Cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI Trends Insider', 'scheme': None, 'label': None},\n",
       "    {'term': 'autonomous cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'robot cars', 'scheme': None, 'label': None},\n",
       "    {'term': 'robot taxis', 'scheme': None, 'label': None},\n",
       "    {'term': 'robotics', 'scheme': None, 'label': None},\n",
       "    {'term': 'self driving cars', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://www.aitrends.com/?p=18113',\n",
       "   'guidislink': False,\n",
       "   'summary': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider Is he a man or a machine? That was asked about Francesco Molinari when he won the 2018 Open Golf Championship and earned himself nearly $2 million in prize money. It was his first major golf victory and it was the first time that the now 147th annual [&#8230;]',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider Is he a man or a machine? That was asked about Francesco Molinari when he won the 2018 Open Golf Championship and earned himself nearly $2 million in prize money. It was his first major golf victory and it was the first time that the now 147th annual [&#8230;]'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Lance Eliot, the AI Trends Insider</em></p>\\n<p>Is he a man or a machine?</p>\\n<p>That was asked about Francesco Molinari when he won the 2018 Open Golf Championship and earned himself nearly $2 million in prize money.</p>\\n<p>It was his first major golf victory and it was the first time that the now 147<sup>th</sup> annual golf tournament was won by an Italian (there was a lot of celebrating in Italy!).</p>\\n<p>How did he achieve the win?</p>\\n<p>You could say that it was years upon years of other golf competitions and smaller wins that led to this big win.</p>\\n<p>Or, you could say it was maybe the weather conditions and the mood and skills of the other golfers at the tournament that converged to let him be the best on that particular occasion.</p>\\n<p>Presumably, you could say it was random chance, or maybe that he had a lucky charm.</p>\\n<p>Would you be willing to say it was due to practice?</p>\\n<p>As they famous joke goes, how do you get to Carnegie Hall – via practice, practice, practice.</p>\\n<p>Francesco is known for being a slave to practicing.</p>\\n<p>Of course, the odds are that many of the other golfers there had put in as many hours practicing as he has. It stands to reason that golfers at that level of play are practicing all of the time, day and night. They likely dream about golf. They likely are mentally playing golf when they eat lunch or dinner. It&#8217;s an all-consuming passion for most of them.</p>\\n<p>If they are all practicing about the same amount of the time, perhaps the nature of how they practice might account for some of the differences in their playing levels. Just because I say that I practice, it doesn&#8217;t indicate in what manner I practice. For almost any kind of practices, you can take a varied approach to how you practice.</p>\\n<p>I used to play tennis when I was in college. My practices often involved hitting tennis balls against a wall for hours on end. When I could find someone to play against, I&#8217;d certainly do a practice game, but at other times it was solo practicing that took place. Is the potential outcome of the solo practicing as good as doing actual practice games? You can debate the matter. The practice games are certainly more akin to what will occur when playing a match game, and so it seems logical that the practice game is a better form of practice. On the other hand, the repetition of hitting hundreds of times back-and-forth against a wall does build-up your arm and body in a manner that a practice game cannot.</p>\\n<p>Francesco realized about two years ago that he needed to do something to boost his golf game.</p>\\n<p>He had been a professional golfer for more than a dozen years and had been an amateur champion before turning pro. But, he had not yet reached the top echelon of the winner&#8217;s circle of professional players. Would it take some kind of voodoo magic to push him to the top? Did he have to make changes to how he perceived golf and played golf.</p>\\n<p>He opted to radically change his practice routines.</p>\\n<p>He entered into the ugly zone.</p>\\n<p><strong>Introducing The Notion Of An Ugly Zone</strong></p>\\n<p>For those of you familiar with the Twilight Zone (the old TV series), I suppose the ugly zone sounds somewhat like it.</p>\\n<p>There&#8217;s nothing especially odd about the ugly zone though. The concept is relatively straightforward.</p>\\n<p>When practicing any kind of skill, you are to do so with a maximum amount of pressure, perhaps even more so than what you&#8217;ll experience during live competition play.</p>\\n<p>The goal is to make practices as rough and tough as a real match.</p>\\n<p>Maybe even more so.</p>\\n<p>When I used to help coach my son&#8217;s Little League baseball team, we often had rather acrimonious debates among the coaches and assistant coaches about whether the practices should be easy or hard.</p>\\n<p>There were some coaches that said we should be easy on the kids and provide a supportive environment for them to learn baseball and hone their skills. It was about fun. It was about falling in love with the sport. We knew in contrast that the actual games would be pressure cookers, so the practices would hopefully serve as a means to inspire them towards becoming proficient baseball players.</p>\\n<p>If you&#8217;ve not been to a Little League baseball game, allow me to open your eyes. You&#8217;ve got the doting parents that want their kids to win no matter what it takes. Many hope that their child will someday become a big league player, getting the fat paychecks and the out sized fame.</p>\\n<p>Some of the eager parents had a different but similarly high pressure perspective, namely they thought that winning was the key to life, and they didn&#8217;t care that it was a baseball game per se. Instead, it was that their child needed to discover that winning is good and losing is bad.</p>\\n<p>It wasn&#8217;t so important that the child was able to swing a bat &#8212; what was really paramount was that you must win however you can achieve it – this includes maybe swinging a bat, or catching a fly ball, or tricking the opposing team, screaming at the other team, spitting on the other team, you name it (all&#8217;s fair in love and war, and baseball).</p>\\n<p>Should the practices be like the games?</p>\\n<p>Would it be better to have the boys experience the crazed high pressures of a real game during their practices, or would that distract them from the needed step-at-a-time of learning their craft?</p>\\n<p>Maybe doing high pressure practices would make them emotionally upset and they would become disgruntled about playing the sport entirely. They&#8217;d also have no opportunity to try out new techniques. They&#8217;d be constantly under the gun, so to speak.</p>\\n<p>You&#8217;ll find this next anecdote amusing (or, maybe serious!).</p>\\n<p>One of the coaches suggested that we setup loudspeakers at practice that would blare out the sounds of a typical game audience, including a recorded cacophony of loudmouthed spectators yelling and screaming, doing so during the practices (side note, we opted to not do that). This would help re-create the setting of actual games, apparently.</p>\\n<p>Anyway, there are some that philosophically believe that practices need to be conducted in a high pressure manner that aligns with the pressures encountered during competitive matches.</p>\\n<p>Of course, maybe doing this with Little League kids is not the right audience. Perhaps we might say that this approach is more suitable to adults. Furthermore, adults that are already versed in their craft, rather than someone just starting out to gain a new skill.</p>\\n<p>Well, I realize that some of you that believe in the ugly zone approach will maybe disagree with me and my list of carve out exceptions, and you&#8217;ll insist that the ugly zone is always applicable, regardless of age, skill level, etc.</p>\\n<p>Fine, have it your way.</p>\\n<p>Let&#8217;s agree to disagree, and continue on, thanks.</p>\\n<p><strong>Desirable Difficulty Is King</strong></p>\\n<p>Francesco shifted his practices two years prior to his incredible win into becoming near torture tests.</p>\\n<p>His new coach embodied the ugly zone philosophy and emphasized that the frustration level had to be equal to a real game or possibly higher than a real game.</p>\\n<p>The more annoyed that Francesco became with his coach, the more the coach knew he was doing something right in terms of making practices hard. Every practice golf shot was considered vital. No more of the traditional hitting golf balls with your clubs for mindless hours on end. Instead, all sorts of complicated shots and series of shots were devised for practices.</p>\\n<p>There you are on the putting green, practicing. You are 8 feet away from the hole. You try to make the putt, but miss the hole. It&#8217;s practice, so you just shrug your shoulders, you try to figure out what went wrong, and you then casually setup to do the same shot again. Not so with the ugly zone. That 8-foot putt is for the golden trophy, every time. If you miss the hole, you are done for. You are a failure. You must take each and every putt with somber seriousness. If you happen to make the putt the first time, that&#8217;s not good enough. Do it again. Indeed, do it five times in a row, flawlessly.</p>\\n<p>Some psychologists suggest that adding challenges to practices tends to boost the long-term impacts of the practices.</p>\\n<p>It is often referred to as desirable difficulty.</p>\\n<p>As mentioned earlier, you might perceive that this challenges factor should be for all of the practices and all of the time of the practices, or you might believe that it should be done in a more measured fashion, just for some of the practices and maybe for just some of the time of those practices.</p>\\n<p>Let&#8217;s take a slightly different angle on this ugly zone notion.</p>\\n<p>Suppose you had practices that never were in the ugly zone.</p>\\n<p>So far, I&#8217;ve mentioned the belief by some that the practices should always and exclusively be in the ugly zone. The opposite tack perhaps would be to never use the ugly zone approach at all. I&#8217;ve seen this happen in some contexts.</p>\\n<p>For example, I was helping a group of middle school students learn about robotics as they were getting ready for a robotics competition.</p>\\n<p>A fellow mentor was purposely having them avoid encountering any problems while practicing writing code to program the robots for doing various tasks. I took him aside and gently pointed out that we ought to have the kids experience some issues or errors, so that they&#8217;d be ready during the live competition. He insisted that any kind of difficulty would mar their learning and rebuffed my suggestion. Sadly, things didn&#8217;t go very well for them during the live competition and they were baffled as to what to do when their robots faltered.</p>\\n<p>So, I&#8217;d generally argue that you need some amount of ugly zone involved in practicing.</p>\\n<p>I suppose that I&#8217;m the Goldilocks kind of practices person. It should be not too much ugly zone, and nor too little ugly zone. Just the right amount of ugly zone is the aim. And, crucially, having no ugly zone at all is likely an unfortunate and perhaps misguided omission that undermines the overall utility of the practices.</p>\\n<p>The ugly zone proponents contend that you need to learn how to think and act under pressure.</p>\\n<p>They say that if you are the type of person that gets butterflies in your stomach during live competitions, you need to hone your skills so that instead of expunging the butterflies that you instead learn to shape them so they fly in a formation. Use the pressure to overcome your fears. Use the pressure as a kind of high octane juice. That&#8217;s what the ugly zone is supposed to achieve.</p>\\n<p><strong>AI Autonomous Cars And Ugly Zones</strong></p>\\n<p>What does this have to do with AI self-driving driverless autonomous cars?</p>\\n<p>At the Cybernetic AI Self-Driving Car Institute, we are developing AI software for self-driving cars. In addition, we make use of a wide variety of techniques and one of those that we advocate is the use of the ugly zone.</p>\\n<p>Allow me to explain.</p>\\n<p>Many of the auto makers and tech firms that are making AI self-driving cars are doing testing in these ways:</p>\\n<ul>\\n<li>Use of simulations</li>\\n<li>Use of proving grounds</li>\\n<li>Use on public roads</li>\\n</ul>\\n<p>For my article about the use of simulations for AI self-driving cars, see: <a href=\"https://aitrends.com/selfdrivingcars/simulations-self-driving-cars-machine-learning-without-fear/\">https://aitrends.com/selfdrivingcars/simulations-self-driving-cars-machine-learning-without-fear/</a></p>\\n<p>For my article about providing grounds for AI self-driving cars, see: <a href=\"https://aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/</a></p>\\n<p>When an AI self-driving car is being &#8220;tested&#8221; on public roads, this means it is being done in a relatively uncontrolled environment and that presumably just about anything can happen.</p>\\n<p>On the one hand, this is good because there might be that &#8220;unexpected&#8221; aspect that arises and for which it is then handy to see how well the AI can respond to the matter. On the other hand, you might go hundreds, thousands, or millions of miles using the AI self-driving car and not encounter these plausible rare occasions at all, thus, in that sense, the AI self-driving car will not be tested readily on such facets.</p>\\n<p>There&#8217;s also the rather obvious but worth stating point that doing &#8220;testing&#8221; of AI self-driving cars while on public roads is something of a dicey proposition. If the AI is unable to appropriately respond to something that occurs, the public at large could be endangered. Suppose a man on a pogo stick suddenly appears in front of the AI self-driving car and the AI does not know what to do, and perhaps hits and injures the man – that&#8217;s not good.</p>\\n<p>See my article about the Uber crash incident that killed a pedestrian: <a href=\"https://aitrends.com/selfdrivingcars/initial-forensic-analysis/\">https://aitrends.com/selfdrivingcars/initial-forensic-analysis/</a></p>\\n<p>And, my follow-up article about the Uber crash: <a href=\"https://aitrends.com/selfdrivingcars/ntsb-releases-initial-report-on-fatal-uber-pedestrian-crash-dr-lance-eliot-seen-as-prescient/\">https://aitrends.com/selfdrivingcars/ntsb-releases-initial-report-on-fatal-uber-pedestrian-crash-dr-lance-eliot-seen-as-prescient/</a></p>\\n<p>As I&#8217;ve mentioned many times, there are some AI developers that have an &#8220;egocentric&#8221; perspective about AI self-driving cars and seem to think that if someone does something &#8220;stupid&#8221; like pogoing in front of a self-driving car that they get what they deserve (this will doom the emergence AI self-driving cars, I assure you).</p>\\n<p>There is also some sense of false security by many of the auto makers and tech firms that having a human back-up driver during public roadway testing is a sure way of avoiding any adverse incidents. This is quite a myth or misunderstanding, and there is still a bona fide chance that even with a human back-up driver that things can go awry for an AI self-driving car.</p>\\n<p>See my article about egocentric designers for AI self-driving cars: <a href=\"https://aitrends.com/selfdrivingcars/egocentric-design-and-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/egocentric-design-and-ai-self-driving-cars/</a></p>\\n<p>For my article about the dangers even with a human back-up driver, please see: <a href=\"https://aitrends.com/selfdrivingcars/human-back-up-drivers-for-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/human-back-up-drivers-for-ai-self-driving-cars/</a></p>\\n<p>Another aspect of doing testing on public roadways is that it might be difficult to reproduce the instance of what happened. I mention this because trying to do Machine Learning (ML) via only one example of something is quite difficult to do. It would be handy to be able to undertake the situation a multitude of times in order to try and arrive at a &#8220;best&#8221; or at least better way to respond. I&#8217;ve stated in my industry speeches that we&#8217;re suffering from a kind of irreproducibility in the AI self-driving car realm and for which inhibits or staggers potential progress.</p>\\n<p>For more about irreproducibility, see my article: <a href=\"https://aitrends.com/selfdrivingcars/irreproducibility-and-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/irreproducibility-and-ai-self-driving-cars/</a></p>\\n<p>For my overall framework about AI self-driving cars, see: <a href=\"https://aitrends.com/selfdrivingcars/framework-ai-self-driving-driverless-cars-big-picture/\">https://aitrends.com/selfdrivingcars/framework-ai-self-driving-driverless-cars-big-picture/</a></p>\\n<p>As perhaps is evident, doing testing on public roadways has some disadvantages.</p>\\n<p>That&#8217;s why it is vital to also do testing via the other means possible, including using simulations and using proving grounds.</p>\\n<p>For simulations, you can presumably run the AI through zillions of scenarios. There&#8217;s almost no limit to what you could try to test. The main constraint would be the computational cycles needed. Some auto makers and tech firms are even using supercomputers for their simulations, similar to how such high-powered computing is being used to gauge the impacts of climate change or other large-scale problems.</p>\\n<p>Not everyone though necessarily believes that the simulations are true to the real-world and thus the question is posed whether the AI reacting in a simulated environment is actually the same as it will react while on the roadways. If you are simulating climate change and your simulation is a bit off-base by estimates being made, this is likely Okay. But, if you are dealing with AI self-driving cars, which are multi-ton beasts that can produce instantaneous life-or-death consequences, a simulation that isn&#8217;t true to the real-world does not give one a full sense of confidence in the results.</p>\\n<p>In essence, if I told you that I had an AI self-driving car that has successfully passed a simulation of over one-hundred million miles of car driving, albeit only in a computer-based simulation, and never been on an actual road, would you be happy to see it now placed into public use, or unhappy, or disturbed, or what?</p>\\n<p>I think it&#8217;s fair to say that you&#8217;d be concerned.</p>\\n<p>There&#8217;s also the potential use of proving grounds.</p>\\n<p>See my article about proving grounds and self-driving cars: <a href=\"https://www.aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/\">https://www.aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/</a></p>\\n<p>This is usually private land or sometimes government land that is set aside for the purposes of testing AI self-driving cars.</p>\\n<p>You could say that in some ways it is better than simulations because it has a real-world aspect to it.</p>\\n<p>You could also say that this is safer than being on the public roadways since it is in an area that avoids potential harm to the general public.</p>\\n<p>I recently had a chance to closely explore a well-known proving ground, namely the American Center for Mobility (ACM) in Michigan, and spoke with the CEO and President, Michael Noblett, along with getting a specially guided tour of the facility by Angela Flood, Executive Director.</p>\\n<p>The ACM consists of over 500-acres, offering multiple test environments adjacent to the Willow Run Airport. There is about 2.5 miles of an extensive driving loop that contains high-speed usable highway roads and two tri-level overpasses. It is an impressive facility and available for commercial purposes, governmental purposes, and usable too by standards bodies and colleges.</p>\\n<p>For more info about the ACM, see: <a href=\"https://www.acmwillowrun.org/learn-about-the-facility/\">https://www.acmwillowrun.org/learn-about-the-facility/</a></p>\\n<p><strong>Creating Ugly Zones In All Modes</strong></p>\\n<p>Generally, it seems apparent that you&#8217;d want to use a combination of simulations, proving grounds, and public roadways for developing and testing of your AI self-driving car.</p>\\n<p>Each approach has its own merits, and each approach has its own drawbacks.</p>\\n<p>In combination, you can aim to get more kinds of testing that will hopefully lead to sounder AI self-driving cars.</p>\\n<p>Let&#8217;s now revisit the ugly zone.</p>\\n<p>For real-world driving of an AI self-driving car, as mentioned earlier, the AI might go for many miles without ever encountering some really difficult driving situations. Any such instances would presumably occur by happenstance, if at all. With a providing ground, you can possibly setup the AI for having to cope with quite ugly situations. Same goes for the use of simulations.</p>\\n<p>Regrettably, there are some auto makers and tech firms that are not pushing their AI to the limits via the use of the proving grounds and nor the simulations. They seem to believe that the focus should be the &#8220;normal&#8221; conditions of driving.</p>\\n<p>For example, at a proving ground, the AI self-driving car is driving on a road and all of a sudden a woman pushing a baby stroller carriage starts to walk across the street (this might be a stunt woman hired for this purpose, and the baby stroller is empty other than a fake doll). The AI self-driving car detects the motions and objects involved, i.e., the adult female and the stroller, and deftly swerves to avoid them. AI saves the day! Case closed, the AI is prepared for such a scenario.</p>\\n<p>This seems convincing as a test.</p>\\n<p>You might mark-off on your checklist and claim that the AI can detect a person with a baby stroller and take the right kind of action to avoid a calamity.</p>\\n<p>There are though additional considerations.</p>\\n<p>How many other cars were on the road with the AI self-driving car?</p>\\n<p>In this case, none.</p>\\n<p>Was there a car directly next to the AI self-driving car that would have been potentially in the way of the swerving action?</p>\\n<p>Not in this case.</p>\\n<p>Were there other pedestrians also trying to cross the street at the same time as the woman and the stroller?</p>\\n<p>No, just the woman and the stroller.</p>\\n<p>Were there any road signs warning about an upcoming hazard or perhaps any orange cones in the road due to roadway repairs being made? No.</p>\\n<p>And so on.</p>\\n<p>I think we would all feel a bit more confident in the testing of avoiding the woman with the baby stroller if we believed it was done in a more high-pressure situation.</p>\\n<p>Imagine if the AI self-driving car had other cars all around it, boxing it in, and meanwhile there were lots of other pedestrians near to or approaching the self-driving car, and the road itself was a mess, and a lot of things were happening all at once. That&#8217;s more telling about what the AI can cope with.</p>\\n<p>Having a simplified, stripped down situation with an otherwise barren road, and just the woman and the stroller, does not seem like much of a test per se.</p>\\n<p>It&#8217;s not anything close to being an ugly zone.</p>\\n<p>Don&#8217;t misunderstand my point. I&#8217;m fine with the stripped down test as one such test.</p>\\n<p>But, if that&#8217;s going to be the nature of the testing that&#8217;s taking place, it would seem like there&#8217;s no provision for the ugly zone.</p>\\n<p>Recall that I earlier mentioned that having a practice without any kind of ugly zone would seem to be a practice that has a substantial omission and we ought to question the validity of the practice overall.</p>\\n<p>For AI self-driving cars, we should definitely have ugly zone testing (or, if you prefer, we can say &#8220;practices&#8221; rather than &#8220;testing&#8221;).</p>\\n<p>Should you use only and always ugly zones?</p>\\n<p>Well, as I mentioned previously, I&#8217;m an advocate for a measured amount of practice time for sometimes having ugly zones and sometimes not.</p>\\n<p>My Goldilocks viewpoint is to have a combination of times with and without the ugly zones. But, however you allocate the time, there must be some amount of ugly zone practice.</p>\\n<p>Avoidance of using an ugly zone approach in undertaking practices for AI self-driving cars is a scary and understated form of practice and will pretty much &#8220;guarantee&#8221; the failure of AI self-driving cars in the real-world.</p>\\n<p>Per my framework, these are the key AI self-driving car driving tasks:</p>\\n<ul>\\n<li>Sensor data collection and interpretation</li>\\n<li>Sensor fusion</li>\\n<li>Virtual world model updating</li>\\n<li>AI action planning</li>\\n<li>Cars control commands issuance</li>\\n</ul>\\n<p>The ugly zone is a means to see how well each of those AI elements are able to perform. Furthermore, you want to see how well they each individually work as a semi-independent component, along with how they work in concert together to drive the self-driving car. Therefore, the ugly zone needs to have a varied and myriad of aspects that will put &#8220;pressure&#8221; on each of the components.</p>\\n<p>You might wonder how you can &#8220;pressure&#8221; an AI system, since it&#8217;s not like a human wherein you can pressure a human to get into a tizzy by throwing all sorts of things at them at once. Actually, in some ways, you can indeed pressure the AI system by doing likewise of what you&#8217;d do to a human, namely, pile-on as many things as you can, and see what the AI does. The internal timing of the AI system needs to be taxed to see that it can handle a multitude of simultaneous things happening on the roadway at the same time and in the same place.</p>\\n<p>For my article about the cognition timing of real-time AI systems, please see: <a href=\"https://aitrends.com/selfdrivingcars/cognitive-timing-for-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/cognitive-timing-for-ai-self-driving-cars/</a></p>\\n<p><strong>Conclusion </strong></p>\\n<p>We believe in the ugly zone approach for AI self-driving cars.</p>\\n<p>Let&#8217;s create as tough an environment as feasible so that once the AI self-driving car is on the public roadways, it&#8217;s a piece of cake.</p>\\n<p>True stress testing should be done in all means feasible and not wait until the AI self-driving car is in a public place and for which public harm can occur.</p>\\n<p>Whether you want to put your own children into an ugly zone for their piano practices or for their art lessons, that&#8217;s up to you.</p>\\n<p>I think we can all agree that we&#8217;d believe more so in the potential of AI self-driving cars to be trustworthy on our streets if we knew that they had survived, learned from, and were adept at dealing with ugly zones.</p>\\n<p>Go, ugly zones, go.</p>\\n<p><em>Copyright 2019 Dr. Lance Eliot </em></p>\\n<p><em>This content is originally posted on AI Trends.</em></p>\\n<p><a href=\"http://ai-selfdriving-cars.libsyn.com/website\"><img class=\"alignnone size-medium wp-image-17417\" src=\"https://www.aitrends.com/wp-content/uploads/2019/06/selfdrivingcarspodcastv2-300x150-300x150.jpg\" alt=\"\" width=\"300\" height=\"150\" /></a></p>'}]}],\n",
       " 'bozo': 0,\n",
       " 'encoding': 'utf-8',\n",
       " 'version': 'rss20',\n",
       " 'namespaces': {'content': 'http://purl.org/rss/1.0/modules/content/',\n",
       "  'wfw': 'http://wellformedweb.org/CommentAPI/',\n",
       "  'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  '': 'http://www.w3.org/2005/Atom',\n",
       "  'sy': 'http://purl.org/rss/1.0/modules/syndication/',\n",
       "  'slash': 'http://purl.org/rss/1.0/modules/slash/'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Trends\n",
      "The Business and Technology of Enterprise AI\n",
      "Fri, 18 Oct 2019 11:03:27 +0000\n",
      "\tTag: Data Privacy and Security\n",
      "\tTag: Ethics and Social Issues\n",
      "\tTag: Machine Learning\n",
      "\tTag: ai in business\n",
      "\tTag: data security and privacy\n",
      "\tTag: ethics and social issues\n",
      "\tTag: machine learning\n",
      "Data Privacy Clashing with Demand for Data to Power AI Applications\n",
      "Thu, 17 Oct 2019 21:30:40 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff Your data has value, but unlocking it for your own benefit is challenging. Understanding how valuable data are collected and approved for use can help you to get there. Two primary means for differentiating audiences by their data collection methods are site-authenticated data collection and people-based data collection, suggested a recent [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18GDPR-CompliantForm-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By AI Trends Staff</em></p>\n",
      "<p>Your data has value, but unlocking it for your own benefit is challenging. Understanding how valuable data are collected and approved for use can help you to get there.</p>\n",
      "<p>Two primary means for differentiating audiences by their data collection methods are site-authenticated data collection and people-based data collection, suggested a recent piece in <a href=\"https://www.bulletinhealthcare.com/yes-data-is-the-new-oil/\">BulletinHealthcare</a> written by Justin Fadgen, chief corporate development officer for the firm.</p>\n",
      "<p>Site-authenticated data are sourced from individual authentication events, such as when a user completes an online form, and generally agrees to a privacy policy that includes a data use agreement. User data are then be combined with other data sources that add meaning, becoming the basis of advertising targeting for instance. In marketing for healthcare, this is the National Provider Identifier (NPI), a 10-digit numeric identifier for covered healthcare providers under HIPAA.</p>\n",
      "<p>People-based data collection does not come from a registration, but from a variety of sources that could include data licensing, research, and manual verification. These data can be loaded onto a data management platform, which aggregates data from various sources into likely groups using data science. The goal is to provide an anonymized ID to individual users. These then can be individually targeted.</p>\n",
      "<p>People-based data may not be friendly to individual-level reporting, also called physician-level reporting. This is because no privacy policy has stipulated how the data are to be used.</p>\n",
      "<p><strong>National Health Service of England Seeking to Monetize Data</strong></p>\n",
      "<p>Efforts to monetize patient data of the National Health Service (NHS) of England further emphasizes the value of your data. Sensyne Health, a for-profit company, is working to get divisions of the NHS to put patient information into a database. The NHS has 71 years of patient data. In recent years, it has worked to collect patient DNA data for research.</p>\n",
      "<p>Sensyne’s initial goal, according to an account from <a href=\"https://www.bloomberg.com/news/articles/2019-07-18/a-former-science-minister-wants-to-fund-the-nhs-by-selling-patient-data\">Bloomberg</a>, is to gather information on five million NHS patients. Ultimately, said Paul Drayson, the former UK science minister who founded Sensyne, the company hopes to get access to all 55 million members of NHS. EY consultants estimate those data might be worth $12 billion annually, money NHS could apply to patient care and health. Sensyne has so far signed up six of 150 hospital divisions in the NHS. Each division, or trust, receives Sensyne shares worth some $3 million.</p>\n",
      "<p>The potential value is of interest to the UK government, especially with Brexit injecting more uncertainty into the economy. “How the NHS works with the global life sciences industry is key to the health of the nation,” Drayson stated.</p>\n",
      "<p>Other groups are looking data as a business model. Intermountain Healthcare of Salt Lake City recently announced a partnership with Amgen to study the genomes of half a million patients. Israel is working on commercializing its patient health records in a $300 million program. Nebula Genomics is among companies who broker individual patient DNA data to buyers in the health industry.</p>\n",
      "<p><strong>GDPR in European Union Enhances Individual Privacy Protection</strong></p>\n",
      "<p>New privacy laws in Europe increase protections on patient information. According to polls, UK residents are willing to share data if it is invested back into healthcare, but they worry it will get into the wrong hands. Any citizen has the right to block sales of her or her data.</p>\n",
      "<p>The General Data Protection Regulation (GDPR) that went into effect in the European Union in May 2018 specified some rules around data permissions. Customers must now confirm that they want to be contacted, according to an account in <a href=\"https://www.superoffice.com/blog/gdpr-marketing/\">SuperOffice</a>. A default checkbox that automatically opts a customer in will not comply; opt-in needs to be a deliberate choice. SuperOffice has modified its web forms as a result.</p>\n",
      "<p>The GDPR says the customer has the “right to be forgotten,” to have outdated or inaccurate information removed. This gives individuals a way to gain more control over how their data are collected and used. This can be implemented with an unsubscribe link in email messages, and links to customer profiles that allow users to manage their email preferences.</p>\n",
      "<p>Fines for violation of GDPR privacy rules can be hefty, including $90,000 to a company that sent email to 3.3 million customers that had opted out of its lists.</p>\n",
      "<p>As companies pursuing AI and machine learning solutions race to get the data needed to make their applications work, we can see some challenging moments.</p>\n",
      "<p><strong>Contribute Your Face to Google Database, Earn $5</strong></p>\n",
      "<p>For instance, seeking to ensure its facial recognition image database is more diverse, Google recently began offering black homeless people in Atlanta $5 vouchers to submit their faces to the database, according to an account in <a href=\"https://www.theregister.co.uk/2019/10/06/ai_roundup_041019/\">TheRegister</a>.</p>\n",
      "<p>With images of white men dominating its database, Google hired contractors to offer vouchers to people to record their faces. The temporary agency Randstad was told to target people with darker skin. Some were homeless living on the streets in Atlanta. Participants may not have been explicitly told what their images would be used for. When the word got out, it did not go over well in some circles. Atlanta City Attorney Nina Hickson wrote a letter to Google’s chief legal officer Kent Walker, asking the company to explain why the company was targeting “vulnerable populations” in Atlanta. The project was suspended. Google wanted to use the dataset to train a facial biometric system that can unlock its upcoming Pixel 4 smartphone.</p>\n",
      "<p>See the source posts in <a href=\"https://www.bulletinhealthcare.com/yes-data-is-the-new-oil/\">BulletinHealthcare</a>, <a href=\"https://www.bloomberg.com/news/articles/2019-07-18/a-former-science-minister-wants-to-fund-the-nhs-by-selling-patient-data\">Bloomberg</a>, <a href=\"https://www.superoffice.com/blog/gdpr-marketing/\">SuperOffice</a> and <a href=\"https://www.theregister.co.uk/2019/10/06/ai_roundup_041019/\">TheRegister</a>.</p>\n",
      "\tTag: AI and Business Strategy\n",
      "\tTag: AI World 2019\n",
      "\tTag: Startups\n",
      "\tTag: AI and business strategy\n",
      "\tTag: AI and IT services\n",
      "\tTag: ai in business\n",
      "\tTag: startups\n",
      "Startup Pavilion at AI World Showcases Innovation and Promise\n",
      "Thu, 17 Oct 2019 21:30:35 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff The AI World Conference &#38; Expo in Boston, Oct. 23-25, will include a Startup Pavilion of companies showing innovation, promise and creativity as they pursue business opportunities in new ventures in AI and machine learning. Here is a brief profile of each of the startups: The AI Network of Ridgeway Partners [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18AIWorld-Startups-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By AI Trends Staff</em></p>\n",
      "<p>The AI World Conference &amp; Expo in Boston, Oct. 23-25, will include a Startup Pavilion of companies showing innovation, promise and creativity as they pursue business opportunities in new ventures in AI and machine learning.</p>\n",
      "<p>Here is a brief profile of each of the startups:</p>\n",
      "<p><strong>The AI Network of </strong><a href=\"https://ridgewaypartners.com/\"><strong>Ridgeway Partners</strong></a></p>\n",
      "<p>The <strong>AI Network</strong> was created by Ridgeway Partners, a global executive and board recruiting firm. The AI Network is a talent marketplace which uses AI to connect companies to the best  early-stage AI and data science talent. The firm has offices in New York, Boston, London and Hong Kong. Most of the recruiting work is based in the US and Europe, and the firm has completed assignments in Africa, the Middle East and Asia.</p>\n",
      "<p><a href=\"https://aireverie.com/\"><strong>AI.Reverie</strong></a></p>\n",
      "<p><strong>AI.Reverie</strong> is a simulation platform that trains AI to understand the world. Our platform offers tools to leverage the power of synthetic data to significantly improve the performance of mission critical vision algorithms. The firm recently announced a strategic partnership and investment from In-Q-Tel, the not-for-profit strategic investor that works to deliver innovative technology to US intelligence and defense agencies.The firm’s website describes its team as, “Idea generators and problem solvers with a passion for creating a better world with AI.” The company’s services include the creation of virtual worlds with animation and the ability to run simulations that produce synthetic data.</p>\n",
      "<p><a href=\"https://ainfinitylabs.com/\"><strong>AInfinity</strong></a></p>\n",
      "<p><strong>AInfinity </strong>specializes in cutting-edge technology solutions that combine Artificial Intelligence and ITOps capabilities. Drawing on the industry knowledge and expertise of its parent company, Atlas Systems, AInfinity has launched an end-to-end solution focused on predicting IT infrastructure (OS, Network, DB, Middleware) issues and resolving them using its rich knowledge library. The AInfinity Knowledge Library includes runbooks,, use cases, business rules, workflow orchestration, and proven best practices for resolving a wide range of IT issues.</p>\n",
      "<p><a href=\"https://bauglobal.com/\">BAU Global</a></p>\n",
      "<p><strong>The BAU Global Education Network</strong> is comprised of higher education institutions spread around the world. This international network welcomes students from across the globe to study at a number of locations. Students and graduates of BAU Global form an academic community that spans many countries on four continents: North America, Europe, Africa, and Asia. BAU Global universities offer nearly two hundred undergraduate, graduate and doctoral programs in architecture, art, business administration, communication, design, economics, education, engineering, health sciences, information technology, law, medicine, and social sciences.</p>\n",
      "<p>BAU Global develops global citizens who are committed to values that benefit the entire world. The institutions in this network not only meet the standards set forth by the accreditation bodies in their home countries, but are also highly ranked in the disciplines they offer.</p>\n",
      "<p><a href=\"https://www.campteksoftware.com/\">CampTek</a></p>\n",
      "<p><strong>CampTek Software</strong> is an RPA SaaS Provider offering a wide array of services to assist you anywhere on your RPA Journey. Our team of certified experts focus on Bot development, Bot Support and Hosted Support.  With over 15 years of experience supporting and developing RPA applications, we are the choice. CampTek’s Software solutions include: Center of Excellence (COE), robot development, SaaS hosting and support, Windows and website automation, Citrix and remote desktop automation, support for Legacy Character-based systems, custom component creation and governance and architecture capabilities.</p>\n",
      "<p><a href=\"https://www.capestart.com/\">CapeStart</a></p>\n",
      "<p><strong>CapeStart</strong> is an outsourced data preparation services and software development firm that gives data-driven organizations the ability to offload tedious data tasks with confidence. Our mission is to provide you with reliable, knowledgeable and affordable solutions for resourcing your big data, machine learning, and artificial intelligence projects. The firm’s campus is Nagercoil, India helps to support the development work. CapeStart is engaged in over 50 active projects for its clients in a range of industries, according to its website. One client hired CapeStart to measure the ROI of its public relations activities, by monitoring the media and performing services including data extraction, sentiment analysis and document transcription.</p>\n",
      "<p><a href=\"https://www.capice.cloud/\"><strong>Capice</strong></a></p>\n",
      "<p><strong>Capice</strong> offers machine learning for everyone, suggesting no technical training or programming background is required to create business models. The Capice AI services including algorithms are available via an API interface. The client provides the training data, as audio, video or text. The Caprice tools are used to address business problems using classification and prediction.</p>\n",
      "<p><a href=\"https://daivergent.com/\"><strong>Daivergent</strong></a></p>\n",
      "<p><strong>Daivergent</strong>, a Public Benefit Corporation, hires workers with autism and developmental disabilities. The firm offers: dedicated project managers with experience in ata and technology fields; a US-based workforce, sourced from universities and agencies in the US; handling of requests of any scale; performance guarantees. The Daivergent platform has a remote user base of 850 candidates and 18 corporate clients. The firm offers employees online training in programming languages including Python and SQL, graphic design, 3-D modeling and marketing, to help bolster career growth. The company works closely with agencies including AHRC in New York City, a nonprofit providing workshops, day treatment programs and job training for people with intellectual and developmental disabilities.</p>\n",
      "<p><a href=\"https://firefly.ai/\"><strong>Firefly.ai</strong></a></p>\n",
      "<p><strong>Firefly.ai</strong> puts the power of artificial intelligence in the hands of any business that aims to predict its future. With our automated machine learning platform, analysts can easily build predictive models to enhance every business decision. Clients engage in the following steps: prepare and analyze data, train hundreds of models, design visual reports and deploy the models. Predictive models offered include demand analysis, predictive maintenance, investment optimization, risk mitigation, sales forecasting and customer segmentation. Firefly.ai targets ordinary business users by offering easy access to AI and machine learning.</p>\n",
      "<p><a href=\"https://www.jaxon.ai/\"><strong>Jaxon.ai</strong></a></p>\n",
      "<p>The best way to improve the accuracy of machine learning models is to increase the amount of labeled data ingested and/or re-label existing data, according to <strong>Jaxon.ai</strong>. Normally it takes months and massive amounts of manpower to get deep learning models trained with meaningful volumes of datasets. By the time the data is labeled, it is frequently already outdated. Jaxon aims to eliminate this bottleneck and allowing models to be updated continuously.</p>\n",
      "<p>With self-adjusting pipelines, Jaxon is said to adapt to each organization’s nuanced data and domain-specific terminology. Training sets are created using existing data, as well as new text streaming in from online and internal sources. Jaxon labels can train any text-based predictive model and can be used for document classification, recommenders, chatbots, customer insights and trend detection.</p>\n",
      "<p><a href=\"https://kyndi.com/\"><strong>Kyndi</strong></a></p>\n",
      "<p><strong>Kyndi </strong>offers an Explainable AI product and Intelligent Process Automation software platform for use by government, pharmaceutical, and financial services organizations. The product addresses the “black box” of Deep Learning, which restricts their use in regulated industries. The Kyndi platform scores the provenance and origin of each document it processes. Its Explainable AI software can be used with robotic process automation (RPA) tools to analyze text and automate inefficient workflows.</p>\n",
      "<p><a href=\"https://lazarusfin.com/\"><strong>Lazarus Enterprises</strong></a></p>\n",
      "<p><strong>Lazarus </strong>uses patient health data to improve early cancer detection. By using its clinical decision support tools, physicians are said to be able to improve their diagnostic accuracy from 76% all the way up to 93%. The company uses deep learning and accesses millions of patient records. The company’s business model is to sell test and subscriptions for physicians and hospitals, and selling anonymous datasets to insurance companies and research companies.</p>\n",
      "<p><a href=\"https://liquidtechnology.net/\"><strong>Liquid Technologies</strong></a></p>\n",
      "<p><strong>LiquidTechnology </strong>is a nationwide provider of IT Asset Management Services. The company specializes in performing data center clean-outs, de-installations, consolidations and moves. The firm’s core competencies include: IT asset purchasing &amp; brokerage, project management, compliant data destruction, chain of custody/ reverse logistics, as well as e-Stewards and R2 compliant e-Waste recycling.</p>\n",
      "<p><a href=\"https://www.ontoforce.com/\"><strong>Ontoforce</strong></a></p>\n",
      "<p><strong>ONTOFORCE </strong>offers to help customers transform siloed data into smart-linked data ecosystems to empower data-driven decision making. The company’s linked data platform DISQOVER builds intelligent links between internal and external data sources, turning data into smart data. The software is installed on-premise or in the cloud. The company employs semantic search technology to help find insights into data. DISQOVER Public is a free resource with links to 145 different public data sources in biomedicine, enabling users to learn about the technology.</p>\n",
      "<p><a href=\"https://www.openmetrik.com/\"><strong>Openmetrik</strong></a></p>\n",
      "<p><strong>Openmetrick </strong>works to automated three activities critical to business success: end-to-end digitization of analytics, enterprise data government and business process virtualization. The firm seeks to disrupt the IT industry by cutting the chaos of current fragmented IT tools, and to eliminate mundate, IT-resource intensive methods. Its software platform, dubbed GRIP, offers business intelligence, performance measurement and business process integration. The company’s Integration Metrics Platform secured a US patent in June 2018 enabling what the company calls the digitization of performance measurement, or a centralized metrics playbook.</p>\n",
      "<p><a href=\"https://perceptimed.com/\"><strong>PerceptiMed</strong></a></p>\n",
      "<p><strong>PerceptiMed’s </strong>advanced pharmacy automation technologies reduce prescription errors and improve pharmacy workflow productivity ─ from fill to will call. PerceptiMed’s identRx<img src=\"https://s.w.org/images/core/emoji/11/72x72/2122.png\" alt=\"™\" class=\"wp-smiley\" style=\"height: 1em; max-height: 1em;\" /> uses artificial intelligence for pill verification, ensuring every pill placed into a prescription is correct and simultaneously serves as an ultra-accurate pill counter. IdentRx supports remote verification for telepharmacy. The products are designed to eliminate human errors in medication dispensing in pharmacies, long-term care facilities and hospitals.</p>\n",
      "<p><a href=\"https://roborus.ai/\"><strong>Roborus</strong></a></p>\n",
      "<p><strong>Roborus</strong> offers AI-based kiosks that employ facial recognition to automatically identify customers in cafes, restaurants, and retail shops. The software platform uses face recognition technology to classify customers&#8217; data such as facial ID, gender, age, and 7 different moods. The machine learning system can provide guests with personalized services and is able to, for example, recommend specific menu items based on customer profile. The software gathers and analyzes data such as number of visits, consumption patterns and average spending, helping clients to enhance marketing efforts and increase sales.</p>\n",
      "<p><a href=\"https://www.talentseer.com/\"><strong>TalentSeer</strong></a></p>\n",
      "<p><strong>TalentSeer </strong>uses AI to provide integrated talent acquisition, market research, and career mentorship services. With an engaged AI community and deep domain knowledge, TalentSeer has helped over 100 high tech companies from autonomous driving, to finance, and healthcare at various growth stages to build strong teams. AI engineers are overloaded with repetitive pitch messages. The firm employs insight-based and influence-based recruiting techniques, to produce insights on industry, business and career development.</p>\n",
      "<p><a href=\"https://www.tfir.io/\"><strong>TFiR </strong></a></p>\n",
      "<p><strong>TFiR</strong> is an abbreviation for The Fourth Industrial Revolution. The company publishes news, analysis, interviews, op-eds and tutorials covering emerging technologies and open source. The coverage addresses new technologies, new business models, tech culture and their impact on society. A recent newsletter issue included an update from Richard Stallman, the open source software movement activist and self-described “Chief GNUisance.” Stallman announced the GNU Project’s goals, principles and policies will make incremental and not radical changes. TFiR targets CXOs, developers/operators and enthusiasts, according to its website.</p>\n",
      "<p>For more information, see <a href=\"https://aiworld.com/sponsors\">AI World Sponsors. </a></p>\n",
      "\tTag: AI Trends Insider on Autonomy\n",
      "\tTag: Robotics\n",
      "\tTag: Self Driving Cars\n",
      "\tTag: AI Trends Insider\n",
      "\tTag: autonomous cars\n",
      "\tTag: robot cars\n",
      "\tTag: robot taxis\n",
      "\tTag: robotics\n",
      "\tTag: self driving cars\n",
      "Machine Learning Embodying Fear and AI Autonomous Cars\n",
      "Thu, 17 Oct 2019 21:30:27 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider [Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/] Fear is considered one of the fundamental elements of emotion. It seems as though humans and pretty much all animals are prone to fear. Fear [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18FearandHalloween-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Lance Eliot, the AI Trends Insider</em></p>\n",
      "<p><em>[Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: </em><a href=\"https://forbes.com/sites/lanceeliot/\"><em>https://forbes.com/sites/lanceeliot/</em></a><em>]</em></p>\n",
      "<p>Fear is considered one of the fundamental elements of emotion.</p>\n",
      "<p>It seems as though humans and pretty much all animals are prone to fear.</p>\n",
      "<p>Fear can be based on a real situation, such as you might be standing in front of a hungry lion and so you naturally are bound to be fearful of it, or fear might be based on a perceived danger that is not necessarily directly evident, such as walking down a dark alley and being inherently suspicious that something bad might happen to you.</p>\n",
      "<p>Typically, there is a physical response in a human or animal when experiencing fear.</p>\n",
      "<p>You have likely been on a roller coaster and in anticipation of that big drop up ahead your heart rate goes up, you feel your body tensing, your mind might become laser focused and you can’t think of anything other than the circumstance that you are facing.</p>\n",
      "<p>Humans have an ability to detect fear on others, including via facial expression analysis (someone’s face gets tense), the person might clench their teeth and make fists with their hands, etc. Of course, animals can also detect fear, of which I’m guessing you’ve had cases whereby a dog sensed your fear, maybe smelling your perspiration, and either took advantage of your fearful state or in some instances maybe even tried to reduce it.</p>\n",
      "<p>Responding to fear can be as simple as the classic fight-or-flight kind of response.</p>\n",
      "<p>If you fear something, you might decide to stand your ground and fight it. Alternatively, you might instead decide to run from whatever is causing the fear. Regrettably, sometimes while in the grip of fear we make bad choices. It could be that you should have chosen to run away from an angry bear rather than trying to confront it. Maybe trying to run away from an approaching ball of fire would have been better handled by trying to shelter in place.</p>\n",
      "<p>There are other options beyond just fight-or-flight, including one that can be the worst of them all, freezing up.</p>\n",
      "<p>Sometimes the fear is so overwhelming that trying to ascertain what to do is beyond our mental capacity at the moment, and thus we become frozen in fear. Though it might be possible that being frozen will work out okay in the given situation, generally some response is more likely to be successful than no response at all.</p>\n",
      "<p><strong>Fear Plausibility</strong></p>\n",
      "<p>Another twist to fear is that it can be considered plausible or implausible (some would say valid or invalid).</p>\n",
      "<p>Last year, there was a Chinese space station that was going to fall to earth and supposedly no one could predict where it would ultimately land.</p>\n",
      "<p>I had a colleague that told me he was fearful it could land on him.</p>\n",
      "<p>I tried to point out that the vast majority of the globe is water and so the odds were high that it would fall into the water and not strike anyone in particular.</p>\n",
      "<p>Even if it fell over land, I pointed out that by being inside a structure such as a building, it would seem unlikely he’d get hit and killed.</p>\n",
      "<p>The odds that he would be outside and be struck by it were likely much less odds than say winning the multi-state lotto (I realize he’d rather win the lotto than get hit by the space station). I suggested he buy the multi-state lotto ticket, the payout was around $500 million, and that maybe he’d win the lotto and get hit by the space station at the same time (those are some amazing odds!).</p>\n",
      "<p>Anyway, sometimes fear is in our minds, but not due to an actual fearful situation per se.</p>\n",
      "<p>We can convince ourselves to be fearful.</p>\n",
      "<p>In that sense, fear is definitely a dual-edged sword.</p>\n",
      "<p>Fear provides us with a vital survival technique. When utilized poorly, it can cause us to damage ourselves as based on a false believe that something dangerous is going to happen, when let’s say there’s really no chance of it happening at all.</p>\n",
      "<p>Some would refer to this as an unfounded fear.</p>\n",
      "<p>A fascinating recent study examined fear and described an angle that most would not have thought of.</p>\n",
      "<p>We all know that you are bound to be fearful of a predator.</p>\n",
      "<p>The field mouse is fearful of the swooping hawk. The prey is fearful of the predator, and rightfully so.</p>\n",
      "<p>This particular study pointed out that animals tend to avoid eating feces or munching on a carcass that has gone bad.</p>\n",
      "<p>Those aren’t predators, so why fear them?</p>\n",
      "<p>It’s because we are fearful of getting infections or disease, and seem to realize that we need to avoid circumstances that might involve getting infected by some untoward bacteria.</p>\n",
      "<p><strong>Nature Versus Nurture</strong></p>\n",
      "<p>How do animals know about this?</p>\n",
      "<p>In the nature-versus-nurture debate, are we programmed in our DNA to avoid things that might infect us, or do we only learn over time by either watching others, or by being taught, or by getting an infection and surviving it such that we realize not to do that again?</p>\n",
      "<p>If you see a hawk diving at you, it’s a pretty obvious aspect that maybe you should avoid letting it get you. But, seeing a juicy carcass, when you are starving, and opting to avoid eating it, because you somehow know that hours or maybe days later you might get sick, and might die, now that’s an interesting aspect of fear.</p>\n",
      "<p>You need to connect a later-on consequence to something that at the moment seems benign.</p>\n",
      "<p>The researchers described a landscape of fear.</p>\n",
      "<p>Animals will avoid drinking contaminated water.</p>\n",
      "<p>Animals will avoid eating a carcass when it seems too far gone.</p>\n",
      "<p>Animals will even graze away from an area that had a carcass, as though realizing that whatever is bad about the carcass could be spread locally beyond just the carcass. Animals tend to flee from biting ticks or try to get the ticks off their bodies.</p>\n",
      "<p>Within the landscape of fear, animals are able to detect infection threats. Either instinctively or in a learned manner, animals weigh the risks associated with the threats and try to achieve various levels of safety.</p>\n",
      "<p>For any of you interested in population dynamics and ecological aspects, you’d likely find this view of predator avoidance and infection avoidance of keen fascination.</p>\n",
      "<p><strong>Fear Landscape And Autonomous Cars</strong></p>\n",
      "<p>What does this have to do with AI self-driving driverless autonomous cars?</p>\n",
      "<p>At the Cybernetic AI Self-Driving Car Institute, we are developing an aspect of AI systems for self-driving cars that involves leveraging a landscape of fear regarding driving cars.</p>\n",
      "<p>Allow me a moment to elaborate on this somewhat surprising approach.</p>\n",
      "<p>As a human driver, you presumably already have a fear of hitting another car.</p>\n",
      "<p>You likely are fearful that you might hit a pedestrian.</p>\n",
      "<p>You probably also have a fear that other drivers are going to hit your car.</p>\n",
      "<p>You might have a fear that your car will fail on you, such as being on the freeway and all of a sudden it conks out and you are stranded in the middle of the busy freeway in a stalled car. It is possible you have a fear that the roadway will be unusable or impassable.</p>\n",
      "<p>The other day I drove up to the local mountains and reached a point that the paved road turned to packed dirt, which then became loose dirt, which then became muddy due to recent rains. My car almost got stuck in the middle-of-nowhere in an impassable road (I was driving just a conventional car and not an off-the-road vehicle).</p>\n",
      "<p>All of the above fears as a human driver are plausible.</p>\n",
      "<p>They are founded on a reasonable belief that those things could happen.</p>\n",
      "<p>We daily harness those fears while driving our cars. Some drivers though make driving mistakes as based on a fear that is either unfounded or at least that doesn’t actually materialize.</p>\n",
      "<p>I was in a car one day with a young driver that notably never made a left turn. He seemed to avoid to the extreme making a left turn.</p>\n",
      "<p>Now, we all know that left turns can be dangerous, and even some of the shipping companies such as UPS are using GPS systems that try to minimize the number of left turns. But, this was left turn paranoia.</p>\n",
      "<p>In talking with the driver, he shared with me a sad story of his family having gotten into a car crash while making a left turn, so he vowed that it would never happen again, which he figured by not making left turns would pretty much guarantee it. I did not have the heart to point out that his now heightened frequency of right turns, being done to make-up for not making left turns, might well have balanced out the risks of making a lesser number of left turns.</p>\n",
      "<p>His fear of left turns would not have been apparent or visible unless you were observing him, as I had, while a passenger in the car.</p>\n",
      "<p>If you had asked him about his driving approach, I doubt he would have volunteered that he won’t make left turns. An outside observer might not have noticed it either, unless you were following him like a secret agent.</p>\n",
      "<p>Our fears then can be hidden from view.</p>\n",
      "<p>Likewise, when I mentioned that you are fearful of getting into a car crash and fearful of your car faltering, it’s not something that you probably would have voiced if I had asked you about it.</p>\n",
      "<p>The word “fear” in our society has various connotations, generally being less flattering to the person that embodies the fear. What, you were fearful of riding that roller coaster, you’re a chicken! Society seems to pressure us to hide our fears and tend to not admit to them.</p>\n",
      "<p>For AI purposes, some believe that if we are to achieve true AI, and be able to make computer systems that can do what humans do, we need to replicate as much as possible whatever humans do.</p>\n",
      "<p>If humans rely on emotions, we must then incorporate emotions into computer systems to achieve true AI.</p>\n",
      "<p>There is a counter-argument that maybe we don’t need emotions to have intelligence, and so we can strip away some aspects of humans and yet still arrive at fully intelligent systems.</p>\n",
      "<p>Others say that our intelligence is intertwined with our emotions and you cannot separate them out and yet still have intelligence. Having a no emotions AI system would not end-up being fully intelligent as it has lost an essential component that is wrapped inextricably into intelligence, they would assert.</p>\n",
      "<p>Whether you stand on one side or the other of the debate about emotion and intelligence, I think we could say that fear is something that does make sense for an intelligent being to possess. If you are willing to consider fear as a form of mathematical calculation about the perceived dangers and risks, we certainly should have that same kind of capability built into our AI systems.</p>\n",
      "<p>As such, an AI self-driving car should make use of fear.</p>\n",
      "<p>That being said, I am not talking about the kind of “the sky is falling” kind of fear. I am referring to the notion of fear as a methodical means to try and determine risks and dangers, and seek actions to reduce those risks and try to achieve greater chances of safety.</p>\n",
      "<p><strong>Example Of No Fear Producing Dangers</strong></p>\n",
      "<p>I was in a car with a colleague that likes expensive cars and loves to drive fast (I would say recklessly, while he would say just fast).</p>\n",
      "<p>We were on the freeway in the leftmost lane, the fast lane.</p>\n",
      "<p>Our exit to get off the freeway was fast approaching. He gunned his engine and at the last moment darted across all of the lanes of traffic, having lined up small gaps in each lane, including darting in front of a very large truck hauling a tanker of gasoline.</p>\n",
      "<p>Did we make it to the exit ramp? Yes.</p>\n",
      "<p>Did we hit any cars or trucks? No.</p>\n",
      "<p>In my mind, I was quite fearful when I realized what he was going to try and do. He said that he had no fear because he had done this action many times and he “knew” that he could pull this one off.</p>\n",
      "<p>For an AI self-driving car, suppose it found itself in a similar situation.</p>\n",
      "<p>You might argue with me that the self-driving car would have been better prepared and would have gradually made its way over to the exit and not needed to leap toward it. But, suppose I told you that the occupant in the self-driving car had suddenly told the self-driving car that they wanted it to make that next exit.</p>\n",
      "<p>Thus, the self-driving car had little time to take the more gradual path to get to the exit.</p>\n",
      "<p>You could say that the AI should have refused to make the exit.</p>\n",
      "<p>The AI should have said that the occupant had been late in asking and so it was tough luck, and that instead the AI would route the self-driving car to the next exit and then via side streets make its way back to where that earlier exit had been.</p>\n",
      "<p>This brings up an important aspect about AI self-driving cars, namely, what is the nature of the driving approach that we want our self-driving cars to have?</p>\n",
      "<p>You might want the AI to do exactly what the “reckless” human driver had done, and have gone for it in terms of making a last gasp dive to the freeway exit. Why is the gradual approach better than the dive for it approach? You might assert that the gradual approach is certainly safer. By what proof do you claim this?</p>\n",
      "<p>In fact, those that believe we will have a Utopian world of all self-driving cars, which I’ve pointed out is unlikely and that at least for many decades we will have a mix of both human driven cars and self-driving cars, but if we do have all self-driving cars then presumably the dive to the exit would be as safe as any other maneuver.</p>\n",
      "<p>The self-driving car that wanted to dive to the exit could alert all the other self-driving cars nearby, via V2V (vehicle-to-vehicle communications), and the pathway that otherwise randomly had formed for the human driver might now become a designed path instead (based on the cooperation of the other self-driving cars).</p>\n",
      "<p>We could end-up with extremely aggressive AI self-driving cars.</p>\n",
      "<p>It all depends on how we program the AI and also what the AI is learning.</p>\n",
      "<p><strong>Machine Learning Subtly Captures Fear</strong></p>\n",
      "<p>Let’s consider the Machine Learning aspects of fear.</p>\n",
      "<p>Suppose you have an AI self-driving car that is learning about driving by observing traffic situations and trying to find patterns to the driving behavior, of which then the AI will adopt those same driving behaviors.</p>\n",
      "<p>In a traffic environment of reasonable human drivers that give proper way to other drivers and abide by legal speeds, the machine learning would find those patterns and presumably be a monkey-see monkey-do and perform driving in the same manner. We have artificial neural networks that indeed do this.</p>\n",
      "<p>Imagine driving in the chaotic streets of New York City at rush hour. Cars cut each other off. Cars drive within inches of other cars. Cars won’t let other cars into their lanes. It’s a dog eat dog world there. Without knowing the drivers, themselves, and by only looking at the outcomes of their driving, we have a different picture of what driving is all about.</p>\n",
      "<p>Deriving a pattern to driving behavior would be quite a contrast to a traffic environment of a more safety conscious wider-margins-for-error kinds of drivers.</p>\n",
      "<p>Thus, a neural network or other kind of machine learning will indirectly embody “fear” as it is embodied in the driving behavior of those that the system is learning from. We are not in this case of a machine learning approach explicitly calling out fear and making it part of the AI system as a separate component, and instead it is being captured via the behavior of the driving going on that is being used to pattern after.</p>\n",
      "<p>In one case, the fear of the drivers has led to more collegian driving outcomes, while in the other case the lesser sense of fear leads to cars that nearly hit or actually do include fender benders.</p>\n",
      "<p>We could though be more explicit about the fear aspects.</p>\n",
      "<p>The AI self-driving car has sensors that collect data for purposes of sensing the world around the self-driving car, and that data is then fed into the sensor fusion. The sensor fusion tries to figure out from the sensor data what is usable and what might not be, such as having a camera lens that is obscured by dirt and needing to rely instead on a radar that is able to detect that same area that the camera would. The sensor fusion then feeds into a virtual world model that depicts the existing and ongoing state of the surroundings and the self-driving car too.</p>\n",
      "<p>Based on the virtual world model, the AI needs to derive an action plan of what to do next with the self-driving car. If the situation involves accelerating to get between cars that are to the right of the self-driving car, this is then issued as commands to the controls of the self-driving car. As is the steering command to direct the self-driving car over into the next lane. And so on.</p>\n",
      "<p>It is within these AI action plans that we are immersing a healthy dose of fear.</p>\n",
      "<p>You want the self-driving car to be “fearful” of hitting other cars.</p>\n",
      "<p>You want it to be “fearful” of having other drivers hit the self-driving car.</p>\n",
      "<p>These are part of the algorithms of deriving the action plans.</p>\n",
      "<p>If the AI isn’t instructed or hasn’t learned to not hit other cars, it would likely come up with action plans that inevitably would be intentionally hitting other cars. Indeed, if you have ever watched a simulation that is used to train self-driving cars, you’ll see that the self-driving car action plans at first involve hitting other cars, but there is a points mechanism that helps the AI to realize that hitting other cars is not a good thing to do.</p>\n",
      "<p>By the use of Machine Learning, we are putting an “instinctive” landscape of fear into the AI of the self-driving car, and this is augmented by an explicitly taught landscape of fear by programming the AI code accordingly.</p>\n",
      "<p>Since we are on the topic of fear and AI self-driving cars, I should take a moment to also discuss a whole different aspect about fears and AI self-driving cars.</p>\n",
      "<p>There are humans that are fearful of being occupants in AI self-driving cars.</p>\n",
      "<p>I’ve discussed this at length in various forums and pointed out that though the media at times makes it seem that these are unfounded fears, I assert that people are right to have a healthy dose of fear about riding in today’s AI self-driving cars. Notice that I use the word “today’s” because I don’t want to suggest that we will always be fearful of riding in self-driving cars and instead differentiating that the existing crop of self-driving cars have yet to earn the right to have a low level of fear for occupants.</p>\n",
      "<p>On a similar vein, some humans are fearful about having AI self-driving cars on our roadways.</p>\n",
      "<p>This is due to a concern that the self-driving cars might hit other cars and strike pedestrians. Once again, I say these people are well justified in such a fear today. AI self-driving cars have yet to provide ample evidence to warrant our being fearless about how these self-driving cars might behave. I don’t believe this will be forever and just want to emphasize that it’s a condition of the state-of-the-art of what exists today.</p>\n",
      "<p>Returning back to my mainstay points about including fear into AI self-driving cars, I would want any self-driving car to have a reasonable fear of human drivers.</p>\n",
      "<p>Yes, that’s right, be fearful of human drivers. In the same manner that you or I are watching out for other human drivers, and we are leveraging our “fear” to gauge how we drive, it stands to reason that we want the AI self-driving cars to do the same. It needs to be a reasoned fear, and not an unfounded fear.</p>\n",
      "<p>As they say, once the AI has mastered the landscape of fear, the only fear it should have, will be fear itself.</p>\n",
      "<p><em>Copyright 2019 Dr. Lance Eliot </em></p>\n",
      "<p><em>This content is originally posted on AI Trends.</em></p>\n",
      "<p><a href=\"http://ai-selfdriving-cars.libsyn.com/website\"><img class=\"alignnone size-medium wp-image-17417\" src=\"https://www.aitrends.com/wp-content/uploads/2019/06/selfdrivingcarspodcastv2-300x150-300x150.jpg\" alt=\"\" width=\"300\" height=\"150\" /></a></p>\n",
      "\tTag: AI in Science\n",
      "\tTag: AI Research\n",
      "\tTag: Machine Learning\n",
      "\tTag: AI in science\n",
      "\tTag: ai research\n",
      "\tTag: machine learning\n",
      "\tTag: predictive analytics\n",
      "AI Being Used to Confront, Mediate Climate Change\n",
      "Thu, 17 Oct 2019 21:30:24 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />AI is being applied to the biggest challenge facing the planet &#8211; climate change. Early results are encouraging. Machine learning can be deployed in energy production, CO2 removal, education, solar geoengineering and finance, among 13 relevant answers according to a paper titled “Tackling Climate Change with Machine Learning, present at a workshop in June as [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18ClimateChange-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p>AI is being applied to the biggest challenge facing the planet &#8211; climate change. Early results are encouraging.</p>\n",
      "<p>Machine learning can be deployed in energy production, CO2 removal, education, solar geoengineering and finance, among 13 relevant answers according to a paper titled “Tackling Climate Change with Machine Learning, present at a workshop in June as a way to focus research, according to David Rolnick, a postdoctoral fellow at the University of Pennsylvania and one of the authors.</p>\n",
      "<p>“It’s surprising how many problems in machine learning can meaningfully contribute to,” said Rolnick, quoted in an account in <a href=\"https://www.nationalgeographic.com/environment/2019/07/artificial-intelligence-climate-change/\">National Geographic</a>. Possible outcomes include more energy-efficient buildings, new low-carbon materials, better monitoring of deforestation and greener transportation.</p>\n",
      "<p>Three specific areas where AI research could focus were suggested: better climate predictions, showing the effects of extreme weather and measuring where the carbon is coming from.</p>\n",
      "<p>Climate predictions can be enhanced by climate informatics, a discipline at the intersection of data science and climate science. It covers a range of topics including extreme events, reconstructing of past climate conditions, and large-scale models to be used for predictions. Climate modeling is progressing, with complex climate simulations having potential to unlock new insights.</p>\n",
      "<p>One project is using machine learning algorithms to combine the predictions of some 30 climate models used by the Intergovernmental Panel on Climate Change.</p>\n",
      "<p>Researchers at the Montreal Institute for Learning Algorithms (MILA), Microsoft and ConscientAI Labs are using General Adversarial Networks (GANs) to simulate what homes will look like after being damaged by rising sea levels and more intense storms. Plans include release of an app to show individuals what their neighborhoods and homes might look like with different climate change scenarios.</p>\n",
      "<p><strong>Banking Industry Also Studying Climate Change</strong></p>\n",
      "<p>A London-based not-for-profit consultancy called Caron Tracker is researching the impact of climate change on financial markets. It generates data by monitoring coal plant emissions with satellite imagery. Carbon Tracker is working to fulfill a UN goal of preventing new coal plants from being built by 2020. A grant from Google is expanding the effort to include emissions from natural gas plants, to help identify where pollution is coming from.</p>\n",
      "<p>“This can be used worldwide in places that aren’t monitoring,” said Durand D’souza, a data scientist at Carbon Tracker. “And we don’t have to ask permission.”</p>\n",
      "<p>Climate Change AI is an organization of volunteers from academia and industry discussing how computational science can mitigate climate change. Participants include Andrew Ng, co-founder of Google Brain, Deis Hassabis, a founder of DeepMind and Jennifer Chayes, managing director at Microsoft Research, according to an account in <a href=\"https://www.bbva.com/en/artificial-intelligence-an-ally-against-climate-change/\">BBVA</a>, serving the banking sector.</p>\n",
      "<p>AI is seen as helping improve the energy sector, where automated distribution networks can perform real-time smart assessments to fine tune supply and demand of electricity. Smart homes and intelligent operations and logistics in the construction industry, have the potential to lower the carbon footprint. Algorithms and machine learning make it possible to anticipate electricity demand of a city or a manufacturing plan months in advance. Power can potentially be distributed to small local populations more efficiently as a result.</p>\n",
      "<p>Google operates a fleet of wind farms in the US. Algorithms developed by Alphabet’s Deepmind researchers are able to predict wind farm energy 36 hours in advance, using advanced weather forecast technologies, now available.</p>\n",
      "<p>In transportation and logistics, data from the Intergovernmental Panel on Climate Change (IPCC) shows that between 1970 and 2004, the sector increased its greenhouse emissions by 120 percent. The potential is there for transportation companies to more accurately predict demand and avoid risks. DHL, the global logistics services provider, has developed software that can juggle up to 58 parameters to define optimal schedules for cargo airplanes days in advance. This should result in few flights.</p>\n",
      "<p><strong>UK Government Backing New Doctoral Research on Climate Change</strong></p>\n",
      "<p>The UK government is backing more research into climate change at Cambridge University, with a new doctoral training program on the Application of AI to the Study of Environmental Risks, to be led by Prof. Simon Redfern, head of the Department of Earth Sciences.</p>\n",
      "<p>The scientific community has access to larger datasets than ever before to help conduct this research. “These datasets represent a transformation in the way we can study and understand the Earth and environment, as we assess and find solutions to environmental risk,” said Redfern in an account in <a href=\"https://liwaiwai.com/2019/08/26/using-artificial-intelligence-to-avert-environmental-catastrophe/\">liwaiwai.com</a>, a site aimed at programmers. “Such huge datasets pose their own challenges, however, and new methods need to be developed to tap their potential and to use this information to guide our path away from environmental catastrophe.”</p>\n",
      "<p>Projects underway include the use of satellite observations to chart the distribution and pathways of whales through oceans, large datasets to understand biodiversity changes in woodland habitats, machine learning to understand earthquake risk,and the use of drones to monitor hazards at active volcanoes.</p>\n",
      "<p>See the source posts at <a href=\"https://www.nationalgeographic.com/environment/2019/07/artificial-intelligence-climate-change/\">National Geographic</a>,  <a href=\"https://www.bbva.com/en/artificial-intelligence-an-ally-against-climate-change/\">BBVA</a> and <a href=\"https://liwaiwai.com/2019/08/26/using-artificial-intelligence-to-avert-environmental-catastrophe/\">liwaiwai.com</a>.</p>\n",
      "\tTag: Executive Interviews\n",
      "\tTag: Health Care\n",
      "\tTag: Machine Learning\n",
      "\tTag: ethics and social issues\n",
      "\tTag: health care\n",
      "\tTag: machine learning\n",
      "Executive Interview: Dr. Angeli Moeller, AI Program Lead, Bayer Pharmaceuticals\n",
      "Thu, 17 Oct 2019 21:30:20 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />Focus is on AI as a tool that guides in the detection of diseases; lighthouse projects showing results; public-private partnerships helping with access to needed data Dr. Angeli Moeller has two roles at Bayer Pharmaceuticals, she co-leads the artificial intelligence work stream and is responsible for the research digital investment strategy. Before joining Bayer she [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-18Bayer-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p>Focus is on AI as a tool that guides in the detection of diseases; lighthouse projects showing results; public-private partnerships helping with access to needed data</p>\n",
      "<p><em>Dr. Angeli Moeller has two roles at Bayer Pharmaceuticals, she co-leads the artificial intelligence work stream and is responsible for the research digital investment strategy. Before joining Bayer she worked as a data scientist for translational medicine at Thomson Reuters and researcher at Cancer Research UK and the Max Delbrück Center for Molecular Medicine.</em></p>\n",
      "<p><em>As a keen proponent of pre-competitive collaboration, she also sits on the executive committee of the </em><a href=\"https://www.theaaih.org/\"><em>Alliance for Artificial Intelligence in Healthcare (AAIH)</em></a><em> and on the investment committee of the </em><a href=\"https://www.pistoiaalliance.org/\"><em>Pistoia Alliance.</em></a></p>\n",
      "<p><em>Moeller </em><em>is driving work at Bayer to employ AI to help get the right treatment to the right patient at the right time. Bayer Pharmaceuticals invests in lighthouse initiatives that use AI to drive top-line and bottom-line growth, while accelerating digital transformation. She recently spent a few minutes talking to AI Trends Editor John P. Desmond.</em></p>\n",
      "<p><strong>Could you describe your responsibilities at Bayer?</strong></p>\n",
      "<p>The IT business partnering team I lead is in the pharmaceutical research area, and it is responsible for the digital investments in both the pre-clinical area and investments that cover cross-R&amp;D projects. I took on that role in May last year, at which time I was also appointed co-lead of our artificial intelligence work stream for the entire pharmaceuticals division, a role I share with a colleague from the strategy team, Michael Heinke. The scope of the AI workstream encompasses R&amp;D, medical affairs and pharmacovigilance, commercial and product supply. The projects are run by several empowered teams working across our value chain, strongly supported by external partnerships, and enabled by our parallel data architecture workstream.</p>\n",
      "<figure id=\"attachment_18143\" style=\"width: 200px\" class=\"wp-caption alignleft\"><img class=\"size-medium wp-image-18143\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AngelieMoller-2-200x300.jpg\" alt=\"\" width=\"200\" height=\"300\" /><figcaption class=\"wp-caption-text\">Dr. Angeli Moeller, AI Program Lead, Bayer Pharmaceuticals</figcaption></figure>\n",
      "<p><strong>You have concentrations in your career in molecular biology, protein chemistry, and cell biology for example. What impact is new AI technologies having on those areas of research?</strong></p>\n",
      "<p>When I started my PhD at Edinburgh University, I was doing lab work coupled with informatics. We were getting so much data from our phage-display methods we were only able to make predictions leveraging bioinformatics. Subsequently in my post-doc, the value of predictions made possible through machine learning became increasingly critical. You can call it artificial intelligence or you can call it machine learning. At the time, it became clear to everyone working in molecular biology that you couldn&#8217;t just study molecular biology. You had to also be working in data science or informatics.</p>\n",
      "<p>The rise of AI in research has been triggered by two big trends. Firstly, that lab automation now creates datasets so large that we can make increasingly accurate predictions with methodologies like machine learning, because we now have the compute power needed. The other trend, which is driving things forward is translational research. For molecular biology, protein biochemistry and cell biology, it can be limiting to treat research as a sequential process, for instance to start <em>in vitro</em> then go into animal studies or human studies. During my time in academia we increasingly began building predictions from <em>in vivo </em>experiments and clinical studies, using meta-analysis across investigations conducted in the past. Although the need to validate predictions is still the critical next step.</p>\n",
      "<p>The rise of translational medicine and machine learning has completely changed the way that we can look at molecular biology and protein biochemistry. For example, in the first year of my PhD I looked at interactions between two or three proteins in detail whereas in my postdoc we worked on modeling the human chemical synapse and predicting protein-protein interactions. The parameters modelled came from mouse knock-out studies, genome-wide association studies, high-throughput cell line screening and only through integration of these varied data sets were we able to model the thousands of complex interactions at a single synapse. Now add to that a model of all synapses across the brain, at various timepoints in different states of activation and we can really start to tackle some interesting medical questions.</p>\n",
      "<p><strong>Could you describe one or more of the initiatives using AI to drive growth at Bayer?</strong></p>\n",
      "<p>Within Bayer, we have a series of AI projects with the shared objective of getting new medicines to patients more quickly and efficiently. To achieve this goal, our projects tackle various aspect of the value chain from drug development, to clinical development, to market access, to product supply, to commercial, to providing information to health care professionals and enabling reimbursement.</p>\n",
      "<p>One example is our CTEPH app, which got a breakthrough device designation from the FDA. It is based on an artificial neural network.</p>\n",
      "<p><em>[Ed. Note: Chronic Thromboembolic Pulmonary Hypertension (CTEPH) Pattern Recognition was given a </em><a href=\"https://media.bayer.com/baynews/baynews.nsf/id/FDA-grants-breakthrough-device-designation-artificial-intelligence-software-CTEPH-pattern\"><em>Breakthrough Device Designation </em></a><em>in December 2018 by the FDA.]</em></p>\n",
      "<p>CTEPH is an indication where patients have blood clots forming in their lungs. It manifests in symptoms where you have high blood pressure, shortness of breath or you feel very fatigued. These are also symptoms of other diseases so it can be very difficult to diagnose. But using our algorithm, which runs on the CT images of patients, we aim to detect very early whether or not patients are suffering from CTEPH. And then if they are suffering from CTEPH to make sure they get on the right treatment very quickly. For us it&#8217;s all about getting the right medicine to the right patient as quickly and as efficiently as possible.</p>\n",
      "<p>The second example is in the heart failure and stroke area. We have a collaboration with Sensyne, a startup operating in the UK, and the goal is to use data from several National Health Service Trusts to identify new biomarkers in heart failure and stroke. The team is exploring a range of machine learning approaches across those data sets.</p>\n",
      "<p><strong>What are some of the challenges you face in applying AI to healthcare in your research areas?</strong></p>\n",
      "<p>One key challenge is education. Many people fear that artificial intelligence will take away choice from patients and doctors. It’s important to us that AI is used as a tool that guides us in the detection of diseases and makes treatment recommendations. But in the end, the control over which treatments are given to which patients is still something that patients and their doctor decide together, using more accurate information to make that decision.</p>\n",
      "<p>We want to provide the most accurate information for the researchers who are developing the drugs, the doctors who are testing the drugs and prescribing the drugs, and for the patients who are being treated by the medicines. We don&#8217;t want to take away control of making decisions from anyone. And I think there it&#8217;s really important when we put the applications into clinical practice or into hospitals that we&#8217;re very careful to make sure that it&#8217;s used in the right way. So that in the end, the control of the decision-making processes is still with the doctor and their patient.</p>\n",
      "<p><strong>Are there any other challenges?</strong></p>\n",
      "<p>Getting access to the data we need is a very big challenge. For machine learning to be meaningful, you need very large data sets. However, we’re using a number of approaches that mean we don&#8217;t have to clean and curate the data sets to the extent we did in the past. Additionally, federated learning means that we can now train our models on data that is stored in different locations without moving the data. We train an algorithm behind the firewall of different data owners who ensure the security and integrity of the data, this allows the model to improve its predictive power using the data without having to put all the datasets together. Which is very important because for most patient data, it has to stay in a very secure local environment.</p>\n",
      "<p>But just trying to find enough data can be a daunting challenge. What’s going to be very important is establishing public-private partnerships, B2B partnerships, and academic partnerships, which will make safe access to data possible. This will drive forward innovative disease research using artificial intelligence.</p>\n",
      "<p><strong>What is the role of the Alliance for AI in healthcare that you helped to found?</strong></p>\n",
      "<p>The Alliance is dealing with exactly the challenge I mentioned earlier around education. Our core focus is to do that together with policy makers and academic thought leaders.</p>\n",
      "<p>We founded the Alliance because we wanted to stop this from being a competitive approach, and make it a pre-competitive approach where different companies work together to do what is in the best interest of the patients who can benefit from this new technology. That’s why within the AAIH you have large pharma and tech companies working together with university partners and biotech to try and tackle these issues.</p>\n",
      "<p>Our education committee works with member companies to create internships for students who want to move into AI in healthcare and to provide educational material useful for doctors who are starting to think about how they can use AI-based applications.</p>\n",
      "<p><strong>How has the role of IT changed, if at all, since the growth of AI technology at Bayer?</strong></p>\n",
      "<p>I work in IT. At some companies people would have asked “why is this person working in the IT department?” The answer is that at Bayer, IT teams must understand how emerging technologies can best be applied to meet the needs of the business, in my case the pharmaceutical division, therefore an increasing number of our hires have a data-science background often coupled with experience in an area of pharma, e.g. commercial, product supply or R&amp;D. Our pharma IT organization works in cross-disciplinary teams that include cloud-engineers, data scientists, biosample experts, bioinformaticians, clinical data managers, just to name a few.</p>\n",
      "<p><strong>How far along is it the digitization of pharma, would you say?</strong></p>\n",
      "<p>As an industry… it&#8217;s an interesting question. When I was at Thomson Reuters, which was only three years ago, I had clients which made up five of the largest pharmaceutical companies in the world. Now I sit in the Pistoia Alliance, in which 19 of the top pharma companies work together on pre-competitive projects. So based on those observation points, I’d say it&#8217;s very uneven. Some pharma companies are further ahead than others. Many have focused in certain areas and certain parts of the pharmaceutical process and not in others. I would say that, compared to other industries, we&#8217;re still just entering our digital journey, but I think some of us have understood that we must move at a highly accelerated rate to enact our digital transformation.</p>\n",
      "<p><strong>Are you able to find the people you need to get the AI work done at Bayer? What do you look for in new hires?</strong></p>\n",
      "<p>We are making really good hires, I have had the opportunity to work with new employees with extraordinary talent in the last year. But the market for data scientists is very competitive. There are not enough highly skilled machine learning experts in the world right now. This is why we’re working on the pipeline of talent coming out of universities, e. g. with internships we are creating with the Alliance for AI in Healthcare.</p>\n",
      "<p>We are also able to offer very good packages, which makes us an attractive employer. On a personal note, I&#8217;m the mother of a young child and I like to keep a healthy work-life balance. This is what Bayer has to offer and that helps us to attract talent.</p>\n",
      "<p>Another important point is that if you&#8217;re working on AI in healthcare, you always have a strong motivation for what you&#8217;re doing. Here we are implementing AI to help keep people healthy or to fight diseases like cancer. This makes a difference in comparison to pure tech companies.</p>\n",
      "<p>Most of our lighthouse case work on artificial intelligence is in cardiovascular disease and oncology right now. Many people have a loved one affected by diseases in these areas. For instance, my own family has a very high incidence of serious cardiac events. A lot of our work in artificial intelligence is still in early research stages, but knowing we’re working to have a positive impact on diagnosis and treatment is very rewarding.</p>\n",
      "<p><strong>Do you have any advice for young people interested in a career in AI for what they should study if they&#8217;re students, or if they&#8217;re early career where they should concentrate?</strong></p>\n",
      "<p>For young people entering their career, it&#8217;s critical to invest in your hard skills, e.g. statistics and programming. For people who have done that and are now looking to expand in their career in industry, it’s necessary to also demonstrate business understanding. If I look at my job today, it also involves discussions on financial impact, population health economics and a broader understanding of how a strategy for artificial intelligence can be developed. So I think then having more business insight is critical for that further career development. Lucky for me we have a lot of coaches and mentors at Bayer in senior positions who are always ready to support fellow employees developing new skills.</p>\n",
      "<p>Bayer is invested in helping young people start data science careers in healthcare. If any of your readers are interested, we have our job portal, we&#8217;re very active on LinkedIn, and we also host a lot of networking events.</p>\n",
      "<p><strong>Is there anything you would like to add?</strong></p>\n",
      "<p>I like to emphasize that we keep the patient at the center because I think it&#8217;s very easy to get swept up in the technology. If we keep the needs of the patient at the center of our strategy, then we’ll stay on the right track.</p>\n",
      "<p>Follow Angeli Moeller on <a href=\"https://de.linkedin.com/in/angelimoeller\">Linked</a><a href=\"https://de.linkedin.com/in/angelimoeller\">In</a>.</p>\n",
      "\tTag: AI Trends Insider on Autonomy\n",
      "\tTag: Robotics\n",
      "\tTag: Self Driving Cars\n",
      "\tTag: AI Trends Insider\n",
      "\tTag: autonomous cars\n",
      "\tTag: robot cars\n",
      "\tTag: robot taxis\n",
      "\tTag: robotics\n",
      "\tTag: self driving cars\n",
      "Open Source Cyber-Hacking and AI Autonomous Cars\n",
      "Tue, 15 Oct 2019 12:04:17 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider [Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/] You’ve likely had to enter a series of numbers and letters when accessing a web site that wanted “proof” that you are a human being [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-15Hacked-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Lance Eliot, the AI Trends Insider</em></p>\n",
      "<p><em>[Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: </em><a href=\"https://forbes.com/sites/lanceeliot/\"><em>https://forbes.com/sites/lanceeliot/</em></a><em>]</em></p>\n",
      "<p>You’ve likely had to enter a series of numbers and letters when accessing a web site that wanted “proof” that you are a human being and that you were not some kind of Internet bot. The typical approach involves your visual inspection of a grainy image that contains letters and numbers, and then having to try and figure out what those letters and numbers are.</p>\n",
      "<p>It is intentionally made difficult due to the aspect that the letters and numbers are usually smashed together, and they are often twisted and distorted so as to be hard to discern.</p>\n",
      "<p>These challenge-response tests are known as CAPTCHA, which is an acronym for &#8220;Completely Automated Public Turing test to tell Computers and Humans Apart.”</p>\n",
      "<p>The idea is that if a website wants to keep automated bots from accessing their site, there needs to be some means to differentiate between whether a human is trying to access the web site or whether it is some kind of automation.</p>\n",
      "<p>Humans are quite good at visually being able to discern letters and numbers, and so the CAPTCHA aids in distinguishing whether the response is va a human or a bot. Automated systems have a difficult time trying to ferret out amongst a twisted and distorted mix of letters and numbers the intended indication of what those distinct letters and numbers are.</p>\n",
      "<p>Some people don’t know why the CAPTCHA is being used and are pretty much just irritated by the whole thing.</p>\n",
      "<p>Why do I have to look at this stupid and obviously messed-up list of random letters and numbers, asks those that are not in-the-know.</p>\n",
      "<p>Makers of web sites are at times hesitant to use the CAPTCHA because it could dissuade people from using the web site and decrease the number of potential visitors to their site. But, those pesky automated bots that might otherwise become “false” visitors, meaning that the site might believe them to be actual humans, and also there are potential adverse aspects a bot might do at a web site, and so in the end it often is worthwhile to consider making use of CAPTCHA.</p>\n",
      "<p>Now, you might be puzzled that the CAPTCHA is not readily able to be hacked by automation.</p>\n",
      "<p>One might assume that with the tremendous advances in Artificial Intelligence (AI) in recent times, certainly there must be a means to figure out those grainy images via automation.</p>\n",
      "<p>Well, it depends partially on how strong the CAPTCHA is. If the CAPTCHA makes use of a varied combination of letters and numbers that are really swerved and mushed together, along with varying the height and width of the characters, and if the number of such characters is sizable enough, the ability for an AI system to figure it out is quite limited today.</p>\n",
      "<p>Of course, the worse it is for the AI also means that it is likely harder for humans to figure out too. And, if it gets too hard for humans, you’ll have neither bots nor humans being able to pass the test. That’s not very helpful in that it will simply prevent anyone or anything from succeeding – you might as well close down your web site since it won’t be accessible at all.</p>\n",
      "<p>To properly recognize the CAPTCHA, you need to perform at least three key visual and mental tasks:</p>\n",
      "<p>* Recognition</p>\n",
      "<p>You need to visually examine the image and recognize that there are letters and numbers in it.</p>\n",
      "<p>Any of the characters can be enlarged or shrunk in size, and can be at various angles. They can be stretched or squeezed together. The parts of one character might be merged with the parts of another character. The number of variations is seemingly endless of how the CAPTCHA can obscure conventional letters and numbers.</p>\n",
      "<p>Humans seem to be able to relatively easily handle these invariant recognition aspects, namely that we can very quickly realize the essence of a letter or number shape, in spite of the distortions made to it.</p>\n",
      "<p>* Segmentation</p>\n",
      "<p>If I show you a letter or number and it is displayed on a standalone basis, such as the letter “h” and the letter “e,” you have a much easier time generally of figuring it out.</p>\n",
      "<p>On the other hand, if I merge them with other letters and numbers, such as pushing together the “he” and making each flow into the other directly, it typically becomes harder to discern. The true shape of the letter or number becomes masked by its being merged with other letters and numbers.</p>\n",
      "<p>You need to be able to mentally disentangle the crammed together numbers and letters into a series of distinctive chunks, and within each chunk try to reconstruct what the individual letter or number might be.</p>\n",
      "<p>* Contextual</p>\n",
      "<p>By having multiple letters and numbers, you can often improve your odds of guessing any individual letter or number by considering the context of the characters within the overall image. That being said, many CAPTCHAs don’t use regular words, since it would make things perhaps too easy to guess the individual characters. If the letters were “d” “o” “g” and you were able to guess the first two letters, it might be overly easy to guess the third letter. If instead the letters were “d” “g” “o” then you might not so readily be able to guess the entire set of letters because it does not make into a word that you would normally recognize.</p>\n",
      "<p>There are numerous variations nowadays of CAPTCHA algorithms.</p>\n",
      "<p>Some use just letters and numbers, while some also add into the mix a variety of special characters such as an ampersand and a percentage symbol.</p>\n",
      "<p>You’ve likely also encountered CAPTCHA that ask you to pick images that have something in common. For example, you are presented with six images of a grassy outdoor field, and are asked to mark the images that have a horse shown in the image. These aren’t so easy because the horse will often be obscured or only a small portion of a horse appears in any given image.</p>\n",
      "<p>The reason why the acronym of CAPTCHA mentions a Turing test is that there is a famous test in the field of AI that was proposed by the mathematician Alan Turing about how to determine whether an automated system could exhibit intelligence.</p>\n",
      "<p>The test consists of having a human ask questions or essentially interview another human and a separate AI system, for which the interviewer is not privy beforehand as to which is which, and if the interviewer is unable to tell the difference between the two interviewees, we presumably could declare that the automation has exhibited intelligent behavior.</p>\n",
      "<p>There are some that are critical of this test and don’t believe it to be sufficient per se, but nonetheless it is quite famous and regarded by many as a key test for ascertaining AI.</p>\n",
      "<p>In the case of CAPTCHA, the Turing test approach is being used to see if humans can outwit a bot that might be trying to also pass the same test.</p>\n",
      "<p>Whomever is able to figure out the letters and numbers is considered or assumed to be a human. Thus, if the bot can indeed figure out the CAPTCHA, it momentarily has won this kind of Turing test. I think we would all agree that even if some kind of automation can succeed in winning in a CAPTCHA contest, we would be hard pressed to say that it has exhibited human intelligence. In that sense, this is a small and extremely narrow version of a Turing test and not really what we all truly intend a Turing test to be able to achieve.</p>\n",
      "<p>In fact, because the human is having to essentially prove they are a human by passing a CAPTCHA, some refer to this test as a Reverse Turing test.</p>\n",
      "<p>Here’s why.</p>\n",
      "<p>The limelight of a conventional Turing test is for the automation to prove it has human-like capabilities. In this reverse Turing test, it is up to the human to prove that they are a human and able to perform better than the automation.</p>\n",
      "<p>There is a popular CAPTCHA algorithm used as a plug-in for many WordPress developed websites that is known as “Really Simple CAPTCHA.”</p>\n",
      "<p>In a recent article about it, a developer showed how easy it can be to develop a simple AI system to be able to succeed at cracking the CAPTCHA challenges.</p>\n",
      "<p>The CAPTCHA in this case consisted of a string of 4 characters that used a mixture of four fonts, and it avoided using the letters “o” and “i” to reduce any confusion by the humans that have to try and figure out the CAPTCHA generated images. Notice that by these limitations it becomes a much smaller problem to be solved, in the sense that rather than say using a string of 10 characters and using 25 fonts, and by eliminating some of the letters, the solution space is a lot smaller than otherwise.</p>\n",
      "<p>The developer wanting to crack it used the popular Python programming language, along with the OpenCV set of programs that are freely available for doing image processing, and Keras which is a deep learning program written in Python. He also used TensorFlow, which is Google’s machine learning library of programs (Keras uses TensorFlow). I mention the tools herein to be able to emphasize that the developer used off-the-shelf programming tools. He didn’t need to resort to some “dark web” secretive code to be able to proceed to crack this CAPTCHA.</p>\n",
      "<p>The CAPTCHA program was readily available as open source and therefore the developer could inspect the code at will.</p>\n",
      "<p>He then used the CAPTCHA to generate numerous samples of CAPTCHA images, doing so to create a set of training data. The training data consisted of each generated image and its right answer. This could then allow a pattern-matching system such as an artificial neural network to compare each image to the right answer, and then try to statistically figure out a pattern for being able to go from the seemingly inscrutable image to the desired answer.</p>\n",
      "<p>After doing some transformations on the images, the developer fed the images into a neural network that he setup with two convolutional layers and with two hidden connected layers. According to his article, by just having ten passes through the training data set, the neural network was able to achieve full accuracy. He then tried it with actual new CAPTCHA generated by the “Really Simple CAPTCHA” code, and his efforts paid-off as it was able to figure out the letters and numbers. This particular article caught my eye due to the claim that from the start of this project to the finish it took just 15 minutes of time.</p>\n",
      "<p>Now please keep in mind that this was a very simple kind of CAPTCHA.</p>\n",
      "<p>I don’t want you to get a misleading impression that all CAPTCHA is as easy to crack as this.</p>\n",
      "<p>I assure you that there are CAPTCHAs today that nobody has any kind of AI or any software that can crack it with any kind of assurance or consistency. CAPTCHA is still a relatively good means to try and distinguish between a human and a bot. The CAPTCHA just has to be tough enough to weed out the commonly used methods of cracking the CAPTCHA.  By convention, CAPTCHA is normally made available as open source code.</p>\n",
      "<p>Thus, some would say that it increases the chances of being able to crack it.</p>\n",
      "<p>What does this have to do with AI self-driving driverless autonomous cars?</p>\n",
      "<p>At the Cybernetic AI Self-Driving Car Institute, we are using open source software to develop AI self-driving systems, and so are most of the self-driving car makers and tech firms, and this is both a boon and a danger.</p>\n",
      "<p>As discussed about the CAPTCHA algorithm, it was available as open source, meaning that the source code for it was publicly available. Anyone that wanted to look at the source code can do so.</p>\n",
      "<p>By looking at the source code, you can figure out how it works. By figuring out how it works, you are a leg-up on being able to find ways to crack it.</p>\n",
      "<p>If you don’t use open source code, and instead develop your own proprietary code, you can try to keep the source code secret and therefore it is much harder for someone else to figure out how it works.</p>\n",
      "<p>If an attacker does not know how the code works, it becomes much harder to try and crack it. This does not mean it is impossible to crack it, but merely that it is likely going to be harder to crack it.</p>\n",
      "<p>Some refer to the open source approach as a white box method, while the proprietary code approach as a black box method. With a black box method, though you know what comes into and out of it, you don’t know what is going on inside the box to do so. Meanwhile, with a white box method, you know what goes into it and comes out, along with how it is doing its magic too.</p>\n",
      "<p>Today, open source code is prevalent and found in an estimated 95% of all computer servers, along with being used in high profile systems such as the systems that run stock exchanges and the systems that run the International Space Station. Some estimates say that there is at least 30 billion lines of open source code available, but even that number might be understated.</p>\n",
      "<p>Notably, open source is extensively used for AI software and many of the most popular AI packages today are available as open source.</p>\n",
      "<p>Generally, there is an ongoing debate about the use of open source as to whether it is unsafe because of the potential for nefarious hackers to be able to readily inspect the code and find ways to hack it, or whether it is maybe safer than even proprietary software because you can have so many eyes inspecting it.</p>\n",
      "<p>Presumably, something that is open to anyone to inspect can be seen by hundreds, thousands, maybe millions of developers, and that such a large number of reviewers will ensure that the open source code is safe and sound to use.</p>\n",
      "<p>One caveat about using open source is the classic use-it-and-forget-it aspect that arises for many developers that decide to use open source code in their own systems.</p>\n",
      "<p>Developers will go ahead and wrap the open source into a system they are building, and pretty much move on to other things. Meanwhile, if a hole is spotted in the publicly posted open source, and if there is a fix applied to the hole, the developer that grabbed the open source at an earlier time might not be aware of the need to apply the fix in their instance. This can happen readily by the aspect that the developer forgets they used that particular open source, or maybe they don’t become aware of the fix, or they no longer have anything to do with the developed proprietary code and others that are maintaining it don’t know that it includes the open source portions.</p>\n",
      "<p>One of the most infamous cases of open source being exploited consists of the Heartbleed computer security hole that was discovered in the OpenSSL cryptographic source code.</p>\n",
      "<p>In OpenSSL, there is a part of the code that sends a so-called heartbeat request from one system to another system. This is an important program that is used by most web sites to ensure a secure connection, such as for doing your online banking.</p>\n",
      "<p>When making the request, the requesting system would normally send a message of one size, let’s say 10 characters in size, and expect to get back the same message also of 10 characters in size. Turns out that if the requesting system sent a message that asked to get back 300 characters but only sent 10 characters, the system providing the response would be misled into sending back 300 characters &#8212; of which, 290 of those characters might contain something sensitive from that system inadvertently. In programming parlance, this is often referred to as a buffer over-read problem.</p>\n",
      "<p>In 2014, this hole immediately became headline news once it was pointed out.</p>\n",
      "<p>The significance of the hole was that it made zillions of interacting systems that were thought to be secure to potentially not be so secure.</p>\n",
      "<p>The clever name of “heart bleed” was given to this security hole, since it is related to the heartbeat portion of the systems and was now essentially bleeding out secure info. The hole was quickly plugged, and the matter was logged into the global registry of Common Vulnerabilities and Exposures (CVE) database for everyone to know about. Nonetheless, many did not right away apply the fix to their systems, even though they should have done so.</p>\n",
      "<p>Currently, most of the automakers and tech firms are feverishly incorporating all sorts of open source into their AI of their self-driving cars systems.</p>\n",
      "<p>It makes sense to do so, since otherwise you would need to reinvent the wheel on all sorts of software aspects that are needed for a self-driving car.</p>\n",
      "<p>The cost to develop that same open source from scratch would be enormous. And, it would take time, lots of time, in order to create that same code. That’s time that nobody has. Indeed, there is a madcap rush today to achieve a true self-driving car, and no one developing self-driving cars wants to be left behind due to writing code that they could otherwise easily and freely get.</p>\n",
      "<p>We do need to ask some serious questions about this.</p>\n",
      "<p>Does the use of open source in the AI and the other software of the self-driving cars mean that we are laying ourselves bare for a substantial and really ugly security problem down-the-road, so to speak?</p>\n",
      "<p>Some would say, yes.</p>\n",
      "<p>Are there nefarious hackers that are right now inspecting the self-driving car open source code and looking for exploits?</p>\n",
      "<p>Some would say, yes.</p>\n",
      "<p>If they are looking for exploits, there’s not much reason right now for them to reveal those holes, and so they presumably would wait until the day comes that there are enough self-driving cars on the roads to make it worthwhile to use such an exploit. Plus, once self-driving cars do become popular, it is likely to attract hackers at that time to begin inspecting the open source code, hopeful of finding some adverse “golden nugget” of a hole.</p>\n",
      "<p>This open source conundrum exists for all aspects of self-driving cars, including:</p>\n",
      "<ul>\n",
      "<li>Sensors – open source software for sensor device control and use</li>\n",
      "<li>Sensor Fusion – open source software for sensor fusion</li>\n",
      "<li>Virtual World Model – open source software for virtual world modeling</li>\n",
      "<li>Action Planning – open source software for creating AI action plans</li>\n",
      "<li>Controls Activation – open source software to activate the car controls</li>\n",
      "<li>Tactical AI – open source software for self-driving car tactical AI</li>\n",
      "<li>Strategic AI – open source software for self-driving car strategic AI</li>\n",
      "<li>Self-Aware AI – open source software for self-driving car self-aware AI</li>\n",
      "</ul>\n",
      "<p>Depending upon how a particular car maker or tech firm is building their self-driving car, each element is likely to either have open source in it, or be based upon some open source.</p>\n",
      "<p>It is incumbent upon the self-driving car industry to realize the potential for exposures and risks due to the use of open source.</p>\n",
      "<p>Self-driving car developers need to be make sure they are closely inspecting their open source code and not just blindly making use of it.</p>\n",
      "<p>Any patches or fixes need to be kept on top of. We need more audits of the open source code that is being used in self-driving cars. And, overall, we need more eyeballs on reviewing the open source code that underlies self-driving cars. As mentioned earlier, it is hoped that the more “good” eyeballs involved will mean that any holes or issues will be caught and fixed before the “bad” eyeballs find them and exploit those holes.</p>\n",
      "<p>If the bad eyeballs have their way, it will be not so much a CAPTCHA as a GOTCHA.</p>\n",
      "<p><em>Copyright 2019 Dr. Lance Eliot </em></p>\n",
      "<p><em>This content is originally posted on AI Trends.</em></p>\n",
      "<p><a href=\"http://ai-selfdriving-cars.libsyn.com/website\"><img class=\"alignnone size-medium wp-image-17417\" src=\"https://www.aitrends.com/wp-content/uploads/2019/06/selfdrivingcarspodcastv2-300x150-300x150.jpg\" alt=\"\" width=\"300\" height=\"150\" /></a></p>\n",
      "\tTag: AI and Business Strategy\n",
      "\tTag: AI and IT Services\n",
      "\tTag: Software Development\n",
      "\tTag: AI and business strategy\n",
      "\tTag: AI and IT services\n",
      "\tTag: AI application deployment\n",
      "\tTag: data science\n",
      "\tTag: software development\n",
      "AI Has Changed the Game for Service Providers\n",
      "Thu, 10 Oct 2019 21:30:43 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By John P. Desmond, AI Trends Editor AI has changed the game for service providers. Client companies now expect the service provider will deliver on the promise of AI for them, or help them get moving in the right direction. We spoke about trends in AI and services to executives of two service providers recently: [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11AIandServices-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By John P. Desmond, AI Trends Editor</em></p>\n",
      "<p>AI has changed the game for service providers. Client companies now expect the service provider will deliver on the promise of AI for them, or help them get moving in the right direction. We spoke about trends in AI and services to executives of two service providers recently: Asheesh Mehra, co-founder and CEO of AntWorks; and Prabhdeep (PD) Singh, VP of AI at UiPath.</p>\n",
      "<p>AntWorks, founded in 2015, is an AI and intelligent automation company, with a platform that understands every data type. The company digitizes every bit of information from a wide range of industries. Mehra is co-founder and group CEO; his background includes seven years at Infosys working in business process outsourcing in Asia Pacific, Japan, and the Middle East. The company offers the ANTstein intelligent automation. It supports robotic process automation support, intuitive machine learning, and natural language modeling capabilities.</p>\n",
      "<p>UiPath of New York City is an AI enterprise software company known for AI, machine learning, and Robotic Process Automation. The company was recently positioned in the upper right Leaders quadrant in Gartner Magic Quadrant for Robotic Process Automation Software.  Prabhdeep (PD) Singh, VP of AI at UiPath, was at Microsoft for nearly 10 years before coming to UiPath a year ago. He led the product and business teams for the Microsoft Sales Intelligence AI solution.</p>\n",
      "<p>Mehra and Singh were interviewed separately by AI Trends Editor John P. Desmond.</p>\n",
      "<p><strong>How has AI changed the game for service providers?</strong></p>\n",
      "<p><strong>Asheesh Mehra, co-founder and CEO of AntWorks</strong>: Some customers expect AI to be a magic wand that can start delivering results overnight. However, an AI engine is not magic. It needs training at the back end before it can start performing an action. It can start learning from the representative data set that is received over a few months. Then it can start its machine learning capability to help make intelligent decisions, or start predicting or inferring dependent of the representative data set it has seen over the months it has been deployed at an enterprise.</p>\n",
      "<p>So, is it changing expectations of customers? The answer is absolutely, yes. Some expectations are realistic, and some expectations are unrealistic. Is it impacting the end customer of enterprises? It is. In some ways it&#8217;s impacting them by making their lives, their day-to-day jobs a lot easier because it is now a helping hand, or a joint force with the human. When you put both together, you get a far superior outcome.</p>\n",
      "<figure id=\"attachment_18146\" style=\"width: 198px\" class=\"wp-caption alignleft\"><img class=\" wp-image-18146\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-18AshofAntWorks-2.jpg\" alt=\"\" width=\"198\" height=\"297\" /><figcaption class=\"wp-caption-text\">Asheesh Mehra, co-founder and CEO, AntWorks</figcaption></figure>\n",
      "<p><strong>Prabhdeep (PD) Singh, VP of AI at UiPath: </strong>The way the older service providers would typically solve business problems would be to have a human sitting in some back room doing this stuff for you manually. But now the automation has reached a stage—and the set of technologies that are available to us have reached a stage—where you can optimize pretty much every and any business process. If you remember, the name of the game for these BPO [Business Process Outsourcing] providers was to get down the cost. That&#8217;s why you couldn&#8217;t run call centers here in the US, because the cost of employing humans was just too high.</p>\n",
      "<p>That&#8217;s when people started going to places like India, Vietnam, and all these other places where you had English-speaking populations, but it was much cheaper to hire people. It was more of this cost optimization, cost-cutting exercise. With AI and automation coming in, there is a paradigm shift happening in the sense that you can actually increase the productivity of those humans and drive down the costs even more. We talk about this in almost every conference that I&#8217;ve gone to. If you look at the workforce productivity for the US over the last decade, it has pretty much plateaued. After we had a saturation of PCs, pretty much for all and every knowledge worker. And now in order to increase the productivity of those information workers in the workforce, you need more of AI and automation. We are seeing that, and many of our customers are getting monetary and productivity gains by automating and deploying AI in their business processes.</p>\n",
      "<p><strong>Is AI delivering?</strong></p>\n",
      "<p><strong>Mehra of AntWorks</strong>: That&#8217;s a very loaded and very difficult question to answer. Yes, it&#8217;s delivering in certain spaces and in certain areas. I think AI is over-hyped and not delivering in certain other cases. If I had to use an example from the insurance world, I think AI is delivering on its promise for processing claims, being for your health, or your house, or your car. It is delivering there. There is room for AI to be improved and enhanced to deliver the outcome it is promising in some other industries, such as financial services.</p>\n",
      "<p>If I was to summarize that, I&#8217;d put the bar right in the center and say depending on the use case and depending on the industry segment, AI is delivering; and for where AI is not delivering, it has not been exposed and trained enough in those spaces.</p>\n",
      "<p><strong>Singh of UiPath</strong>: When AI works, it&#8217;s magical. I&#8217;ve seen it work in both large companies and small startups. I&#8217;ve seen it save lives. I worked on systems that can do things like readmission prediction. It can predict if a patient is going to come back within 30 days, and the doctors can look at it and say, &#8220;Okay, let&#8217;s not discharge this patient right now.&#8221; If you have a system like that, you&#8217;re actually saving lives, because you&#8217;re not sending really sick patients home where adverse things can happen to them. You&#8217;re also saving money, because if you look at the Medicare/Medicaid guidelines, if the patient comes back within 30 days, the government is not going to reimburse you for the readmission.</p>\n",
      "<figure id=\"attachment_18110\" style=\"width: 200px\" class=\"wp-caption alignright\"><img class=\"size-full wp-image-18110\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/9-10PDSingh-2.jpg\" alt=\"\" width=\"200\" height=\"200\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/9-10PDSingh-2.jpg 200w, https://www.aitrends.com/wp-content/uploads/2019/10/9-10PDSingh-2-120x120.jpg 120w\" sizes=\"(max-width: 200px) 100vw, 200px\" /><figcaption class=\"wp-caption-text\">Prabhdeep (PD) Singh, VP of AI at UiPath</figcaption></figure>\n",
      "<p>The problem right now in the AI industry is what we call the last mile problem. If you look at the AI deployments, only 4% of CIOs have put something in production. Almost 90% to 95% of CIOs want to do something with AI. They know kind of where AI can be useful. Actually putting a system into production is a completely different beast. So once you have a machine learning model that works, you need to put it into production, have it interact with humans, with the existing applications. That&#8217;s where RPA [Robotic Process Automation] is useful, because RPA is the last mile vehicle for all things AI.</p>\n",
      "<p><strong>Are there problems for which AI is not a fit?</strong></p>\n",
      "<p><strong>Mehra of AntWorks:</strong> If you take a step back and ask what is AI, the definition varies. In my view, AI is all about learning and then a machine taking intelligent decisions or providing accurate predictions on the data that it has received. Do we say, &#8220;No&#8221; to customers when we think we or the AI is not equipped? The answer is absolutely, yes. We do say, &#8220;No&#8221; to customers when we think we cannot deliver a particular piece using our machine learning or other algorithms. Because as I said, the expectation might be that AI is a magic wand.</p>\n",
      "<p>The fundamental philosophy at AntWorks is, &#8220;Say no where you have to say it. When you say &#8216;yes&#8217;, get it right the first time.&#8221;</p>\n",
      "<p>Can AI be deployed in every single use case in an enterprise? The answer is no. I don&#8217;t think AI is mature enough to go out there and solve every kind of challenge today that an enterprise experiences. We see a lot of room for the AI engines to be trained to become smarter and more intelligent to deliver to customer expectations.</p>\n",
      "<p><strong>Singh of UiPath: </strong>I will say, the things that are non-digitized are problems that you cannot optimize with AI. You see many AI use cases in sales and marketing, because sales and marketing is highly digital. If an industry has gone through digital transformation, that&#8217;s where AI can be very useful. But if you have antiquated processes, and you actually never digitized, then it&#8217;s a little difficult. For example, if there was a company doing everything paper-based and old school very well, the first process is to get that paper scanned and put it in digital format before you can apply anything intelligent on top of that information.</p>\n",
      "<p><strong>Do AI engagements take more time than the former non-AI way of solving problems?</strong></p>\n",
      "<p><strong>Mehra of AntWorks: </strong>No, absolutely not. One of the whole drivers to make a business case positive is to cut the time it takes to do projects. The whole objective is to speed up the business process and to ensure that accuracy is a lot higher. So does it take more time? The answer is no. If it does take more time, it&#8217;s probably taking a lot more time because not enough training has been done for the engine and it has been deployed prematurely.</p>\n",
      "<p>No different to when you bring a human being into an enterprise, the first four weeks of them coming in or the first three weeks or the first six weeks, is to train that individual on how to perform their job, or how to deliver that outcome. An AI engine is no different. If you expect an AI engine to start delivering the results that you&#8217;re expecting without spending enough time on training the engine, it will not deliver for you.</p>\n",
      "<p>So the marketplace needs to understand how to make your AI or machine learning engine deliver results for you. There are no shortcuts. You need to invest the right amount of time and expose the AI engine to the right amount of representative data for it to deliver results for you.</p>\n",
      "<p><strong>Singh of UiPath: </strong> I would say no. If you planned your system correctly, it&#8217;s much easier to solve problems and much more effective to solve problems with AI versus the older way. For example, if you remember the old school real estate agents, there were good agents and there were bad agents. The really good sales people didn&#8217;t need any of these electronic nannies and electronic aids like CRM systems. They were just going in, doing it the old school way, pounding the pavement, being really good at selling stuff.</p>\n",
      "<p>My point is if you have a problem which is highly dependent on human expertise, it will take time to have AI go in and improve it. But if there is a process where you are not realizing the human efficiencies to the maximum, that is where AI can make a big difference.</p>\n",
      "<p><strong>What are your challenges?</strong></p>\n",
      "<p><strong>Mehra of AntWorks: </strong>I have a few challenges today. One of my first challenges is market share. I&#8217;m a four year old company. I&#8217;m against all the names from a competition perspective. They&#8217;ve all been around for longer, have captured a large market share and I&#8217;m playing catch up. So we took time to build the technology and the whole platform out while they were out there selling single technology tool sets. So now it&#8217;s my turn to capture market share.</p>\n",
      "<p>My second challenge is that the understanding level of the buyer varies to a large extent. On a scale of one to 10, a very large percentage of buyers are at three and below. There is a very small percentage of buyers that are in the seven, eight, nine, and 10, from a rating perspective. That starts becoming a challenge because the expectations that they have, and what reality is are a vast distance apart. So we need to deploy larger resources to help educate the marketplace.</p>\n",
      "<p>The third challenge is around the expectation of what AI is. There is just so much hype and white noise in this whole AI space right now. This puts pressure on you as a product company because people dream up things and it becomes a challenge. The minute you start pushing back, and say, &#8220;That&#8217;s not really what we can deliver, or a machine can deploy&#8221;, you start creating a sense of dissatisfaction in the buyer community. But you are being realistic. So, that truly is another challenge for me. Those are the three challenges for me today.</p>\n",
      "<p><strong>Singh of UiPath: </strong>Once you start deploying these systems in an enterprise at a very large scale, a couple of things happen. Enterprise software is a very well-understood area. The people who deploy software and applications in their enterprise, with traditional software applications, have a very well-understood product. With AI applications, it&#8217;s not just a matter of deploying software. AI models work off of data. The data must be clean, the data pipelines need to run properly, and the AI models need to work well. That whole vision is our principle. If, for example, the data shuts off at the input, the model starts behaving completely differently. For example, I had this vision readmission model, and it uses a patient feed which was giving it the economic data of the patient. And so we know that people who are low income patients, they have a higher risk of readmissions, and also if you&#8217;re not getting that feed, the model won&#8217;t be confident enough in making these predictions. It might go completely haywire. So scaling AI is a big challenge.</p>\n",
      "<p>We have a discipline called DevOps to address the way traditional software is handled in the enterprise. What we need is a DevOps equivalent for AI. We in the industry call it MLOps, or machine learning ops. It&#8217;s basically the discipline around practices to manage, deploy, and create these models in a structured way. One of the offerings in our product, AI Fabric, is an MLOps system for the data scientists, who might not really understand enterprise software deployment cycles. We simplify it for them. We say, &#8220;You just create a model, the rest of the stuff on the deployment, DevOps, MLOps side, we will take care of.&#8221; So deploying AI applications in the real world we have seen as a challenge.</p>\n",
      "<p>The third challenge, I would say, is the ROI quantification. The business owner needs to know the impact of putting the machine learning model into production. Is it hurting or improving the overall business? You need a system which can quantify the return on investment when you&#8217;re deploying AI. Typically, you would use BI tools for this. We are working on having an embedded analytics or BI offering, to give customers this ROI visibility. You need that quantification system in place.</p>\n",
      "<p><strong>What does the future hold for your company and for AI in business? Where is it going?</strong></p>\n",
      "<p><strong>Mehra of AntWorks: </strong>John, we&#8217;re super excited. I&#8217;m speaking to you today from a delivery center in Bengal. I&#8217;ve just spent the whole day sitting next to my developers, talking to my product leads and the head of my product, and it&#8217;s just super exciting. It scares me when I look at possibilities that are in store for us over the next six, 12, and 24 months, and just what machines can do if trained correctly or if deployed correctly. I&#8217;m super excited about the next two years also. We&#8217;ve grown more than 350% in the last quarter and a half.</p>\n",
      "<p>I did a Town Hall [in India] this afternoon and the last time I was here a quarter ago, I had, I think, 40 people. Today I addressed 165 people. I&#8217;m hiring people to support customer demand.  So, there is a huge amount of potential and growth. Over the next 12-24 months, we are looking at dramatic growth. Automation and AI are in the top three agenda items of every Fortune 500 board today. We are addressing that challenge for those organizations.</p>\n",
      "<p>While there is a huge opportunity, all the organizations in this space need to be responsible to not over commit and under deliver, because that will start taking away the belief in what AI machine learning and automation can do.</p>\n",
      "<p><strong>Singh of UiPath: </strong>I&#8217;ll be honest with you, where we stand right now as a company, as an industry, I see a whole tsunami coming our way. It&#8217;s not a bad tsunami; it&#8217;s a good one. Right now, most of these enterprises, they&#8217;ve just gone through digital transformation. They&#8217;re putting all these new-fangled systems in place. You have Salesforce for your sales system. You have Microsoft office. You have different cloud applications that you put in production. I can name you many companies, for example oil companies, they have completely digitized processes now, for even things like drilling reports. CPG [consumer packaged goods] companies who have digital processes for designing the labels that go on to their products. They also have inventory management systems and logistics management systems.</p>\n",
      "<p>They&#8217;ve just put these systems in place. The next thing, or the next ROI that they want to get out of the digital transformation, is to try machine learning and some automation. They want to try putting AI in some of these processes, to inject some automation and AI, to see if they can make them more efficient. I would say in the post-digital transformation era, the future for RPA and AI looks really great. These will be the technologies that are at the cutting edge of this post-digital transformation age.</p>\n",
      "<p>Learn more at <a href=\"https://www.ant.works/\">AntWorks </a>and at <a href=\"https://www.uipath.com/\">UiPath</a>.</p>\n",
      "\tTag: AI in Business\n",
      "\tTag: AI in Industry\n",
      "\tTag: Self Driving Cars\n",
      "\tTag: ai in business\n",
      "\tTag: cloud services\n",
      "\tTag: predictive maintenance\n",
      "\tTag: self driving cars\n",
      "Advanced Car Safety Systems Using AI Delivering for Motorists Today\n",
      "Thu, 10 Oct 2019 21:30:39 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By AI Trends Staff Advanced safety systems using AI are being delivered in cars today, whether the customer asks for them or not. This is big business, with the value of AI in automotive manufacturing and cloud services projected to exceed $10.7 billion by 2024. Reaction to the new systems from the auto consumer public [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11ADASImpact-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By AI Trends Staff</em></p>\n",
      "<p>Advanced safety systems using AI are being delivered in cars today, whether the customer asks for them or not. This is big business, with the value of AI in automotive manufacturing and cloud services projected to exceed $10.7 billion by 2024.</p>\n",
      "<p>Reaction to the new systems from the auto consumer public is mostly positive based on reactions seen so far.</p>\n",
      "<p>When a deer jumped in front of a 2017 Subaru Outback being driven in Skokie, Ill, recently, the vehicle came to a complete stop on its own, before the driver could react, according to an account in <a href=\"https://www.consumerreports.org/automotive-technology/car-safety-systems-that-could-save-your-life/\">Consumer Reports</a>, based on a survey of Advanced Driver Assistance Systems (ADAS). &#8220;Without the car&#8217;s automatic emergency braking system, I&#8217;d have hit the deer, no question about it,&#8221; the driver said.</p>\n",
      "<p>Consumer Reports readers were asked about their experiences with ADAS in their vehicles, including forward collision warning (FCW), automatic emergency braking (AEB) and blind spot warning (BSW). Some 57% of respondents reported at least one ADAS feature had prevented them from getting into a crash. The respondents provided data on some 72,000 vehicles.</p>\n",
      "<p>ADAS systems have increased substantially in the last 10 years in cars sold in the US, starting with FCW and AEB, then extending to BSW, lane departure warning (LDW), lane keeping assist (LKA) and more recently, pedestrian detection systems (PDS).</p>\n",
      "<p>Jake Fisher, senior director of auto testing for Consumer Reports, was quoted as saying, &#8220;Our survey results show that in the real world, these systems are creating positive outcomes in situations that only a few short years ago would have ended in costly and tragic results.&#8221;</p>\n",
      "<p>Manufacturers vary on the ADAS features included in new cars, whether they charge extra for them or supply them as standard equipment.</p>\n",
      "<p>Survey respondents had the highest satisfaction with AEB, adaptive cruise control (ACC), and BSW. Respondents were least satisfied with lane-keeping features, owing to &#8220;annoying&#8221; alert chimes, vibrations, or aggressive steering corrections. The dissatisfaction led owners to disable those features more frequently than others.</p>\n",
      "<p>BSW was the feature that drivers credited with most often keeping them out of a crash; 60% said BSW had prevented a collision.</p>\n",
      "<p><strong>General Motors Research with U of Michigan</strong></p>\n",
      "<p>General Motors conducted research on ADAS features with the University of Michigan Transportation Research Institute, that showed several of the features are helping to reduce car crashes in a statistically significant way, according to an account in <a href=\"https://www.greencarcongress.com/driver-assistance-systems/\">Green Car Congress</a>.</p>\n",
      "<p>The study included 3.7 million GM vehicles across 20 different models from 2013 to 2017. Some 15 different ADAS systems were evaluated using police report crash databases from 10 states.</p>\n",
      "<p>Among the findings:</p>\n",
      "<ul>\n",
      "<li>Automatic Emergency Braking (or Forward Automatic Braking) with Forward Collision Alert reduced rear-end striking crashes by 46%.</li>\n",
      "<li>Lane Keep Assist with Lane Departure Warning reduced lane departure-related crashes by 20%.</li>\n",
      "<li>Lane Change Alert with Side Blind Zone Alert reduced lane change crashes by 26%.</li>\n",
      "<li>Rear Vision Camera alone, Rear Park Assist functionality, Rear Cross Traffic Alert (which nearly always includes the two previous backing features) and Reverse Automatic Braking (which includes all the previous backing features) produced, respectively, an estimated 21%, 38%, 52%, and an 81% reduction in backing crashes.</li>\n",
      "<li>IntelliBeam and High-Intensity Discharge headlight features provided 35% and 21% reductions, respectively, in nighttime pedestrian/bicyclist/animal crashes, with a 49% reduction when offered together.</li>\n",
      "</ul>\n",
      "<p>&#8220;The results show that the GM active safety systems evaluated are addressing a wide range of common crashes that cause a staggering amount of injuries, property damage and cost to our customers and society, putting GM well on its way toward a vision of zero crashes,&#8221; said Raymond Kiefer, GM Safety Technical Fellow.</p>\n",
      "<p><strong>Predictive Maintenance, Driver Recognition Coming</strong></p>\n",
      "<p>Related benefits to drivers from AI plugging into the auto world include better ability to do predictive maintenance. Volkswagen and Microsoft announced in October 2018 a partnership to tap the power of Azure IoT, PowerBI and Skype to gather data that could indicate a pending component failure, long before the failure actually happens, according to an account on a blog from <a href=\"https://igniteoutsourcing.com/automotive/artificial-intelligence-in-automotive-industry/\">Ignite</a>, an automotive and AI service provider. Plans are for all vehicles to receive Over the Air (OTA) software updates as well.</p>\n",
      "<p>Driver recognition systems are also making headway. An Israeli automotive computer vision startup, eyeSight, uses AI and deep learning in cameras and sensors that monitor driver behavior. This includes observations of eye gaze, eye openness, and head position. The system can alert the driver to keep eyes on the road, and attempt to wake up the driver if necessary. Contextual controls allow eyeSight to tailor the content of a Heads-Up-Display according to where the driver&#8217;s eyes are focused. Upper body detection reflects the driver&#8217;s posture.</p>\n",
      "<p>Read the source accounts in <a href=\"https://www.consumerreports.org/automotive-technology/car-safety-systems-that-could-save-your-life/\">Consumer Reports</a>, <a href=\"https://www.greencarcongress.com/driver-assistance-systems/\">Green Car Congress</a> and at  <a href=\"https://igniteoutsourcing.com/automotive/artificial-intelligence-in-automotive-industry/\">Ignite</a>.</p>\n",
      "\tTag: Health Care\n",
      "\tTag: Machine Learning\n",
      "\tTag: Predictive Analytics\n",
      "\tTag: AI in healthcare\n",
      "\tTag: data analysis\n",
      "\tTag: health care\n",
      "\tTag: machine learning\n",
      "\tTag: predictive analytics\n",
      "New AI Model Predicts Clinical Translation Of Biomedical Research\n",
      "Thu, 10 Oct 2019 21:30:29 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Benjamin Ross, Editor, AI Trends The US National Institutes of Health (NIH)&#8217;s Office of Portfolio Analysis (OPA) has developed a machine learning model that predicts whether a scientific advance is likely to translate to the clinic. The model, described in a recent study published in PLOS Biology (DOI:https://doi.org/10.1371/journal.pbio.3000416), determines the likelihood that a research [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11NewNIHModel-1-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Benjamin Ross, Editor, AI Trends</em></p>\n",
      "<p>The US National Institutes of Health (NIH)&#8217;s Office of Portfolio Analysis (OPA) has developed a machine learning model that predicts whether a scientific advance is likely to translate to the clinic. The model, described in a recent study published in <em>PLOS Biology</em> (DOI:https://doi.org/10.1371/journal.pbio.3000416), determines the likelihood that a research article will be cited by a future clinical trial or guideline, which OPA labels as early indicators of translational progress.</p>\n",
      "<p>Developed by OPA Director George Santangelo and colleagues, the model qualifies predictions using a novel metric called &#8220;Approximate Potential to Translate&#8221; (APT). &#8220;We found that distinct knowledge flow trajectories are linked to papers that either succeed or fail to influence clinical research,&#8221; the study&#8217;s authors write. &#8220;Translational progress in biomedicine can therefore be assessed and predicted&#8230; based on information conveyed by the scientific community&#8217;s early reaction to a paper.&#8221;</p>\n",
      "<p>The development of APT values comes as the NIH launches the second version of its <em>iCite</em> tool, a web application that provides a panel of bibliometric information for journal publications within a defined analysis group. The APT values will be freely and publicly available as new components of <em>iCite</em>.</p>\n",
      "<p>Clinical research is a long, arduous process, the authors say, possibly taking decades for a discovery to translate into improvements in human health. This presents challenges when assessing and guiding the translation of the bench-to-bedside process.</p>\n",
      "<p>Santangelo tells <em>AI Trends</em> that machine learning presented an opportunity to get a better read on the likelihood that papers would move into the clinic.</p>\n",
      "<p>&#8220;The work started to develop in terms of seeing if we could find a method that would give us an earlier read on what to expect from different parts of the biomedical research landscape in terms of citation by clinical trials or guidelines as evidence that things were moving into the clinic.&#8221;</p>\n",
      "<p>As the team began to apply their APT values to existing data, Santangelo says nuanced patterns began to emerge as key predictors for translational progress.</p>\n",
      "<p>&#8220;I think the most important one that we focus on is the diversity of interest from across the fundamental to clinical research axis,&#8221; he says. &#8220;When people across that axis — from fundamental scientists often in the same field as the work that&#8217;s being published, all the way to people in the clinic — show an interest in the form of citations in those papers, then the likelihood of eventual citation by a clinical trial or guideline is quite high.&#8221;</p>\n",
      "<p>These indicators have proven to be effective, Santangelo and his colleagues argue, writing that &#8220;as little as 2 years [post publication] data yield accurate predictions about a paper&#8217;s eventual citation by a clinical article.&#8221;</p>\n",
      "<p>&#8220;We can now get a sense of what&#8217;s happening in the literature without as dramatic a censoring effect [a condition in which the value of a measurement is only partially known], which allows us to be more forward looking in understanding what areas of research are more likely to draw interest from clinically-focused scientists,&#8221; Santangelo says.</p>\n",
      "<p><strong>Breaking Down The Paywall</strong></p>\n",
      "<p>In addition to APT values, the <em>iCite</em> webtool will offer the NIH&#8217;s Open Citation Collection (NIH-OCC), a free public access database for biomedical research. The database currently comprises over 420 million citation links, with additional citations accumulating monthly.</p>\n",
      "<p>Santangelo says the database offers a solution to proprietary, restrictive, and often costly licensing agreements that have been a barrier to collaborative research.</p>\n",
      "<p>&#8220;These days there really isn&#8217;t a good justification for keeping [this data] behind a paywall, especially with the issues of data quality,&#8221; says Santangelo. &#8220;We recognized early on that, if we were publishing something, we were using a proprietary source for the raw data, and that others would not be able to calculate the values without working with us on a subset of the data. That never sat easy with us.&#8221;</p>\n",
      "<p>The NIH-OCC offers researchers the chance to access the raw data. &#8220;There&#8217;s no better check on data quality than that,&#8221; Santangelo says.</p>\n",
      "<p>In a Community Page article in <em>PLOS Biology</em> (DOI:https://doi.org/10.1371/journal.pbio.3000385), Santangelo and his co-authors say the NIH-OCC dataset has been generated from unrestricted data sources such as MedLine, PubMed Central, and CrossRef, as well as &#8220;data from a machine learning pipeline that identifies, extracts, resolves, and disambiguates authors in references from full-text articles available on the internet.&#8221;</p>\n",
      "<p>Santangelo says there&#8217;s a standing invitation for data sharing. &#8220;We&#8217;re data sponges,&#8221; he says. &#8220;We&#8217;ll take data from wherever we can find it.&#8221;</p>\n",
      "<p>Learn more at <a href=\"https://dpcpsi.nih.gov/opa\">Office of Portfolio Analysis.</a></p>\n",
      "\tTag: AI Trends Insider on Autonomy\n",
      "\tTag: Robotics\n",
      "\tTag: Self Driving Cars\n",
      "\tTag: AI Trends Insider\n",
      "\tTag: autonomous cars\n",
      "\tTag: robot cars\n",
      "\tTag: robot taxis\n",
      "\tTag: robotics\n",
      "\tTag: self driving cars\n",
      "Robust Ugly Zone Scenarios For AI Autonomous Cars\n",
      "Thu, 10 Oct 2019 21:30:27 +0000\n",
      "Benjamin Ross\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" />By Lance Eliot, the AI Trends Insider Is he a man or a machine? That was asked about Francesco Molinari when he won the 2018 Open Golf Championship and earned himself nearly $2 million in prize money. It was his first major golf victory and it was the first time that the now 147th annual [&#8230;]\n",
      "<img width=\"100\" height=\"70\" src=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"float: left; margin-right: 5px;\" link_thumbnail=\"\" srcset=\"https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-100x70.jpg 100w, https://www.aitrends.com/wp-content/uploads/2019/10/10-11UglyZone-2-218x150.jpg 218w\" sizes=\"(max-width: 100px) 100vw, 100px\" /><p><em>By Lance Eliot, the AI Trends Insider</em></p>\n",
      "<p>Is he a man or a machine?</p>\n",
      "<p>That was asked about Francesco Molinari when he won the 2018 Open Golf Championship and earned himself nearly $2 million in prize money.</p>\n",
      "<p>It was his first major golf victory and it was the first time that the now 147<sup>th</sup> annual golf tournament was won by an Italian (there was a lot of celebrating in Italy!).</p>\n",
      "<p>How did he achieve the win?</p>\n",
      "<p>You could say that it was years upon years of other golf competitions and smaller wins that led to this big win.</p>\n",
      "<p>Or, you could say it was maybe the weather conditions and the mood and skills of the other golfers at the tournament that converged to let him be the best on that particular occasion.</p>\n",
      "<p>Presumably, you could say it was random chance, or maybe that he had a lucky charm.</p>\n",
      "<p>Would you be willing to say it was due to practice?</p>\n",
      "<p>As they famous joke goes, how do you get to Carnegie Hall – via practice, practice, practice.</p>\n",
      "<p>Francesco is known for being a slave to practicing.</p>\n",
      "<p>Of course, the odds are that many of the other golfers there had put in as many hours practicing as he has. It stands to reason that golfers at that level of play are practicing all of the time, day and night. They likely dream about golf. They likely are mentally playing golf when they eat lunch or dinner. It&#8217;s an all-consuming passion for most of them.</p>\n",
      "<p>If they are all practicing about the same amount of the time, perhaps the nature of how they practice might account for some of the differences in their playing levels. Just because I say that I practice, it doesn&#8217;t indicate in what manner I practice. For almost any kind of practices, you can take a varied approach to how you practice.</p>\n",
      "<p>I used to play tennis when I was in college. My practices often involved hitting tennis balls against a wall for hours on end. When I could find someone to play against, I&#8217;d certainly do a practice game, but at other times it was solo practicing that took place. Is the potential outcome of the solo practicing as good as doing actual practice games? You can debate the matter. The practice games are certainly more akin to what will occur when playing a match game, and so it seems logical that the practice game is a better form of practice. On the other hand, the repetition of hitting hundreds of times back-and-forth against a wall does build-up your arm and body in a manner that a practice game cannot.</p>\n",
      "<p>Francesco realized about two years ago that he needed to do something to boost his golf game.</p>\n",
      "<p>He had been a professional golfer for more than a dozen years and had been an amateur champion before turning pro. But, he had not yet reached the top echelon of the winner&#8217;s circle of professional players. Would it take some kind of voodoo magic to push him to the top? Did he have to make changes to how he perceived golf and played golf.</p>\n",
      "<p>He opted to radically change his practice routines.</p>\n",
      "<p>He entered into the ugly zone.</p>\n",
      "<p><strong>Introducing The Notion Of An Ugly Zone</strong></p>\n",
      "<p>For those of you familiar with the Twilight Zone (the old TV series), I suppose the ugly zone sounds somewhat like it.</p>\n",
      "<p>There&#8217;s nothing especially odd about the ugly zone though. The concept is relatively straightforward.</p>\n",
      "<p>When practicing any kind of skill, you are to do so with a maximum amount of pressure, perhaps even more so than what you&#8217;ll experience during live competition play.</p>\n",
      "<p>The goal is to make practices as rough and tough as a real match.</p>\n",
      "<p>Maybe even more so.</p>\n",
      "<p>When I used to help coach my son&#8217;s Little League baseball team, we often had rather acrimonious debates among the coaches and assistant coaches about whether the practices should be easy or hard.</p>\n",
      "<p>There were some coaches that said we should be easy on the kids and provide a supportive environment for them to learn baseball and hone their skills. It was about fun. It was about falling in love with the sport. We knew in contrast that the actual games would be pressure cookers, so the practices would hopefully serve as a means to inspire them towards becoming proficient baseball players.</p>\n",
      "<p>If you&#8217;ve not been to a Little League baseball game, allow me to open your eyes. You&#8217;ve got the doting parents that want their kids to win no matter what it takes. Many hope that their child will someday become a big league player, getting the fat paychecks and the out sized fame.</p>\n",
      "<p>Some of the eager parents had a different but similarly high pressure perspective, namely they thought that winning was the key to life, and they didn&#8217;t care that it was a baseball game per se. Instead, it was that their child needed to discover that winning is good and losing is bad.</p>\n",
      "<p>It wasn&#8217;t so important that the child was able to swing a bat &#8212; what was really paramount was that you must win however you can achieve it – this includes maybe swinging a bat, or catching a fly ball, or tricking the opposing team, screaming at the other team, spitting on the other team, you name it (all&#8217;s fair in love and war, and baseball).</p>\n",
      "<p>Should the practices be like the games?</p>\n",
      "<p>Would it be better to have the boys experience the crazed high pressures of a real game during their practices, or would that distract them from the needed step-at-a-time of learning their craft?</p>\n",
      "<p>Maybe doing high pressure practices would make them emotionally upset and they would become disgruntled about playing the sport entirely. They&#8217;d also have no opportunity to try out new techniques. They&#8217;d be constantly under the gun, so to speak.</p>\n",
      "<p>You&#8217;ll find this next anecdote amusing (or, maybe serious!).</p>\n",
      "<p>One of the coaches suggested that we setup loudspeakers at practice that would blare out the sounds of a typical game audience, including a recorded cacophony of loudmouthed spectators yelling and screaming, doing so during the practices (side note, we opted to not do that). This would help re-create the setting of actual games, apparently.</p>\n",
      "<p>Anyway, there are some that philosophically believe that practices need to be conducted in a high pressure manner that aligns with the pressures encountered during competitive matches.</p>\n",
      "<p>Of course, maybe doing this with Little League kids is not the right audience. Perhaps we might say that this approach is more suitable to adults. Furthermore, adults that are already versed in their craft, rather than someone just starting out to gain a new skill.</p>\n",
      "<p>Well, I realize that some of you that believe in the ugly zone approach will maybe disagree with me and my list of carve out exceptions, and you&#8217;ll insist that the ugly zone is always applicable, regardless of age, skill level, etc.</p>\n",
      "<p>Fine, have it your way.</p>\n",
      "<p>Let&#8217;s agree to disagree, and continue on, thanks.</p>\n",
      "<p><strong>Desirable Difficulty Is King</strong></p>\n",
      "<p>Francesco shifted his practices two years prior to his incredible win into becoming near torture tests.</p>\n",
      "<p>His new coach embodied the ugly zone philosophy and emphasized that the frustration level had to be equal to a real game or possibly higher than a real game.</p>\n",
      "<p>The more annoyed that Francesco became with his coach, the more the coach knew he was doing something right in terms of making practices hard. Every practice golf shot was considered vital. No more of the traditional hitting golf balls with your clubs for mindless hours on end. Instead, all sorts of complicated shots and series of shots were devised for practices.</p>\n",
      "<p>There you are on the putting green, practicing. You are 8 feet away from the hole. You try to make the putt, but miss the hole. It&#8217;s practice, so you just shrug your shoulders, you try to figure out what went wrong, and you then casually setup to do the same shot again. Not so with the ugly zone. That 8-foot putt is for the golden trophy, every time. If you miss the hole, you are done for. You are a failure. You must take each and every putt with somber seriousness. If you happen to make the putt the first time, that&#8217;s not good enough. Do it again. Indeed, do it five times in a row, flawlessly.</p>\n",
      "<p>Some psychologists suggest that adding challenges to practices tends to boost the long-term impacts of the practices.</p>\n",
      "<p>It is often referred to as desirable difficulty.</p>\n",
      "<p>As mentioned earlier, you might perceive that this challenges factor should be for all of the practices and all of the time of the practices, or you might believe that it should be done in a more measured fashion, just for some of the practices and maybe for just some of the time of those practices.</p>\n",
      "<p>Let&#8217;s take a slightly different angle on this ugly zone notion.</p>\n",
      "<p>Suppose you had practices that never were in the ugly zone.</p>\n",
      "<p>So far, I&#8217;ve mentioned the belief by some that the practices should always and exclusively be in the ugly zone. The opposite tack perhaps would be to never use the ugly zone approach at all. I&#8217;ve seen this happen in some contexts.</p>\n",
      "<p>For example, I was helping a group of middle school students learn about robotics as they were getting ready for a robotics competition.</p>\n",
      "<p>A fellow mentor was purposely having them avoid encountering any problems while practicing writing code to program the robots for doing various tasks. I took him aside and gently pointed out that we ought to have the kids experience some issues or errors, so that they&#8217;d be ready during the live competition. He insisted that any kind of difficulty would mar their learning and rebuffed my suggestion. Sadly, things didn&#8217;t go very well for them during the live competition and they were baffled as to what to do when their robots faltered.</p>\n",
      "<p>So, I&#8217;d generally argue that you need some amount of ugly zone involved in practicing.</p>\n",
      "<p>I suppose that I&#8217;m the Goldilocks kind of practices person. It should be not too much ugly zone, and nor too little ugly zone. Just the right amount of ugly zone is the aim. And, crucially, having no ugly zone at all is likely an unfortunate and perhaps misguided omission that undermines the overall utility of the practices.</p>\n",
      "<p>The ugly zone proponents contend that you need to learn how to think and act under pressure.</p>\n",
      "<p>They say that if you are the type of person that gets butterflies in your stomach during live competitions, you need to hone your skills so that instead of expunging the butterflies that you instead learn to shape them so they fly in a formation. Use the pressure to overcome your fears. Use the pressure as a kind of high octane juice. That&#8217;s what the ugly zone is supposed to achieve.</p>\n",
      "<p><strong>AI Autonomous Cars And Ugly Zones</strong></p>\n",
      "<p>What does this have to do with AI self-driving driverless autonomous cars?</p>\n",
      "<p>At the Cybernetic AI Self-Driving Car Institute, we are developing AI software for self-driving cars. In addition, we make use of a wide variety of techniques and one of those that we advocate is the use of the ugly zone.</p>\n",
      "<p>Allow me to explain.</p>\n",
      "<p>Many of the auto makers and tech firms that are making AI self-driving cars are doing testing in these ways:</p>\n",
      "<ul>\n",
      "<li>Use of simulations</li>\n",
      "<li>Use of proving grounds</li>\n",
      "<li>Use on public roads</li>\n",
      "</ul>\n",
      "<p>For my article about the use of simulations for AI self-driving cars, see: <a href=\"https://aitrends.com/selfdrivingcars/simulations-self-driving-cars-machine-learning-without-fear/\">https://aitrends.com/selfdrivingcars/simulations-self-driving-cars-machine-learning-without-fear/</a></p>\n",
      "<p>For my article about providing grounds for AI self-driving cars, see: <a href=\"https://aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/</a></p>\n",
      "<p>When an AI self-driving car is being &#8220;tested&#8221; on public roads, this means it is being done in a relatively uncontrolled environment and that presumably just about anything can happen.</p>\n",
      "<p>On the one hand, this is good because there might be that &#8220;unexpected&#8221; aspect that arises and for which it is then handy to see how well the AI can respond to the matter. On the other hand, you might go hundreds, thousands, or millions of miles using the AI self-driving car and not encounter these plausible rare occasions at all, thus, in that sense, the AI self-driving car will not be tested readily on such facets.</p>\n",
      "<p>There&#8217;s also the rather obvious but worth stating point that doing &#8220;testing&#8221; of AI self-driving cars while on public roads is something of a dicey proposition. If the AI is unable to appropriately respond to something that occurs, the public at large could be endangered. Suppose a man on a pogo stick suddenly appears in front of the AI self-driving car and the AI does not know what to do, and perhaps hits and injures the man – that&#8217;s not good.</p>\n",
      "<p>See my article about the Uber crash incident that killed a pedestrian: <a href=\"https://aitrends.com/selfdrivingcars/initial-forensic-analysis/\">https://aitrends.com/selfdrivingcars/initial-forensic-analysis/</a></p>\n",
      "<p>And, my follow-up article about the Uber crash: <a href=\"https://aitrends.com/selfdrivingcars/ntsb-releases-initial-report-on-fatal-uber-pedestrian-crash-dr-lance-eliot-seen-as-prescient/\">https://aitrends.com/selfdrivingcars/ntsb-releases-initial-report-on-fatal-uber-pedestrian-crash-dr-lance-eliot-seen-as-prescient/</a></p>\n",
      "<p>As I&#8217;ve mentioned many times, there are some AI developers that have an &#8220;egocentric&#8221; perspective about AI self-driving cars and seem to think that if someone does something &#8220;stupid&#8221; like pogoing in front of a self-driving car that they get what they deserve (this will doom the emergence AI self-driving cars, I assure you).</p>\n",
      "<p>There is also some sense of false security by many of the auto makers and tech firms that having a human back-up driver during public roadway testing is a sure way of avoiding any adverse incidents. This is quite a myth or misunderstanding, and there is still a bona fide chance that even with a human back-up driver that things can go awry for an AI self-driving car.</p>\n",
      "<p>See my article about egocentric designers for AI self-driving cars: <a href=\"https://aitrends.com/selfdrivingcars/egocentric-design-and-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/egocentric-design-and-ai-self-driving-cars/</a></p>\n",
      "<p>For my article about the dangers even with a human back-up driver, please see: <a href=\"https://aitrends.com/selfdrivingcars/human-back-up-drivers-for-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/human-back-up-drivers-for-ai-self-driving-cars/</a></p>\n",
      "<p>Another aspect of doing testing on public roadways is that it might be difficult to reproduce the instance of what happened. I mention this because trying to do Machine Learning (ML) via only one example of something is quite difficult to do. It would be handy to be able to undertake the situation a multitude of times in order to try and arrive at a &#8220;best&#8221; or at least better way to respond. I&#8217;ve stated in my industry speeches that we&#8217;re suffering from a kind of irreproducibility in the AI self-driving car realm and for which inhibits or staggers potential progress.</p>\n",
      "<p>For more about irreproducibility, see my article: <a href=\"https://aitrends.com/selfdrivingcars/irreproducibility-and-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/irreproducibility-and-ai-self-driving-cars/</a></p>\n",
      "<p>For my overall framework about AI self-driving cars, see: <a href=\"https://aitrends.com/selfdrivingcars/framework-ai-self-driving-driverless-cars-big-picture/\">https://aitrends.com/selfdrivingcars/framework-ai-self-driving-driverless-cars-big-picture/</a></p>\n",
      "<p>As perhaps is evident, doing testing on public roadways has some disadvantages.</p>\n",
      "<p>That&#8217;s why it is vital to also do testing via the other means possible, including using simulations and using proving grounds.</p>\n",
      "<p>For simulations, you can presumably run the AI through zillions of scenarios. There&#8217;s almost no limit to what you could try to test. The main constraint would be the computational cycles needed. Some auto makers and tech firms are even using supercomputers for their simulations, similar to how such high-powered computing is being used to gauge the impacts of climate change or other large-scale problems.</p>\n",
      "<p>Not everyone though necessarily believes that the simulations are true to the real-world and thus the question is posed whether the AI reacting in a simulated environment is actually the same as it will react while on the roadways. If you are simulating climate change and your simulation is a bit off-base by estimates being made, this is likely Okay. But, if you are dealing with AI self-driving cars, which are multi-ton beasts that can produce instantaneous life-or-death consequences, a simulation that isn&#8217;t true to the real-world does not give one a full sense of confidence in the results.</p>\n",
      "<p>In essence, if I told you that I had an AI self-driving car that has successfully passed a simulation of over one-hundred million miles of car driving, albeit only in a computer-based simulation, and never been on an actual road, would you be happy to see it now placed into public use, or unhappy, or disturbed, or what?</p>\n",
      "<p>I think it&#8217;s fair to say that you&#8217;d be concerned.</p>\n",
      "<p>There&#8217;s also the potential use of proving grounds.</p>\n",
      "<p>See my article about proving grounds and self-driving cars: <a href=\"https://www.aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/\">https://www.aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/</a></p>\n",
      "<p>This is usually private land or sometimes government land that is set aside for the purposes of testing AI self-driving cars.</p>\n",
      "<p>You could say that in some ways it is better than simulations because it has a real-world aspect to it.</p>\n",
      "<p>You could also say that this is safer than being on the public roadways since it is in an area that avoids potential harm to the general public.</p>\n",
      "<p>I recently had a chance to closely explore a well-known proving ground, namely the American Center for Mobility (ACM) in Michigan, and spoke with the CEO and President, Michael Noblett, along with getting a specially guided tour of the facility by Angela Flood, Executive Director.</p>\n",
      "<p>The ACM consists of over 500-acres, offering multiple test environments adjacent to the Willow Run Airport. There is about 2.5 miles of an extensive driving loop that contains high-speed usable highway roads and two tri-level overpasses. It is an impressive facility and available for commercial purposes, governmental purposes, and usable too by standards bodies and colleges.</p>\n",
      "<p>For more info about the ACM, see: <a href=\"https://www.acmwillowrun.org/learn-about-the-facility/\">https://www.acmwillowrun.org/learn-about-the-facility/</a></p>\n",
      "<p><strong>Creating Ugly Zones In All Modes</strong></p>\n",
      "<p>Generally, it seems apparent that you&#8217;d want to use a combination of simulations, proving grounds, and public roadways for developing and testing of your AI self-driving car.</p>\n",
      "<p>Each approach has its own merits, and each approach has its own drawbacks.</p>\n",
      "<p>In combination, you can aim to get more kinds of testing that will hopefully lead to sounder AI self-driving cars.</p>\n",
      "<p>Let&#8217;s now revisit the ugly zone.</p>\n",
      "<p>For real-world driving of an AI self-driving car, as mentioned earlier, the AI might go for many miles without ever encountering some really difficult driving situations. Any such instances would presumably occur by happenstance, if at all. With a providing ground, you can possibly setup the AI for having to cope with quite ugly situations. Same goes for the use of simulations.</p>\n",
      "<p>Regrettably, there are some auto makers and tech firms that are not pushing their AI to the limits via the use of the proving grounds and nor the simulations. They seem to believe that the focus should be the &#8220;normal&#8221; conditions of driving.</p>\n",
      "<p>For example, at a proving ground, the AI self-driving car is driving on a road and all of a sudden a woman pushing a baby stroller carriage starts to walk across the street (this might be a stunt woman hired for this purpose, and the baby stroller is empty other than a fake doll). The AI self-driving car detects the motions and objects involved, i.e., the adult female and the stroller, and deftly swerves to avoid them. AI saves the day! Case closed, the AI is prepared for such a scenario.</p>\n",
      "<p>This seems convincing as a test.</p>\n",
      "<p>You might mark-off on your checklist and claim that the AI can detect a person with a baby stroller and take the right kind of action to avoid a calamity.</p>\n",
      "<p>There are though additional considerations.</p>\n",
      "<p>How many other cars were on the road with the AI self-driving car?</p>\n",
      "<p>In this case, none.</p>\n",
      "<p>Was there a car directly next to the AI self-driving car that would have been potentially in the way of the swerving action?</p>\n",
      "<p>Not in this case.</p>\n",
      "<p>Were there other pedestrians also trying to cross the street at the same time as the woman and the stroller?</p>\n",
      "<p>No, just the woman and the stroller.</p>\n",
      "<p>Were there any road signs warning about an upcoming hazard or perhaps any orange cones in the road due to roadway repairs being made? No.</p>\n",
      "<p>And so on.</p>\n",
      "<p>I think we would all feel a bit more confident in the testing of avoiding the woman with the baby stroller if we believed it was done in a more high-pressure situation.</p>\n",
      "<p>Imagine if the AI self-driving car had other cars all around it, boxing it in, and meanwhile there were lots of other pedestrians near to or approaching the self-driving car, and the road itself was a mess, and a lot of things were happening all at once. That&#8217;s more telling about what the AI can cope with.</p>\n",
      "<p>Having a simplified, stripped down situation with an otherwise barren road, and just the woman and the stroller, does not seem like much of a test per se.</p>\n",
      "<p>It&#8217;s not anything close to being an ugly zone.</p>\n",
      "<p>Don&#8217;t misunderstand my point. I&#8217;m fine with the stripped down test as one such test.</p>\n",
      "<p>But, if that&#8217;s going to be the nature of the testing that&#8217;s taking place, it would seem like there&#8217;s no provision for the ugly zone.</p>\n",
      "<p>Recall that I earlier mentioned that having a practice without any kind of ugly zone would seem to be a practice that has a substantial omission and we ought to question the validity of the practice overall.</p>\n",
      "<p>For AI self-driving cars, we should definitely have ugly zone testing (or, if you prefer, we can say &#8220;practices&#8221; rather than &#8220;testing&#8221;).</p>\n",
      "<p>Should you use only and always ugly zones?</p>\n",
      "<p>Well, as I mentioned previously, I&#8217;m an advocate for a measured amount of practice time for sometimes having ugly zones and sometimes not.</p>\n",
      "<p>My Goldilocks viewpoint is to have a combination of times with and without the ugly zones. But, however you allocate the time, there must be some amount of ugly zone practice.</p>\n",
      "<p>Avoidance of using an ugly zone approach in undertaking practices for AI self-driving cars is a scary and understated form of practice and will pretty much &#8220;guarantee&#8221; the failure of AI self-driving cars in the real-world.</p>\n",
      "<p>Per my framework, these are the key AI self-driving car driving tasks:</p>\n",
      "<ul>\n",
      "<li>Sensor data collection and interpretation</li>\n",
      "<li>Sensor fusion</li>\n",
      "<li>Virtual world model updating</li>\n",
      "<li>AI action planning</li>\n",
      "<li>Cars control commands issuance</li>\n",
      "</ul>\n",
      "<p>The ugly zone is a means to see how well each of those AI elements are able to perform. Furthermore, you want to see how well they each individually work as a semi-independent component, along with how they work in concert together to drive the self-driving car. Therefore, the ugly zone needs to have a varied and myriad of aspects that will put &#8220;pressure&#8221; on each of the components.</p>\n",
      "<p>You might wonder how you can &#8220;pressure&#8221; an AI system, since it&#8217;s not like a human wherein you can pressure a human to get into a tizzy by throwing all sorts of things at them at once. Actually, in some ways, you can indeed pressure the AI system by doing likewise of what you&#8217;d do to a human, namely, pile-on as many things as you can, and see what the AI does. The internal timing of the AI system needs to be taxed to see that it can handle a multitude of simultaneous things happening on the roadway at the same time and in the same place.</p>\n",
      "<p>For my article about the cognition timing of real-time AI systems, please see: <a href=\"https://aitrends.com/selfdrivingcars/cognitive-timing-for-ai-self-driving-cars/\">https://aitrends.com/selfdrivingcars/cognitive-timing-for-ai-self-driving-cars/</a></p>\n",
      "<p><strong>Conclusion </strong></p>\n",
      "<p>We believe in the ugly zone approach for AI self-driving cars.</p>\n",
      "<p>Let&#8217;s create as tough an environment as feasible so that once the AI self-driving car is on the public roadways, it&#8217;s a piece of cake.</p>\n",
      "<p>True stress testing should be done in all means feasible and not wait until the AI self-driving car is in a public place and for which public harm can occur.</p>\n",
      "<p>Whether you want to put your own children into an ugly zone for their piano practices or for their art lessons, that&#8217;s up to you.</p>\n",
      "<p>I think we can all agree that we&#8217;d believe more so in the potential of AI self-driving cars to be trustworthy on our streets if we knew that they had survived, learned from, and were adept at dealing with ugly zones.</p>\n",
      "<p>Go, ugly zones, go.</p>\n",
      "<p><em>Copyright 2019 Dr. Lance Eliot </em></p>\n",
      "<p><em>This content is originally posted on AI Trends.</em></p>\n",
      "<p><a href=\"http://ai-selfdriving-cars.libsyn.com/website\"><img class=\"alignnone size-medium wp-image-17417\" src=\"https://www.aitrends.com/wp-content/uploads/2019/06/selfdrivingcarspodcastv2-300x150-300x150.jpg\" alt=\"\" width=\"300\" height=\"150\" /></a></p>\n"
     ]
    }
   ],
   "source": [
    "print(ai_trends['feed']['title'])\n",
    "print(ai_trends['feed']['subtitle'])\n",
    "print(ai_trends['feed']['updated'])\n",
    "\n",
    "for entry in ai_trends.entries:\n",
    "    for term in entry.tags:\n",
    "        print(f\"\\tTag: {term.term}\")\n",
    "        \n",
    "    print(f\"{entry.title}\\r\\n{entry.published}\\r\\n{entry.author}\")\n",
    "    print(entry.summary)\n",
    "    \n",
    "    for content in entry.content:\n",
    "        print(content.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, there are a couple of things to look at here in the above example. We're doing a lot, and it seems like there will be more to do.\n",
    "\n",
    "1. The `feed` tag is the parent of the feed parse. It contains the information for the feed, including the title, subtitle and when it was last updated\n",
    "2. Each feed has a list of entries, the entries are the actual content we'll be looking at\n",
    "> for each piece of content, we'll want to look at the tags and see if it's related to AI, ML, or what ever to make sure it's something we're actually interested in. This should be configurable\n",
    "3. After we've determined that we're interested in this particular piece of content, we'll want to grab:\n",
    "    * title of the article\n",
    "    * author of the article\n",
    "    * the original publish date, and possible modified date\n",
    "    * summary of the content\n",
    "    * content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feed': {'title': 'Archie.AI - Medium',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Archie.AI - Medium'},\n",
       "  'subtitle': 'ML &amp; Tech Articles from the team behind Archie.AI - Medium',\n",
       "  'subtitle_detail': {'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'ML &amp; Tech Articles from the team behind Archie.AI - Medium'},\n",
       "  'links': [{'rel': 'alternate',\n",
       "    'type': 'text/html',\n",
       "    'href': 'https://medium.com/archieai?source=rss----4e8922a89498---4'},\n",
       "   {'href': 'https://medium.com/feed/archieai',\n",
       "    'rel': 'self',\n",
       "    'type': 'application/rss+xml'},\n",
       "   {'href': 'http://medium.superfeedr.com',\n",
       "    'rel': 'hub',\n",
       "    'type': 'text/html'}],\n",
       "  'link': 'https://medium.com/archieai?source=rss----4e8922a89498---4',\n",
       "  'image': {'href': 'https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png',\n",
       "   'title': 'Archie.AI - Medium',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Archie.AI - Medium'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai?source=rss----4e8922a89498---4'},\n",
       "  'generator_detail': {'name': 'Medium'},\n",
       "  'generator': 'Medium',\n",
       "  'updated': 'Sat, 19 Oct 2019 22:54:51 GMT',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=22, tm_min=54, tm_sec=51, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "  'publisher': 'yourfriends@medium.com',\n",
       "  'publisher_detail': {'email': 'yourfriends@medium.com'}},\n",
       " 'entries': [{'title': 'How Much Money Do You Need to Move the Bitcoin Market?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'How Much Money Do You Need to Move the Bitcoin Market?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/how-much-money-do-you-need-to-move-the-bitcoin-market-202f4316f277?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/how-much-money-do-you-need-to-move-the-bitcoin-market-202f4316f277?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/202f4316f277',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'ethereum', 'scheme': None, 'label': None},\n",
       "    {'term': 'bitcoin', 'scheme': None, 'label': None},\n",
       "    {'term': 'investing', 'scheme': None, 'label': None},\n",
       "    {'term': 'cryptocurrency', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Ishtiaq Rahman'}],\n",
       "   'author': 'Ishtiaq Rahman',\n",
       "   'author_detail': {'name': 'Ishtiaq Rahman'},\n",
       "   'published': 'Thu, 12 Jul 2018 03:46:18 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=7, tm_mday=12, tm_hour=3, tm_min=46, tm_sec=18, tm_wday=3, tm_yday=193, tm_isdst=0),\n",
       "   'updated': '2018-03-05T19:45:36.992Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=3, tm_mday=5, tm_hour=19, tm_min=45, tm_sec=36, tm_wday=0, tm_yday=64, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4>Whale Science\\xa0🐋</h4><p>I did a quick estimation to figure out what kind of investment you’d need to be able to move the Bitcoin market in the short term, in a particular direction.</p><p>I looked at Gdax trading data which handled about 2.98% of all BTC trading volume on February 26th,\\xa02018.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZNfAigHdJMdvAk1J6T-1kQ.png\" /><figcaption>Source: Coinmarkercap.com</figcaption></figure><p>On February 26, between 11: 54 PM PST and 11:55 PM PST, the total volume traded on Gdax was 65 Bitcoins which was worth around $686,440 USD at the time. This resulted in a\\xa0.557% increase in the price of\\xa0Bitcoin.</p><p>I picked this particular minute for my example because it had visibly higher trading volume compared to the minutes before it.(See image\\xa0below).</p><p>We can now estimate that the total volume of Bitcoins traded in ALL markets during that 1-minute was about 2181 Bitcoins (~23 million USD worth) from the fact 65 Bitcoins traded on Gdax represented 2.98% of all Bitcoin trade volume in the\\xa0world.</p><p>The actual total volume should be lower since it is unlikely that all markets are completely efficient and received the same magnitude of above average volume like Gdax did during that 1-minute in question\\u200a—\\u200aBut we will continue with this estimation for simplicity.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aRn7JH5cccHoXBThSvBJ2Q.jpeg\" /><figcaption>Data Source:\\xa0Gdax.com</figcaption></figure><p>This means that during that 1-minute, $23 million USD worth of bullish trades increased total market value of Bitcoin by over $1 billion USD (.557% of $180.77 billion total value of all Bitcoins)</p><p>Crudely put\\u200a—\\u200aIt is possible for someone with access to $23 million USD to pump the price up by\\xa0.557% in one\\xa0minute.</p><h3><strong>What About Ethereum?</strong></h3><p>I did the same calculation for Ethereum for that exact same minute\\u200a—\\u200abetween 11: 54 PM PST and 11:55 PM PST on February 26th,\\xa02018.</p><p>Total volume traded on Gdax during that one minute was 120 ETH and resulted in a\\xa0.41% increase in the price of Ethereum.</p><p>Gdax represented 2.97% of all ETH trades which puts the total estimated trade volume during that minute at 4040 ETH which was worth around $3.57 million USD at the\\xa0time.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pqsAybAJixL0W4CZ3ybt7A.jpeg\" /><figcaption>Data Source:\\xa0Gdax.com</figcaption></figure><p>Therefore, we can estimate that a $3.57 million USD worth of bullish trades in Ethereum resulted in an increase of $363 million to the total market value of all ETH(.42% of $86.44 billion USD, total market value of Ethereum)</p><h3>WHAT DOES IT ALL\\xa0MEAN?</h3><ol><li>A lot more extensive analysis is required before any conclusion can be drawn from this. In future, I’d like to look at different time cycles besides one minute and include a lot more data than just the one minute I picked on a random day to do my calculations. However, this simplified calculation does give us some idea about the sensitivity of the\\xa0market.</li><li>It would also be interesting to look at how this “whale-effect” has changed over\\xa0time.</li><li>I assume it was much cheaper to move the market when Bitcoin had a substantially smaller number of hodlers. I also do not doubt that it will get progressively more and more expensive to be able to move\\xa0price.</li><li>This may sound counter-intuitive but Bitcoin needs a lot more whales and deep pockets. It is relatively easier and cheaper for a whale to influence the market if there are not enough other big players. But with a lot of whales in the market, a single whale no longer has the same influence. For reference: There are 2,043 billionaires worldwide (Forbes) and 35 million millionaires worldwide (Credit\\xa0Suisse)</li><li>This is not meant to be a financial advice. Please invest responsibly.</li></ol><p>Note:</p><ul><li>Glad you stopped by. When I’m not staring at crypto prices, I am usually working on my AI/ML startup <a href=\"http://www.archie.ai\">Archie.AI\\u200a—\\u200aThe Artificially Intelligent Data Scientist.</a> Do check it out if you’re interested in that sort of\\xa0thing.</li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=202f4316f277\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/how-much-money-do-you-need-to-move-the-bitcoin-market-202f4316f277\">How Much Money Do You Need to Move the Bitcoin Market?</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4>Whale Science\\xa0🐋</h4><p>I did a quick estimation to figure out what kind of investment you’d need to be able to move the Bitcoin market in the short term, in a particular direction.</p><p>I looked at Gdax trading data which handled about 2.98% of all BTC trading volume on February 26th,\\xa02018.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZNfAigHdJMdvAk1J6T-1kQ.png\" /><figcaption>Source: Coinmarkercap.com</figcaption></figure><p>On February 26, between 11: 54 PM PST and 11:55 PM PST, the total volume traded on Gdax was 65 Bitcoins which was worth around $686,440 USD at the time. This resulted in a\\xa0.557% increase in the price of\\xa0Bitcoin.</p><p>I picked this particular minute for my example because it had visibly higher trading volume compared to the minutes before it.(See image\\xa0below).</p><p>We can now estimate that the total volume of Bitcoins traded in ALL markets during that 1-minute was about 2181 Bitcoins (~23 million USD worth) from the fact 65 Bitcoins traded on Gdax represented 2.98% of all Bitcoin trade volume in the\\xa0world.</p><p>The actual total volume should be lower since it is unlikely that all markets are completely efficient and received the same magnitude of above average volume like Gdax did during that 1-minute in question\\u200a—\\u200aBut we will continue with this estimation for simplicity.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aRn7JH5cccHoXBThSvBJ2Q.jpeg\" /><figcaption>Data Source:\\xa0Gdax.com</figcaption></figure><p>This means that during that 1-minute, $23 million USD worth of bullish trades increased total market value of Bitcoin by over $1 billion USD (.557% of $180.77 billion total value of all Bitcoins)</p><p>Crudely put\\u200a—\\u200aIt is possible for someone with access to $23 million USD to pump the price up by\\xa0.557% in one\\xa0minute.</p><h3><strong>What About Ethereum?</strong></h3><p>I did the same calculation for Ethereum for that exact same minute\\u200a—\\u200abetween 11: 54 PM PST and 11:55 PM PST on February 26th,\\xa02018.</p><p>Total volume traded on Gdax during that one minute was 120 ETH and resulted in a\\xa0.41% increase in the price of Ethereum.</p><p>Gdax represented 2.97% of all ETH trades which puts the total estimated trade volume during that minute at 4040 ETH which was worth around $3.57 million USD at the\\xa0time.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pqsAybAJixL0W4CZ3ybt7A.jpeg\" /><figcaption>Data Source:\\xa0Gdax.com</figcaption></figure><p>Therefore, we can estimate that a $3.57 million USD worth of bullish trades in Ethereum resulted in an increase of $363 million to the total market value of all ETH(.42% of $86.44 billion USD, total market value of Ethereum)</p><h3>WHAT DOES IT ALL\\xa0MEAN?</h3><ol><li>A lot more extensive analysis is required before any conclusion can be drawn from this. In future, I’d like to look at different time cycles besides one minute and include a lot more data than just the one minute I picked on a random day to do my calculations. However, this simplified calculation does give us some idea about the sensitivity of the\\xa0market.</li><li>It would also be interesting to look at how this “whale-effect” has changed over\\xa0time.</li><li>I assume it was much cheaper to move the market when Bitcoin had a substantially smaller number of hodlers. I also do not doubt that it will get progressively more and more expensive to be able to move\\xa0price.</li><li>This may sound counter-intuitive but Bitcoin needs a lot more whales and deep pockets. It is relatively easier and cheaper for a whale to influence the market if there are not enough other big players. But with a lot of whales in the market, a single whale no longer has the same influence. For reference: There are 2,043 billionaires worldwide (Forbes) and 35 million millionaires worldwide (Credit\\xa0Suisse)</li><li>This is not meant to be a financial advice. Please invest responsibly.</li></ol><p>Note:</p><ul><li>Glad you stopped by. When I’m not staring at crypto prices, I am usually working on my AI/ML startup <a href=\"http://www.archie.ai\">Archie.AI\\u200a—\\u200aThe Artificially Intelligent Data Scientist.</a> Do check it out if you’re interested in that sort of\\xa0thing.</li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=202f4316f277\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/how-much-money-do-you-need-to-move-the-bitcoin-market-202f4316f277\">How Much Money Do You Need to Move the Bitcoin Market?</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Why Data is Important for Small, Personal Web Projects\\u200b',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Why Data is Important for Small, Personal Web Projects\\u200b'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/why-data-is-important-for-small-personal-web-projects-355cf0bba2fe?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/why-data-is-important-for-small-personal-web-projects-355cf0bba2fe?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/355cf0bba2fe',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'blogging', 'scheme': None, 'label': None},\n",
       "    {'term': 'web-development', 'scheme': None, 'label': None},\n",
       "    {'term': 'google-analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'personal-development', 'scheme': None, 'label': None},\n",
       "    {'term': 'photography', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Dmitri'}],\n",
       "   'author': 'Dmitri',\n",
       "   'author_detail': {'name': 'Dmitri'},\n",
       "   'published': 'Mon, 11 Jun 2018 07:36:49 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=11, tm_hour=7, tm_min=36, tm_sec=49, tm_wday=0, tm_yday=162, tm_isdst=0),\n",
       "   'updated': '2018-06-11T10:56:16.916Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=6, tm_mday=11, tm_hour=10, tm_min=56, tm_sec=16, tm_wday=0, tm_yday=162, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4>It’s about connecting with the fans, not creeping them\\xa0out</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sMoHJ8PNMA2UgtlYlNaxfw.jpeg\" /></figure><p>To me, small, personal projects are always opportunities. Opportunities to learn, to be creative, and to be\\xa0heard.</p><p>During the past five years, I’ve run and managed nearly a dozen web projects, with traffic ranging from tens to tens of thousands visitors each day. Naturally, larger websites have more at stake. They demand round-the-clock monitoring and weekly analysis. But <strong>analytics play a huge role in small, personal projects, too</strong>.</p><p>With less-frequently visited properties it’s a lot harder to derive statistically-significant conclusions. Data is noisy and takes a long time to collect. Acting on that data is also difficult. But this knowledge is <strong>valuable for understanding the people </strong>who take the time to watch, read, and react to your creative expressions.</p><p>A few years ago I was very much into making music. I performed live and distributed records online. Being an introvert I eventually gravitated towards hiding with my guitar in the bedroom and creating sounds in private. Still, I loved being on the stage, as there is no better way to be with people who happen to like you and/or your\\xa0work.</p><p>Never the less, my public appearances have receded over time. Most of my creative work is now online (as <a href=\"https://www.analog.cafe/\">a film photography publication</a> and a community blogging platform). The people who happen to like it and consume regularly only manifest themselves as tiny spikes on the traffic curve reported by Google Analytics. Knowing this little about the audience creates a significant interaction void.</p><p>As there wasn’t much that I could do with my analytics I switched to Archie <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Reporting</a> product for casual weekly digests. Interestingly, a few months in I began to understand my audience a little better, or, at least, it felt like I did. I knew whether my work is getting more or less popular, where the visitors came from, whether the people are interacting with my content, and what pages, according to the bot, deserve my attention. All without having to obsess about the data via analytics dashboard.</p><p>My resulting understanding of the audience isn’t very scientific. But a rough overview of the crowd does draw a decent picture on seasonal and hourly popularity (like the busy months, or, what time of the day do people visit my site most often). Going beyond this kind of knowledge requires more traffic to come up with statistically significant answers. But <strong>the real advantage of being small is to be able to talk to people on a personal level and spend less time data mining (while still keeping\\xa0track)</strong>.</p><p>Large businesses are spending a lot of money on advanced intelligence, which today is backfiring with harsher compliance requirements (like GDPR) and overall public mistrust. At the same time, small ventures have an advantage in the ability to use analytics reports as a rough gauge of performance and to focus on interacting with fans and customers, something we can do without having to\\xa0scale.</p><p>On Twitter, I regularly engage in conversations, many of which are taken as invaluable feedback or messages of support. I spend my time at the places of gathering for the likeminded individuals, like film development labs and exhibition galleries. All of which have a much greater impact on the success of my small venture, defined by the size of the audience and their ability to appreciate my\\xa0efforts.</p><p>To get to this balance between guestimation and science, automation and personal approach I had to try a lot of different techniques. In the end, for any website that receives less than 5K unique visitors per month this method is perhaps the best. No excessive tracking or obsessive analysis. Instead, a healthy presence online (outside of the publishing platform) and a strong reliance on physical/real-world connections.</p><p>With the casual data approach, I get to have meaningful, guided interactions with the community without having to spend time serving and dissecting non-existent crowds.</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/why-data-is-important-for-small-personal-web-projects\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=355cf0bba2fe\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/why-data-is-important-for-small-personal-web-projects-355cf0bba2fe\">Why Data is Important for Small, Personal Web Projects\\u200b</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4>It’s about connecting with the fans, not creeping them\\xa0out</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sMoHJ8PNMA2UgtlYlNaxfw.jpeg\" /></figure><p>To me, small, personal projects are always opportunities. Opportunities to learn, to be creative, and to be\\xa0heard.</p><p>During the past five years, I’ve run and managed nearly a dozen web projects, with traffic ranging from tens to tens of thousands visitors each day. Naturally, larger websites have more at stake. They demand round-the-clock monitoring and weekly analysis. But <strong>analytics play a huge role in small, personal projects, too</strong>.</p><p>With less-frequently visited properties it’s a lot harder to derive statistically-significant conclusions. Data is noisy and takes a long time to collect. Acting on that data is also difficult. But this knowledge is <strong>valuable for understanding the people </strong>who take the time to watch, read, and react to your creative expressions.</p><p>A few years ago I was very much into making music. I performed live and distributed records online. Being an introvert I eventually gravitated towards hiding with my guitar in the bedroom and creating sounds in private. Still, I loved being on the stage, as there is no better way to be with people who happen to like you and/or your\\xa0work.</p><p>Never the less, my public appearances have receded over time. Most of my creative work is now online (as <a href=\"https://www.analog.cafe/\">a film photography publication</a> and a community blogging platform). The people who happen to like it and consume regularly only manifest themselves as tiny spikes on the traffic curve reported by Google Analytics. Knowing this little about the audience creates a significant interaction void.</p><p>As there wasn’t much that I could do with my analytics I switched to Archie <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Reporting</a> product for casual weekly digests. Interestingly, a few months in I began to understand my audience a little better, or, at least, it felt like I did. I knew whether my work is getting more or less popular, where the visitors came from, whether the people are interacting with my content, and what pages, according to the bot, deserve my attention. All without having to obsess about the data via analytics dashboard.</p><p>My resulting understanding of the audience isn’t very scientific. But a rough overview of the crowd does draw a decent picture on seasonal and hourly popularity (like the busy months, or, what time of the day do people visit my site most often). Going beyond this kind of knowledge requires more traffic to come up with statistically significant answers. But <strong>the real advantage of being small is to be able to talk to people on a personal level and spend less time data mining (while still keeping\\xa0track)</strong>.</p><p>Large businesses are spending a lot of money on advanced intelligence, which today is backfiring with harsher compliance requirements (like GDPR) and overall public mistrust. At the same time, small ventures have an advantage in the ability to use analytics reports as a rough gauge of performance and to focus on interacting with fans and customers, something we can do without having to\\xa0scale.</p><p>On Twitter, I regularly engage in conversations, many of which are taken as invaluable feedback or messages of support. I spend my time at the places of gathering for the likeminded individuals, like film development labs and exhibition galleries. All of which have a much greater impact on the success of my small venture, defined by the size of the audience and their ability to appreciate my\\xa0efforts.</p><p>To get to this balance between guestimation and science, automation and personal approach I had to try a lot of different techniques. In the end, for any website that receives less than 5K unique visitors per month this method is perhaps the best. No excessive tracking or obsessive analysis. Instead, a healthy presence online (outside of the publishing platform) and a strong reliance on physical/real-world connections.</p><p>With the casual data approach, I get to have meaningful, guided interactions with the community without having to spend time serving and dissecting non-existent crowds.</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/why-data-is-important-for-small-personal-web-projects\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=355cf0bba2fe\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/why-data-is-important-for-small-personal-web-projects-355cf0bba2fe\">Why Data is Important for Small, Personal Web Projects\\u200b</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Structuring React.js Web Applications\\u200b',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Structuring React.js Web Applications\\u200b'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/structuring-react-js-web-applications-11271643e941?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/structuring-react-js-web-applications-11271643e941?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/11271643e941',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'programming', 'scheme': None, 'label': None},\n",
       "    {'term': 'javascript', 'scheme': None, 'label': None},\n",
       "    {'term': 'reactjs', 'scheme': None, 'label': None},\n",
       "    {'term': 'react', 'scheme': None, 'label': None},\n",
       "    {'term': 'refactoring', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Dmitri'}],\n",
       "   'author': 'Dmitri',\n",
       "   'author_detail': {'name': 'Dmitri'},\n",
       "   'published': 'Sat, 05 May 2018 15:42:51 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=5, tm_mday=5, tm_hour=15, tm_min=42, tm_sec=51, tm_wday=5, tm_yday=125, tm_isdst=0),\n",
       "   'updated': '2018-10-03T22:34:44.290Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=3, tm_hour=22, tm_min=34, tm_sec=44, tm_wday=2, tm_yday=276, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4><strong><em>A Better Naming and File Organization System</em></strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/1*FKdNcdYWDyafzIApir7dnQ.jpeg\" /></figure><p>The curse and the gift of React.js is the fact that it is not opinionated in terms of how you structure your components and files. Do what you want and it’ll work. But with every new project it’s a “blank slate”\\xa0problem.</p><p>This article is written from a perspective of a person building (and finally refactoring) the front-end of a blogging platform designed for film photography enthusiasts. Besides listing and displaying articles, the app provides admin controls and a full rich text editorial suite, comprised of <strong>280 files and folders</strong>. The app in question is <a href=\"https://www.analog.cafe/\">Analog.Cafe</a>.</p><h3>Preface 1: “dumb” and “smart” components: not a good way to sort your\\xa0files.</h3><pre>- app/<br>  - components/<br>  - containers/</pre><p>When I began working on my application, coming from an intensive year with Ruby on Rails builds for <a href=\"https://www.archie.ai/\">Archie.AI</a> (a fairly opinionated framework) I’ve hit the wall trying to figure out how to structure and name the numerous files with React. The most common advice at the time was to segregate the components into pure functions and stateful components.</p><p>The expectation with this method is that your components will inevitably get reused elsewhere. Although this may be true for many projects, I can’t see how it could be the case for all applications. Furthermore, ripping the functionality apart and placing the pieces of a component that performs the same function into separate corners of your filesystem is counter-productive and counter-intuitive.</p><p>With some experementation I’ve come up with a better system\\xa0(below).</p><h3>Preface 2: styled-components, they aren’t CSS; they are components.</h3><p>\\u200b<a href=\"https://github.com/styled-components/styled-components\">styled-components</a> is my library of choice when it comes to baking CSS into React projects. It’s very\\xa0good.</p><p>A common pattern of usage with it is to separate styles into styles.js, a reminiscent of the file structure we used to have with simpler hand-written HTML files not too long\\xa0ago.</p><p>Turns out this is not a practically good idea. Namely, because this method creates a third type of component (in addition to above-mentioned smart and dumb). What’s worse, this type of component has a completely separate organizational method, which attempts to mimic conflicting paradigms.</p><p>I recommend treating styled-components just as what they are\\u200a—\\u200aReact components.</p><h3>The Interface Pattern.</h3><p><em>The Interface Pattern</em> is a reminder that we are building a front-end application, which is easier to understand and structure when it’s thought of as a compilation of visual interface elements. This pattern consists of suggestions on <strong>file and folder structure, preferred export types, commenting practices, and file size recommendations</strong>.</p><h3>File and folder structure shape.</h3><pre>- app/<br>  - core/<br>  - admin/<br>  - user/<br>  - constants.js<br>  - index.js<br>  - store.js<br>  - utils.js</pre><p><strong><em>Note:</em></strong><em> you can browse the entire application structure for Analog.Cafe in </em><a href=\"http://github.com/dmitrizzle/Analog.Cafe\"><em>this\\xa0repo</em></a><em>.</em></p><p>My application is divided into three major <strong>sections</strong>: core/ admin/ and user/. In your case, you may not have any sections if the app isn’t big enough. Then you can structure your app/ folder just like the contents of the above sections (see\\xa0below).</p><p>The four JavaScript files above should be self-explanatory, but with a few caveats. In this example they serve as index files, where they store only the most basic and commonly-used exports: index.js contains the main wrapper React component for the app, store.js<em> </em>combines the reducers found inside the above three application sections and exports a Redux store, while utils.js and constants.js contain the most common JavaScripit function snippets and reusable constants.</p><pre>- core/<br>  - components/<br>  - constants/<br>  - store/<br>  - utils/</pre><p>Inside each of the application sections are four folders which resemble the shape of the app/ directory. The only difference is that this shape forces you to create more files in your utils/and constants/folders which is <a href=\"https://github.com/airbnb/javascript/issues/1365\">better</a> for the organization and should make tree-shaking work better\\xa0too.</p><p>If you are not splitting your app into <strong>sections</strong> the above folders could be placed inside your app/ folder, instead of\\xa0core/.</p><pre>- constants/<br>  - messages-.js<br>  - messages-article.js<br>  - routes-article.js<br>  - rules-submission.js<br>- utils/<br>  - actions-session.js<br>  - messages-profile.js</pre><p>Both constants/and utils/ folders have similar file-naming patterns. The first keyword is either messages, routes, rules, or actions. Followed by a dash and a keyword describing a specific part of your application view. I understand that this is not the most foolproof naming convention, however, you may be able to understand it much better in practice. The main objectives should be <strong>consistency and\\xa0clarity</strong>.</p><p>Note the file named <em>messages-.js</em> which contains strings and objects designated as user-facing messages, not assigned to any specific part of the application view.</p><pre>- store/<br>  - actions-article.js<br>  - actions-submission.js<br>  - reducers-article.js<br>  - reducers-submission.js</pre><p>The store/ folder is for Redux. It contains pairs of files (actions- and reducers-) for each part of your application view. Simple; all in one\\xa0place.</p><pre>- components/<br>  - controls/<br>  - icons/<br>  - pages/<br>  - routes/<br>  - forms/<br>  - vignettes/</pre><p>components/ folder: I found the above six types of components to be fairly inclusive way to organize an application. It’s required to have such sub-folders to quickly find what you are looking for and understand application structure. Otherwise you may be stuck with hundreds of folders in this part of your app. This is how I distinguish them:</p><p><strong><em>controls/</em>\\u200a—\\u200a</strong>Buttons &amp; button arrays, modal boxes, links, nav bars, menus,\\xa0etc.</p><p><strong><em>icons/</em></strong>\\u200a—\\u200aGraphic elements made with React and meant to stay as part of an app, such as integral SVGs or\\xa0CSSs.</p><p><strong>pages/</strong>\\u200a—\\u200aComponents that are meant to take over a whole or a meaningful part of a screen\\xa0space.</p><p><strong><em>routes/</em></strong>\\u200a—\\u200aThis folder is specifically for React Router route components.</p><p><strong>forms/</strong>\\u200a—\\u200aInput elements.</p><p><strong>vignettes/</strong>\\u200a—\\u200aSmaller components that do not belong anywhere\\xa0else.</p><pre>- controls/<br>  - Card/<br>    - index.js<br>    - components/<br>      - CardFigure.js<br>      - CardHeader.js</pre><p>Each of the component folders would have names written in CamelCase, with an optional index.js at their root, which would tie everything together. If necessary, components/ folder could be placed inside, which can contain styled-components or React.js components which would directly help compose the main component (in this case, <em>Card/ </em>component).</p><p><strong><em>Note 1:</em></strong><em> There is no distinction or rule here between “smart” and “dumb” components, but the “smart” components naturally tend to end up at the root of the main component in index.js\\u200a—\\u200awhich you could use to your advantage.</em></p><p><strong><em>Note 2:</em></strong><em> There is nothing preventing you importing from files located in other application sections; a lot of the time it’s required and there’s nothing wrong with that. Feel free to require </em><em>admin/ utils in your </em><em>core/ components.</em></p><p><strong><em>Note 3:</em></strong><em> You may have noticed that sub-components do not have their own folders. That makes for easier readability and better folder structure. They could, of course, be placed in their own folders if they in-turn have their own sub-components, but that would be messy. Try to keep your file tree as flat as possible.</em></p><h3>Preferred export\\xa0types.</h3><p>A simple rule is to <strong>prefer named exports</strong> like export const function Name ()=&gt;{} in constants/<em> </em>utils/ and store/\\u200a—\\u200athis will encourage you to balance the number of files in those folders\\xa0nicely.</p><p>However, all components should strive to export<strong> only default exports</strong> with some exceptions where they could contain both default and named exports in very small files. This simple rule will force you to create more components (which are by the way a lot easier to name than more rigidly-structured <em>constants</em> and <em>utils</em> files), which in turn will create a number of benefits in terms of the final bundle size and app readability (fewer lines of code per\\xa0file).</p><h3>File size recommendations.</h3><p>No more than 300 lines per file. Anything bigger than that warrants splitting it.</p><h3>Commenting practices.</h3><p>I used to think that more comments in the code is better. Until I learned otherwise. Plentiful comments could be useful when creating a tutorial, however, they tend to pollute application files and encourage bad variable naming practices. So if the code feels difficult to understand, it should be reviewed and corrected for a more comprehensible namings and style. Use tools like <a href=\"https://github.com/prettier/prettier\">Prettier</a> to your advantage.</p><p>Write readable code instead of something that you needs a\\xa0manual.</p><p>It may seem like there’s a lot to deal with, but in practice, it could be easily achieved and understood by the whole team. Have a look at <a href=\"http://github.com/dmitrizzle/Analog.Cafe\">the repo</a> that already uses this method to get yourself acquainted. Refer back to this text to get the details and the reasoning behind each\\xa0choice.</p><p>As you may have noticed I haven’t mentioned anything about where to place tests. This method also hasn’t been tried in a great diversity of production systems so there may be some things I missed or got wrong. In those cases, you may have to adapt, and if you got time please let me know so that I could make this guide\\xa0better.</p><p>🍻</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/structuring-react-applications\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=11271643e941\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/structuring-react-js-web-applications-11271643e941\">Structuring React.js Web Applications\\u200b</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4><strong><em>A Better Naming and File Organization System</em></strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/1*FKdNcdYWDyafzIApir7dnQ.jpeg\" /></figure><p>The curse and the gift of React.js is the fact that it is not opinionated in terms of how you structure your components and files. Do what you want and it’ll work. But with every new project it’s a “blank slate”\\xa0problem.</p><p>This article is written from a perspective of a person building (and finally refactoring) the front-end of a blogging platform designed for film photography enthusiasts. Besides listing and displaying articles, the app provides admin controls and a full rich text editorial suite, comprised of <strong>280 files and folders</strong>. The app in question is <a href=\"https://www.analog.cafe/\">Analog.Cafe</a>.</p><h3>Preface 1: “dumb” and “smart” components: not a good way to sort your\\xa0files.</h3><pre>- app/<br>  - components/<br>  - containers/</pre><p>When I began working on my application, coming from an intensive year with Ruby on Rails builds for <a href=\"https://www.archie.ai/\">Archie.AI</a> (a fairly opinionated framework) I’ve hit the wall trying to figure out how to structure and name the numerous files with React. The most common advice at the time was to segregate the components into pure functions and stateful components.</p><p>The expectation with this method is that your components will inevitably get reused elsewhere. Although this may be true for many projects, I can’t see how it could be the case for all applications. Furthermore, ripping the functionality apart and placing the pieces of a component that performs the same function into separate corners of your filesystem is counter-productive and counter-intuitive.</p><p>With some experementation I’ve come up with a better system\\xa0(below).</p><h3>Preface 2: styled-components, they aren’t CSS; they are components.</h3><p>\\u200b<a href=\"https://github.com/styled-components/styled-components\">styled-components</a> is my library of choice when it comes to baking CSS into React projects. It’s very\\xa0good.</p><p>A common pattern of usage with it is to separate styles into styles.js, a reminiscent of the file structure we used to have with simpler hand-written HTML files not too long\\xa0ago.</p><p>Turns out this is not a practically good idea. Namely, because this method creates a third type of component (in addition to above-mentioned smart and dumb). What’s worse, this type of component has a completely separate organizational method, which attempts to mimic conflicting paradigms.</p><p>I recommend treating styled-components just as what they are\\u200a—\\u200aReact components.</p><h3>The Interface Pattern.</h3><p><em>The Interface Pattern</em> is a reminder that we are building a front-end application, which is easier to understand and structure when it’s thought of as a compilation of visual interface elements. This pattern consists of suggestions on <strong>file and folder structure, preferred export types, commenting practices, and file size recommendations</strong>.</p><h3>File and folder structure shape.</h3><pre>- app/<br>  - core/<br>  - admin/<br>  - user/<br>  - constants.js<br>  - index.js<br>  - store.js<br>  - utils.js</pre><p><strong><em>Note:</em></strong><em> you can browse the entire application structure for Analog.Cafe in </em><a href=\"http://github.com/dmitrizzle/Analog.Cafe\"><em>this\\xa0repo</em></a><em>.</em></p><p>My application is divided into three major <strong>sections</strong>: core/ admin/ and user/. In your case, you may not have any sections if the app isn’t big enough. Then you can structure your app/ folder just like the contents of the above sections (see\\xa0below).</p><p>The four JavaScript files above should be self-explanatory, but with a few caveats. In this example they serve as index files, where they store only the most basic and commonly-used exports: index.js contains the main wrapper React component for the app, store.js<em> </em>combines the reducers found inside the above three application sections and exports a Redux store, while utils.js and constants.js contain the most common JavaScripit function snippets and reusable constants.</p><pre>- core/<br>  - components/<br>  - constants/<br>  - store/<br>  - utils/</pre><p>Inside each of the application sections are four folders which resemble the shape of the app/ directory. The only difference is that this shape forces you to create more files in your utils/and constants/folders which is <a href=\"https://github.com/airbnb/javascript/issues/1365\">better</a> for the organization and should make tree-shaking work better\\xa0too.</p><p>If you are not splitting your app into <strong>sections</strong> the above folders could be placed inside your app/ folder, instead of\\xa0core/.</p><pre>- constants/<br>  - messages-.js<br>  - messages-article.js<br>  - routes-article.js<br>  - rules-submission.js<br>- utils/<br>  - actions-session.js<br>  - messages-profile.js</pre><p>Both constants/and utils/ folders have similar file-naming patterns. The first keyword is either messages, routes, rules, or actions. Followed by a dash and a keyword describing a specific part of your application view. I understand that this is not the most foolproof naming convention, however, you may be able to understand it much better in practice. The main objectives should be <strong>consistency and\\xa0clarity</strong>.</p><p>Note the file named <em>messages-.js</em> which contains strings and objects designated as user-facing messages, not assigned to any specific part of the application view.</p><pre>- store/<br>  - actions-article.js<br>  - actions-submission.js<br>  - reducers-article.js<br>  - reducers-submission.js</pre><p>The store/ folder is for Redux. It contains pairs of files (actions- and reducers-) for each part of your application view. Simple; all in one\\xa0place.</p><pre>- components/<br>  - controls/<br>  - icons/<br>  - pages/<br>  - routes/<br>  - forms/<br>  - vignettes/</pre><p>components/ folder: I found the above six types of components to be fairly inclusive way to organize an application. It’s required to have such sub-folders to quickly find what you are looking for and understand application structure. Otherwise you may be stuck with hundreds of folders in this part of your app. This is how I distinguish them:</p><p><strong><em>controls/</em>\\u200a—\\u200a</strong>Buttons &amp; button arrays, modal boxes, links, nav bars, menus,\\xa0etc.</p><p><strong><em>icons/</em></strong>\\u200a—\\u200aGraphic elements made with React and meant to stay as part of an app, such as integral SVGs or\\xa0CSSs.</p><p><strong>pages/</strong>\\u200a—\\u200aComponents that are meant to take over a whole or a meaningful part of a screen\\xa0space.</p><p><strong><em>routes/</em></strong>\\u200a—\\u200aThis folder is specifically for React Router route components.</p><p><strong>forms/</strong>\\u200a—\\u200aInput elements.</p><p><strong>vignettes/</strong>\\u200a—\\u200aSmaller components that do not belong anywhere\\xa0else.</p><pre>- controls/<br>  - Card/<br>    - index.js<br>    - components/<br>      - CardFigure.js<br>      - CardHeader.js</pre><p>Each of the component folders would have names written in CamelCase, with an optional index.js at their root, which would tie everything together. If necessary, components/ folder could be placed inside, which can contain styled-components or React.js components which would directly help compose the main component (in this case, <em>Card/ </em>component).</p><p><strong><em>Note 1:</em></strong><em> There is no distinction or rule here between “smart” and “dumb” components, but the “smart” components naturally tend to end up at the root of the main component in index.js\\u200a—\\u200awhich you could use to your advantage.</em></p><p><strong><em>Note 2:</em></strong><em> There is nothing preventing you importing from files located in other application sections; a lot of the time it’s required and there’s nothing wrong with that. Feel free to require </em><em>admin/ utils in your </em><em>core/ components.</em></p><p><strong><em>Note 3:</em></strong><em> You may have noticed that sub-components do not have their own folders. That makes for easier readability and better folder structure. They could, of course, be placed in their own folders if they in-turn have their own sub-components, but that would be messy. Try to keep your file tree as flat as possible.</em></p><h3>Preferred export\\xa0types.</h3><p>A simple rule is to <strong>prefer named exports</strong> like export const function Name ()=&gt;{} in constants/<em> </em>utils/ and store/\\u200a—\\u200athis will encourage you to balance the number of files in those folders\\xa0nicely.</p><p>However, all components should strive to export<strong> only default exports</strong> with some exceptions where they could contain both default and named exports in very small files. This simple rule will force you to create more components (which are by the way a lot easier to name than more rigidly-structured <em>constants</em> and <em>utils</em> files), which in turn will create a number of benefits in terms of the final bundle size and app readability (fewer lines of code per\\xa0file).</p><h3>File size recommendations.</h3><p>No more than 300 lines per file. Anything bigger than that warrants splitting it.</p><h3>Commenting practices.</h3><p>I used to think that more comments in the code is better. Until I learned otherwise. Plentiful comments could be useful when creating a tutorial, however, they tend to pollute application files and encourage bad variable naming practices. So if the code feels difficult to understand, it should be reviewed and corrected for a more comprehensible namings and style. Use tools like <a href=\"https://github.com/prettier/prettier\">Prettier</a> to your advantage.</p><p>Write readable code instead of something that you needs a\\xa0manual.</p><p>It may seem like there’s a lot to deal with, but in practice, it could be easily achieved and understood by the whole team. Have a look at <a href=\"http://github.com/dmitrizzle/Analog.Cafe\">the repo</a> that already uses this method to get yourself acquainted. Refer back to this text to get the details and the reasoning behind each\\xa0choice.</p><p>As you may have noticed I haven’t mentioned anything about where to place tests. This method also hasn’t been tried in a great diversity of production systems so there may be some things I missed or got wrong. In those cases, you may have to adapt, and if you got time please let me know so that I could make this guide\\xa0better.</p><p>🍻</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/structuring-react-applications\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=11271643e941\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/structuring-react-js-web-applications-11271643e941\">Structuring React.js Web Applications\\u200b</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Stop Sitting On All That Data & Do Something With It ⚙️',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Stop Sitting On All That Data & Do Something With It ⚙️'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/stop-sitting-on-all-that-data-do-something-with-it-ee9c966ace27?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/stop-sitting-on-all-that-data-do-something-with-it-ee9c966ace27?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/ee9c966ace27',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'machine-learning', 'scheme': None, 'label': None},\n",
       "    {'term': 'artificial-intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'data-science', 'scheme': None, 'label': None},\n",
       "    {'term': 'startup', 'scheme': None, 'label': None},\n",
       "    {'term': 'healthcare', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Ishtiaq Rahman'}],\n",
       "   'author': 'Ishtiaq Rahman',\n",
       "   'author_detail': {'name': 'Ishtiaq Rahman'},\n",
       "   'published': 'Tue, 06 Feb 2018 05:34:21 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=6, tm_hour=5, tm_min=34, tm_sec=21, tm_wday=1, tm_yday=37, tm_isdst=0),\n",
       "   'updated': '2018-02-20T00:03:25.868Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=20, tm_hour=0, tm_min=3, tm_sec=25, tm_wday=1, tm_yday=51, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4>Please, feed your data to the machines.</h4><p>Artificial intelligence is taking the demand for data to a new level.\\xa0📈</p><p>Let’s say you have access to 5,000 X-ray images of patients who were correctly diagnosed with a particular type of cancer\\u200a—\\u200aType\\xa0A.</p><p>Today, it is surprisingly easy to use this data to train a bot to detect this cancer in new patients.</p><p>To build this bot, you’d build an image classifier powered by a neural net and the 5,000 X-ray images would be your training data\\xa0set.</p><p>You’d add another 5,000 X-rays of patients without cancer so the classifier has examples of both healthy and affected\\xa0X-rays.</p><p>In essence, this image classifier bot would look for common patterns at pixel level using image gradients and correlate that pattern to Type-A cancer using a widely used machine learning algorithm called back-propagation.</p><p>Note that YOU don’t have to specify the patterns at the pixel level to the bot for it to detect the cancer. That would be a highly inefficient process and possibly inaccurate as\\xa0well.</p><p>Instead, in our deep learning model, the bot looks for the patterns itself. It painstakingly evaluates small grids of pixels of an image with the cancer and compares it to the corresponding grid in ALL the other images to find the patterns that exist. For further reading, you can check out concepts like <a href=\"https://en.wikipedia.org/wiki/Kernel_(image_processing)\">kernel convolutions </a>or how bots are <a href=\"https://www.kaggle.com/competitions\">detecting various object in Kaggle competitions</a>.</p><p>If you want to dive deeper into the tech, you can read my essay “<a href=\"https://medium.com/archieai/learning-at-scale-the-end-of-if-then-logic-bd3a4e292222\">Learning at Scale &amp; The End of ‘If-Then’ Logic</a>”.</p><p>The point is, using currently available open-source/SaaS deep learning platforms, a bit of motivation and access to the right data set, one could set this bot up in no\\xa0time.</p><p>Once trained, if you input a new patient’s X-ray, the classifier would be able to say things like “There’s a 98% chance that this is a Type A\\xa0Cancer”.</p><p>If you’ve been through a cancer diagnosis process of a loved one, you know how important it is to be certain. That’s why people get the second, the third and the fourth opinion from different doctors.</p><p>Using this bot, every patient can be more confident about a diagnosis, a lot\\xa0faster.</p><p>The best part is that if you continue to add more X-ray images of correctly diagnosed Type A cancer, the bot will continue to get better at detecting it.</p><p><strong>As machine learning techniques become more mainstream, a lot more value will be placed on data because machines can learn from it to do our jobs better than\\xa0us.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/898/0*D7foQzC-k8VBUWpB.png\" /><figcaption>Identifying cats or malignant cancer, it’s all the same for the bot as long as you have training data. Photo: Deep Learning visualized by\\xa0mapr.com</figcaption></figure><p>This above use-case isn’t science\\xa0fiction.</p><p>At John Radcliffe Hospital, a team of <a href=\"http://www.ultromics.com/\">researchers from Oxford University</a> are using electrocardiogram images (Eco test) of the heart to detect heart diseases. The system is called <a href=\"http://www.ultromics.com\">Ultromics</a> and it consistently performs better than human cardiologists. The team has access to Oxford University’s heart imaging database and they are training their machine learning algorithms with these images to detect various heart diseases.</p><p>Google’s DeepMind is using a similar system to train an AI to detect eye disease by looking at thousands of retina scans at <a href=\"https://www.thenational.ae/world/europe/google-s-deepmind-training-ai-to-diagnose-eye-disease-1.702022\">London’s Moorfields Eye Hospital.</a></p><p>In a double blind study, <a href=\"https://www.ibm.com/watson/health/oncology-and-genomics\">IBM Watson for Oncology’s</a> breast cancer treatment recommendations was 90% concordance with the recommendation of a tumor board consisting of multi-disciplinary doctors and practitioners. Here, the training data comes from medical records of past patients, medical journal and\\xa0books.</p><p>Needless to say, AI/ML use-cases are not limited to healthcare but they show us how valuable data is to solve real problems.</p><p>Most organizations/businesses/governments are sitting on top of literal goldmines of data that could be made into powerful AI products.</p><p>Unfortunately, not enough is being done. Not fast\\xa0enough.</p><p>Data is a source of great power. And with great power comes great responsibility.*</p><p>So if you’ve got access to valuable data, you better be building something useful with\\xa0it.</p><p><strong>Note:</strong></p><p>🤖If you’re interested in learning more about my work with AI/ML, check out my startup <a href=\"http://www.archie.ai\">Archie.AI</a>- The Artificially Intelligent Data Scientist.</p><p>🤖If you’re interested in building machine learning models, check out our workshops on\\xa0<a href=\"https://www.youtube.com/channel/UCkm-zUm8tAfyDIRoOVqNZ_Q/videos\">YouTube.</a></p><p>🤖Want me to help you build your AI/ML project? Email me: i@eurekaking.com</p><p>Additional recommended essays on machine learning/artificial intelligence from team Archie.AI</p><h4>👉<a href=\"https://medium.com/archieai/a-dozen-times-artificial-intelligence-startled-the-world-eae5005153db\">A Dozen Times Artificial Intelligence Startled The\\xa0World.</a></h4><h4>👉<a href=\"https://medium.com/archieai/the-power-of-natural-language-processing-f1ab0aa7d8c4\">The Power of Natural Language Processing.</a></h4><h4>👉<a href=\"https://medium.com/archieai/artificially-intelligent-engineers-how-ai-will-kill-all-engineering-jobs-3fd6dac55a06\">Artificially Intelligent Engineers\\u200a—\\u200aHow AI Will Kill All Engineering Jobs. <em>And Why It Is a Good\\xa0Thing.</em></a></h4><p><em>*Spiderman, David\\xa0Lapham</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ee9c966ace27\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/stop-sitting-on-all-that-data-do-something-with-it-ee9c966ace27\">Stop Sitting On All That Data &amp; Do Something With It ⚙️</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4>Please, feed your data to the machines.</h4><p>Artificial intelligence is taking the demand for data to a new level.\\xa0📈</p><p>Let’s say you have access to 5,000 X-ray images of patients who were correctly diagnosed with a particular type of cancer\\u200a—\\u200aType\\xa0A.</p><p>Today, it is surprisingly easy to use this data to train a bot to detect this cancer in new patients.</p><p>To build this bot, you’d build an image classifier powered by a neural net and the 5,000 X-ray images would be your training data\\xa0set.</p><p>You’d add another 5,000 X-rays of patients without cancer so the classifier has examples of both healthy and affected\\xa0X-rays.</p><p>In essence, this image classifier bot would look for common patterns at pixel level using image gradients and correlate that pattern to Type-A cancer using a widely used machine learning algorithm called back-propagation.</p><p>Note that YOU don’t have to specify the patterns at the pixel level to the bot for it to detect the cancer. That would be a highly inefficient process and possibly inaccurate as\\xa0well.</p><p>Instead, in our deep learning model, the bot looks for the patterns itself. It painstakingly evaluates small grids of pixels of an image with the cancer and compares it to the corresponding grid in ALL the other images to find the patterns that exist. For further reading, you can check out concepts like <a href=\"https://en.wikipedia.org/wiki/Kernel_(image_processing)\">kernel convolutions </a>or how bots are <a href=\"https://www.kaggle.com/competitions\">detecting various object in Kaggle competitions</a>.</p><p>If you want to dive deeper into the tech, you can read my essay “<a href=\"https://medium.com/archieai/learning-at-scale-the-end-of-if-then-logic-bd3a4e292222\">Learning at Scale &amp; The End of ‘If-Then’ Logic</a>”.</p><p>The point is, using currently available open-source/SaaS deep learning platforms, a bit of motivation and access to the right data set, one could set this bot up in no\\xa0time.</p><p>Once trained, if you input a new patient’s X-ray, the classifier would be able to say things like “There’s a 98% chance that this is a Type A\\xa0Cancer”.</p><p>If you’ve been through a cancer diagnosis process of a loved one, you know how important it is to be certain. That’s why people get the second, the third and the fourth opinion from different doctors.</p><p>Using this bot, every patient can be more confident about a diagnosis, a lot\\xa0faster.</p><p>The best part is that if you continue to add more X-ray images of correctly diagnosed Type A cancer, the bot will continue to get better at detecting it.</p><p><strong>As machine learning techniques become more mainstream, a lot more value will be placed on data because machines can learn from it to do our jobs better than\\xa0us.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/898/0*D7foQzC-k8VBUWpB.png\" /><figcaption>Identifying cats or malignant cancer, it’s all the same for the bot as long as you have training data. Photo: Deep Learning visualized by\\xa0mapr.com</figcaption></figure><p>This above use-case isn’t science\\xa0fiction.</p><p>At John Radcliffe Hospital, a team of <a href=\"http://www.ultromics.com/\">researchers from Oxford University</a> are using electrocardiogram images (Eco test) of the heart to detect heart diseases. The system is called <a href=\"http://www.ultromics.com\">Ultromics</a> and it consistently performs better than human cardiologists. The team has access to Oxford University’s heart imaging database and they are training their machine learning algorithms with these images to detect various heart diseases.</p><p>Google’s DeepMind is using a similar system to train an AI to detect eye disease by looking at thousands of retina scans at <a href=\"https://www.thenational.ae/world/europe/google-s-deepmind-training-ai-to-diagnose-eye-disease-1.702022\">London’s Moorfields Eye Hospital.</a></p><p>In a double blind study, <a href=\"https://www.ibm.com/watson/health/oncology-and-genomics\">IBM Watson for Oncology’s</a> breast cancer treatment recommendations was 90% concordance with the recommendation of a tumor board consisting of multi-disciplinary doctors and practitioners. Here, the training data comes from medical records of past patients, medical journal and\\xa0books.</p><p>Needless to say, AI/ML use-cases are not limited to healthcare but they show us how valuable data is to solve real problems.</p><p>Most organizations/businesses/governments are sitting on top of literal goldmines of data that could be made into powerful AI products.</p><p>Unfortunately, not enough is being done. Not fast\\xa0enough.</p><p>Data is a source of great power. And with great power comes great responsibility.*</p><p>So if you’ve got access to valuable data, you better be building something useful with\\xa0it.</p><p><strong>Note:</strong></p><p>🤖If you’re interested in learning more about my work with AI/ML, check out my startup <a href=\"http://www.archie.ai\">Archie.AI</a>- The Artificially Intelligent Data Scientist.</p><p>🤖If you’re interested in building machine learning models, check out our workshops on\\xa0<a href=\"https://www.youtube.com/channel/UCkm-zUm8tAfyDIRoOVqNZ_Q/videos\">YouTube.</a></p><p>🤖Want me to help you build your AI/ML project? Email me: i@eurekaking.com</p><p>Additional recommended essays on machine learning/artificial intelligence from team Archie.AI</p><h4>👉<a href=\"https://medium.com/archieai/a-dozen-times-artificial-intelligence-startled-the-world-eae5005153db\">A Dozen Times Artificial Intelligence Startled The\\xa0World.</a></h4><h4>👉<a href=\"https://medium.com/archieai/the-power-of-natural-language-processing-f1ab0aa7d8c4\">The Power of Natural Language Processing.</a></h4><h4>👉<a href=\"https://medium.com/archieai/artificially-intelligent-engineers-how-ai-will-kill-all-engineering-jobs-3fd6dac55a06\">Artificially Intelligent Engineers\\u200a—\\u200aHow AI Will Kill All Engineering Jobs. <em>And Why It Is a Good\\xa0Thing.</em></a></h4><p><em>*Spiderman, David\\xa0Lapham</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ee9c966ace27\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/stop-sitting-on-all-that-data-do-something-with-it-ee9c966ace27\">Stop Sitting On All That Data &amp; Do Something With It ⚙️</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Storing & recalling bot interactions☝️',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Storing & recalling bot interactions☝️'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/storing-recalling-bot-interactions-%EF%B8%8F-f0d17e015401?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/storing-recalling-bot-interactions-%EF%B8%8F-f0d17e015401?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/f0d17e015401',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'open-source', 'scheme': None, 'label': None},\n",
       "    {'term': 'ui', 'scheme': None, 'label': None},\n",
       "    {'term': 'javascript', 'scheme': None, 'label': None},\n",
       "    {'term': 'web-development', 'scheme': None, 'label': None},\n",
       "    {'term': 'bots', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Dmitri'}],\n",
       "   'author': 'Dmitri',\n",
       "   'author_detail': {'name': 'Dmitri'},\n",
       "   'published': 'Mon, 05 Feb 2018 00:03:04 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=5, tm_hour=0, tm_min=3, tm_sec=4, tm_wday=0, tm_yday=36, tm_isdst=0),\n",
       "   'updated': '2018-02-05T00:04:11.042Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=5, tm_hour=0, tm_min=4, tm_sec=11, tm_wday=0, tm_yday=36, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4>Enhancing JavaScript bot UI with localStorage</h4><p>Bot interfaces are fun for the users and advantageous for those who build them (if done right). The concept isn’t new, though today it’s especially powerful.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/525/1*svec126KHXrwAVO2ut0XPw.gif\" /><figcaption>An implementation of a JavaScript <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">bot library</a> with localStorage in-place to memorize previous interactions. Notice the greyed-out text. This screenshot is of a production release of<a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\"> Archie.AI Google Chrome\\xa0app</a>.</figcaption></figure><p>For developers, bots mean less time spent designing and building custom interfaces. It’s just text bubbles; plus many existing platforms offer to completely avoid this process with their already-successful apps’ APIs (i.e. Google Assistant).</p><p>For users, bots mean a possibility of hands-free interaction (via voice) and a more natural and/or seamless way to converse with machines.</p><h3>A simple solution.</h3><p>When I build things I tend to look for simple solutions, sans bloat, which could be easily understood and customized. Unfortunately, when I was looking for one last year there were none for my use\\xa0case…</p><p>My team and I have implemented and trained a natural language classification engine, <a href=\"https://www.archie.ai\"><em>Archie.AI</em></a>, and gave it the power to understand and generate answers from Google Analytics. The bot can give daily briefings about users’ state of business, predict the number of future visitors and answer over <a href=\"https://www.archie.ai/ask-me\">430 related questions</a>. It’s an excellent way to save time when looking for a particular metric or an instant business\\xa0advice.</p><p>It works wonderfully with Google Assistant and Alexa, however, when the time came to get a fast, clean interface for the web, there were no good-enough options. So I built one and kept it open-source. <a href=\"https://www.archie.ai/open-source\">chat-bubble</a> is the one-kilobyte JavaScript file with no dependencies that’s really easy to implement and understand:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;<br>);<br>chatWindow.talk({<br>  &quot;ice&quot;: { &quot;says&quot; : [ &quot;Hello!&quot; ] }<br>});</pre><pre>// <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples</a></pre><p><strong>Batteries included:</strong> a complete set of CSS styles and percision-timed animations, an ability to safely run functions in response to user actions, and a <em>pluggable processing engine</em>.</p><p>By “pluggable processing engine” I mean that the script is not going to tell you how to understand your user’s queries. It’s <em>up to you</em> to implement your own NLC. It’s <em>up to you</em> to either dynamically generate or write response scripts. However, it doesn’t leave you hanging. There are currently three ways to have it respond to your\\xa0users:</p><ol><li>Give your users options, which appear as buttons (see gif below). Nothing needs to be done here, this is built-in.</li><li>Use the provided sample code that utilizes a simple fuzzy-matching logic to map your users’ input to the options you prescribe (see gif\\xa0below).</li><li>Plug-in your own NLC engine (see gif\\xa0above).</li></ol><p>Those options are for recognizing user input. The output (what the bot says) is just as customizable. It could be as simple as a structured JavaScript object variable. Or it could be dynamically imported JSON data. Of course, it doesn’t have to be just one huge JSON file\\u200a—\\u200athat would be inefficient! In our case (again, see gif above), we broke it up into individual answers for the responses that require a trip to the server (on-demand) and some calculations on our\\xa0end.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/410/1*9sMLEpk7ZVFv-H6RPsCSow.gif\" /><figcaption>Bot library example with built-in button controls and input keyboard with fuzzy-match logic implemented. The JSON script that prescribes this conversation structure is\\xa0below:</figcaption></figure><pre>// a simple conversation script written with JSON</pre><pre>var conversationScript = {<br>  ice: {<br>    says: [&quot;Hi&quot;, &quot;Would you like banana or ice cream?&quot;],<br>    reply: [<br>      {<br>        question: &quot;Banana&quot;,<br>        answer: &quot;banana&quot;<br>      },<br>      {<br>        question: &quot;Ice Cream&quot;,<br>        answer: &quot;ice-cream&quot;<br>      }<br>    ]<br>  },<br>  banana: {<br>    says: [&quot;🍌&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  },<br>  &quot;ice-cream&quot;: {<br>    says: [&quot;🍦&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  }<br>}</pre><h3>Local memory.</h3><p>Over the next few months, we tested the script in production with about a thousand users, while adding a few tweaks and improving performance on older browsers. It has also been downloaded over 700 times as of\\xa0today.</p><p>The library works equally well on desktop and mobile. However, when it came time to publish it as a part of our Google Chrome browser extension user experience suffered. Because chat-bubble had no inherit persistence, the conversation history would evaporate every time the plugin window is closed. And that happened quite often as Chrome tends to kill the DOM of the plugins entirely each time the user shifts\\xa0focus.</p><p>That has to be\\xa0fixed.</p><p>There is no one way to keep the conversation history in on disk. I considered using Redux to manage the state, however, that’s a dependency and the philosophy so far is not to have one. That would also over-complicate things.</p><p>Instead, I decided to store a modified JSON object that would share the same structure as the conversation script in localStorage. It would be recalled every time the bot is brought up, however, it would also need\\xa0to:</p><ol><li>Have the potential to be used with a database or any other data storage\\xa0method.</li><li>Have different UI interactivity and style than the rest of the bot (a visual cue for the\\xa0user).</li><li>Be a progressive enhancement that doesn’t break the rest of the\\xa0app.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eQc_eyPCOSPRgt_UqMLSdA.png\" /><figcaption>chat-bubble-interactions is the LS key for keeping in-touch with the chat\\xa0history.</figcaption></figure><h4>Future-proofing.</h4><p>Keeping an option open for implementing a server-side storage solution is pretty straight-forward. The entire library is less than 340 lines of non-compressed, commented JavaScript. Shall anyone attempt to implement that, all that would need to be changed is JSON.parse(localStorage.getItem(interactionsLS)) method for accessing the history and localStorage.setItem(interactionsLS, JSON.stringify(interactionsHistory)) method for saving the\\xa0history.</p><p>The only roadblock I can see here is having to add a Promise -type checks to make sure that everything needed to display history is downloaded before proceeding. Something like this might take some work as there would need to be a few decisions made regarding when the download should start and what functions should it block. I’m leaving that for tomorrow.</p><h4>Custom UI for recalled conversations.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/957/1*ZkXx_a2X6pa46NSCkDD23Q.png\" /><figcaption>Note the “greyed-out” style for this recollected conversation up\\xa0top.</figcaption></figure><p>To keep things simple, previous conversations would appear in the chat as soon as the user opens\\xa0it.</p><p>However, as a side-effect of that decision, those conversations would <em>have</em> to be styled differently to avoid confusing the user. Additionally, the user responses would need special attention when stored and recalled, since user responses <strong>can not have any interactivity associated with\\xa0them</strong>.</p><p>What I mean is that while highlighting chat bubbles in black and floating them right for user responses isn’t that hard there are implications when the chat uses buttons instead of keyboard input messages. Read\\xa0on.</p><p>Consider the example (below) when the user is presented with options to select one of the two or more buttons as a way of answering to the bot. Obviously storing answer options in history isn’t helpful\\u200a—\\u200athey have nothing to do with conversation structure after they’ve been interacted with. Only the user’s response (their selected answer bubble) is relevant. The trick is not storing anything in history until the user has created their final interaction.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*SeO8giseO7LVQ_4D5O3p6w.gif\" /><figcaption>Note how the <strong>answer options</strong> no longer appear in the conversation history.</figcaption></figure><p>For this purpose, I’ve created two functions for saving history: interactionsSave() and interactionsSaveCommit()\\u200a—\\u200awhere the former would be called to mutate the proposed save object in RAM and the latter would commit that object to localStorage.</p><p>interactionSave() would be called every time the bot produces a response, but only after the user has committed their answer. Because when the user clicks a bubble our script has already “forgotten” what that button looked like in terms of DOM structure, a new one would be made, specifically for committing to conversation history:</p><pre>// add re-generated user picks to the history stack<br>if (_convo[key] !== undefined &amp;&amp; content !== undefined) {<br>  interactionsSave(<br>    &#39;&lt;span class=&quot;bubble-button reply-pick&quot;&gt;&#39; + content + &quot;&lt;/span&gt;&quot;,<br>    &quot;reply reply-pick&quot;<br>  )<br>}</pre><p>interactionsSaveCommit() would be called every time a new speech bubble is created in DOM by the means of addBubble() function.</p><h4><strong>Progressively enhancing.</strong></h4><p>This is a relatively new feature that not everyone would want to use, of course. It is also experimental and could easily be overdone (should someone try to remember a 1,000 interactions the performance and user experience would drop every time the boat would load). So by default I left it\\xa0off:</p><pre>recallInteractions = options.recallInteractions || 0</pre><p>Getting it to function is super simple\\xa0though:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;,<br>  { recallInteractions: 10 }<br>);</pre><p>…All that does is tells this interactionsSave() to toss unnecessary stuff\\xa0away:</p><pre>if (interactionsHistory.length &gt; recallInteractions)<br>      interactionsHistory.shift()</pre><p>For simplicity’s sake, all work on chat-bubble is done without any kind of build steps. All JavaScript is written and ran immediately in-browser (even though developers who implement it are given an option to use ES6 Import method). Because the browsers read JavaScript from the hard-drive in develop mode, any attempt to use localStorage breaks the entire code base as it’s not allowed (due to security restrictions). Which made me think: this could happen quite often in other environments. So I’ve implemented a fallback with a\\xa0warning:</p><pre>// local storage for recalling conversations upon restart<br>  var localStorageCheck = function() {<br>    var test = &quot;chat-bubble-storage-test&quot;<br>    try {<br>      localStorage.setItem(test, test)<br>      localStorage.removeItem(test)<br>      return true<br>    } catch (error) {<br>      console.error(<br>        &quot;Your server does not allow storing data locally. Most likely it&#39;s because you&#39;ve opened this page from your hard-drive. For testing, you can disable your browser&#39;s security or start a localhost environment.&quot;<br>      )<br>      return false<br>    }<br>  }<br>  var localStorageAvailable = localStorageCheck() &amp;&amp; recallInteractions &gt; 0</pre><p>Now everything should still work even if the browser can not access disk\\xa0memory.</p><p>As of today, the updated script is available through NPM as chat-bubble@next. It is already performing on our <a href=\"https://www.archie.ai/chrome-extension\">Google Chrome extension</a> and so far is able to save a lot of headache for the users, as well as dramatically reduce perceived loading\\xa0time.</p><p>All of the code described here is available on <a href=\"https://github.com/dmitrizzle/chat-bubble\">this</a> GitHub\\xa0repo.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f0d17e015401\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/storing-recalling-bot-interactions-%EF%B8%8F-f0d17e015401\">Storing &amp; recalling bot interactions☝️🤖</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4>Enhancing JavaScript bot UI with localStorage</h4><p>Bot interfaces are fun for the users and advantageous for those who build them (if done right). The concept isn’t new, though today it’s especially powerful.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/525/1*svec126KHXrwAVO2ut0XPw.gif\" /><figcaption>An implementation of a JavaScript <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">bot library</a> with localStorage in-place to memorize previous interactions. Notice the greyed-out text. This screenshot is of a production release of<a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\"> Archie.AI Google Chrome\\xa0app</a>.</figcaption></figure><p>For developers, bots mean less time spent designing and building custom interfaces. It’s just text bubbles; plus many existing platforms offer to completely avoid this process with their already-successful apps’ APIs (i.e. Google Assistant).</p><p>For users, bots mean a possibility of hands-free interaction (via voice) and a more natural and/or seamless way to converse with machines.</p><h3>A simple solution.</h3><p>When I build things I tend to look for simple solutions, sans bloat, which could be easily understood and customized. Unfortunately, when I was looking for one last year there were none for my use\\xa0case…</p><p>My team and I have implemented and trained a natural language classification engine, <a href=\"https://www.archie.ai\"><em>Archie.AI</em></a>, and gave it the power to understand and generate answers from Google Analytics. The bot can give daily briefings about users’ state of business, predict the number of future visitors and answer over <a href=\"https://www.archie.ai/ask-me\">430 related questions</a>. It’s an excellent way to save time when looking for a particular metric or an instant business\\xa0advice.</p><p>It works wonderfully with Google Assistant and Alexa, however, when the time came to get a fast, clean interface for the web, there were no good-enough options. So I built one and kept it open-source. <a href=\"https://www.archie.ai/open-source\">chat-bubble</a> is the one-kilobyte JavaScript file with no dependencies that’s really easy to implement and understand:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;<br>);<br>chatWindow.talk({<br>  &quot;ice&quot;: { &quot;says&quot; : [ &quot;Hello!&quot; ] }<br>});</pre><pre>// <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples</a></pre><p><strong>Batteries included:</strong> a complete set of CSS styles and percision-timed animations, an ability to safely run functions in response to user actions, and a <em>pluggable processing engine</em>.</p><p>By “pluggable processing engine” I mean that the script is not going to tell you how to understand your user’s queries. It’s <em>up to you</em> to implement your own NLC. It’s <em>up to you</em> to either dynamically generate or write response scripts. However, it doesn’t leave you hanging. There are currently three ways to have it respond to your\\xa0users:</p><ol><li>Give your users options, which appear as buttons (see gif below). Nothing needs to be done here, this is built-in.</li><li>Use the provided sample code that utilizes a simple fuzzy-matching logic to map your users’ input to the options you prescribe (see gif\\xa0below).</li><li>Plug-in your own NLC engine (see gif\\xa0above).</li></ol><p>Those options are for recognizing user input. The output (what the bot says) is just as customizable. It could be as simple as a structured JavaScript object variable. Or it could be dynamically imported JSON data. Of course, it doesn’t have to be just one huge JSON file\\u200a—\\u200athat would be inefficient! In our case (again, see gif above), we broke it up into individual answers for the responses that require a trip to the server (on-demand) and some calculations on our\\xa0end.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/410/1*9sMLEpk7ZVFv-H6RPsCSow.gif\" /><figcaption>Bot library example with built-in button controls and input keyboard with fuzzy-match logic implemented. The JSON script that prescribes this conversation structure is\\xa0below:</figcaption></figure><pre>// a simple conversation script written with JSON</pre><pre>var conversationScript = {<br>  ice: {<br>    says: [&quot;Hi&quot;, &quot;Would you like banana or ice cream?&quot;],<br>    reply: [<br>      {<br>        question: &quot;Banana&quot;,<br>        answer: &quot;banana&quot;<br>      },<br>      {<br>        question: &quot;Ice Cream&quot;,<br>        answer: &quot;ice-cream&quot;<br>      }<br>    ]<br>  },<br>  banana: {<br>    says: [&quot;🍌&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  },<br>  &quot;ice-cream&quot;: {<br>    says: [&quot;🍦&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  }<br>}</pre><h3>Local memory.</h3><p>Over the next few months, we tested the script in production with about a thousand users, while adding a few tweaks and improving performance on older browsers. It has also been downloaded over 700 times as of\\xa0today.</p><p>The library works equally well on desktop and mobile. However, when it came time to publish it as a part of our Google Chrome browser extension user experience suffered. Because chat-bubble had no inherit persistence, the conversation history would evaporate every time the plugin window is closed. And that happened quite often as Chrome tends to kill the DOM of the plugins entirely each time the user shifts\\xa0focus.</p><p>That has to be\\xa0fixed.</p><p>There is no one way to keep the conversation history in on disk. I considered using Redux to manage the state, however, that’s a dependency and the philosophy so far is not to have one. That would also over-complicate things.</p><p>Instead, I decided to store a modified JSON object that would share the same structure as the conversation script in localStorage. It would be recalled every time the bot is brought up, however, it would also need\\xa0to:</p><ol><li>Have the potential to be used with a database or any other data storage\\xa0method.</li><li>Have different UI interactivity and style than the rest of the bot (a visual cue for the\\xa0user).</li><li>Be a progressive enhancement that doesn’t break the rest of the\\xa0app.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eQc_eyPCOSPRgt_UqMLSdA.png\" /><figcaption>chat-bubble-interactions is the LS key for keeping in-touch with the chat\\xa0history.</figcaption></figure><h4>Future-proofing.</h4><p>Keeping an option open for implementing a server-side storage solution is pretty straight-forward. The entire library is less than 340 lines of non-compressed, commented JavaScript. Shall anyone attempt to implement that, all that would need to be changed is JSON.parse(localStorage.getItem(interactionsLS)) method for accessing the history and localStorage.setItem(interactionsLS, JSON.stringify(interactionsHistory)) method for saving the\\xa0history.</p><p>The only roadblock I can see here is having to add a Promise -type checks to make sure that everything needed to display history is downloaded before proceeding. Something like this might take some work as there would need to be a few decisions made regarding when the download should start and what functions should it block. I’m leaving that for tomorrow.</p><h4>Custom UI for recalled conversations.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/957/1*ZkXx_a2X6pa46NSCkDD23Q.png\" /><figcaption>Note the “greyed-out” style for this recollected conversation up\\xa0top.</figcaption></figure><p>To keep things simple, previous conversations would appear in the chat as soon as the user opens\\xa0it.</p><p>However, as a side-effect of that decision, those conversations would <em>have</em> to be styled differently to avoid confusing the user. Additionally, the user responses would need special attention when stored and recalled, since user responses <strong>can not have any interactivity associated with\\xa0them</strong>.</p><p>What I mean is that while highlighting chat bubbles in black and floating them right for user responses isn’t that hard there are implications when the chat uses buttons instead of keyboard input messages. Read\\xa0on.</p><p>Consider the example (below) when the user is presented with options to select one of the two or more buttons as a way of answering to the bot. Obviously storing answer options in history isn’t helpful\\u200a—\\u200athey have nothing to do with conversation structure after they’ve been interacted with. Only the user’s response (their selected answer bubble) is relevant. The trick is not storing anything in history until the user has created their final interaction.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*SeO8giseO7LVQ_4D5O3p6w.gif\" /><figcaption>Note how the <strong>answer options</strong> no longer appear in the conversation history.</figcaption></figure><p>For this purpose, I’ve created two functions for saving history: interactionsSave() and interactionsSaveCommit()\\u200a—\\u200awhere the former would be called to mutate the proposed save object in RAM and the latter would commit that object to localStorage.</p><p>interactionSave() would be called every time the bot produces a response, but only after the user has committed their answer. Because when the user clicks a bubble our script has already “forgotten” what that button looked like in terms of DOM structure, a new one would be made, specifically for committing to conversation history:</p><pre>// add re-generated user picks to the history stack<br>if (_convo[key] !== undefined &amp;&amp; content !== undefined) {<br>  interactionsSave(<br>    &#39;&lt;span class=&quot;bubble-button reply-pick&quot;&gt;&#39; + content + &quot;&lt;/span&gt;&quot;,<br>    &quot;reply reply-pick&quot;<br>  )<br>}</pre><p>interactionsSaveCommit() would be called every time a new speech bubble is created in DOM by the means of addBubble() function.</p><h4><strong>Progressively enhancing.</strong></h4><p>This is a relatively new feature that not everyone would want to use, of course. It is also experimental and could easily be overdone (should someone try to remember a 1,000 interactions the performance and user experience would drop every time the boat would load). So by default I left it\\xa0off:</p><pre>recallInteractions = options.recallInteractions || 0</pre><p>Getting it to function is super simple\\xa0though:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;,<br>  { recallInteractions: 10 }<br>);</pre><p>…All that does is tells this interactionsSave() to toss unnecessary stuff\\xa0away:</p><pre>if (interactionsHistory.length &gt; recallInteractions)<br>      interactionsHistory.shift()</pre><p>For simplicity’s sake, all work on chat-bubble is done without any kind of build steps. All JavaScript is written and ran immediately in-browser (even though developers who implement it are given an option to use ES6 Import method). Because the browsers read JavaScript from the hard-drive in develop mode, any attempt to use localStorage breaks the entire code base as it’s not allowed (due to security restrictions). Which made me think: this could happen quite often in other environments. So I’ve implemented a fallback with a\\xa0warning:</p><pre>// local storage for recalling conversations upon restart<br>  var localStorageCheck = function() {<br>    var test = &quot;chat-bubble-storage-test&quot;<br>    try {<br>      localStorage.setItem(test, test)<br>      localStorage.removeItem(test)<br>      return true<br>    } catch (error) {<br>      console.error(<br>        &quot;Your server does not allow storing data locally. Most likely it&#39;s because you&#39;ve opened this page from your hard-drive. For testing, you can disable your browser&#39;s security or start a localhost environment.&quot;<br>      )<br>      return false<br>    }<br>  }<br>  var localStorageAvailable = localStorageCheck() &amp;&amp; recallInteractions &gt; 0</pre><p>Now everything should still work even if the browser can not access disk\\xa0memory.</p><p>As of today, the updated script is available through NPM as chat-bubble@next. It is already performing on our <a href=\"https://www.archie.ai/chrome-extension\">Google Chrome extension</a> and so far is able to save a lot of headache for the users, as well as dramatically reduce perceived loading\\xa0time.</p><p>All of the code described here is available on <a href=\"https://github.com/dmitrizzle/chat-bubble\">this</a> GitHub\\xa0repo.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f0d17e015401\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/storing-recalling-bot-interactions-%EF%B8%8F-f0d17e015401\">Storing &amp; recalling bot interactions☝️🤖</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Return Flight',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Return Flight'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/return-flight-da9111784266?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/return-flight-da9111784266?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/da9111784266',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'travel', 'scheme': None, 'label': None},\n",
       "    {'term': 'startup-lessons', 'scheme': None, 'label': None},\n",
       "    {'term': 'ycombinator', 'scheme': None, 'label': None},\n",
       "    {'term': 'startup', 'scheme': None, 'label': None},\n",
       "    {'term': 'silicon-valley', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Dmitri'}],\n",
       "   'author': 'Dmitri',\n",
       "   'author_detail': {'name': 'Dmitri'},\n",
       "   'published': 'Wed, 10 Jan 2018 06:17:06 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=10, tm_hour=6, tm_min=17, tm_sec=6, tm_wday=2, tm_yday=10, tm_isdst=0),\n",
       "   'updated': '2018-01-10T06:17:05.931Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=10, tm_hour=6, tm_min=17, tm_sec=5, tm_wday=2, tm_yday=10, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<p>Entire trip lasted around four days, half of which I spent in the air. Three different planes carried me from Chiang Mai to Bangkok, then Taipei, then San Francisco. Three more did it again in reverse\\xa0order.</p><p>I crossed the Pacific twice for a ten-minute meeting.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*g3osmShBgsheGn7KreX0zw.jpeg\" /><figcaption>All the photos in this essay were taken with my fourty-year-old Yashica Electro 35 camera on Ilford Pan 100\\xa0film.</figcaption></figure><p>A week prior, Ishtiaq called first thing in the morning with the news: Y Combinator invited us for an interview and all three co-founders had to be\\xa0there.</p><p>Y Combinator is the most respected startup accelerator program on the planet. They helped Air BnB, Dropbox and Reddit (amongst hundreds of others) get to the position they are at today. Their unique way of deciding whether we were worth their investment is paying for everyone’s return flights and accommodations to meet us for exactly ten\\xa0minutes.</p><p>Arjun flew from Dubai and I flew from Chiang Mai to meet Ish at our tiny San Francisco HQ.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w8ZUtWId7FgLWSKQWzkFNQ.jpeg\" /></figure><p>My part of the job at <a href=\"https://www.archie.ai/\">the company</a> is managing technical resources, building, and fixing things from my home in Thailand. Last time I flew to SFO I was there for nine months before making it\\xa0back.</p><p>While in California, I was always busy. Surrounded by great people, though I often felt lonely, wishing I was back home with my girlfriend, Betty. This trip brought a lot of those memories back. Of course, the prospect of seeing Arjun and Ishtiaq, my very close friends and co-founders, as well as a shot at being a part of a Silicon Valley’s elite club was exhilarating. I felt as if I was being propelled to the heights of an emotional rollercoaster as I sat in the tail section of the plane, quaking from the turbulence.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*keTy7W6yPIVHlmmTY46yAA.jpeg\" /><figcaption>An edgy stewardess sat facing me directly across the emergency exit route. She didn’t seem to stay still for one minute during the entire flight. Perhaps it was her first year at the\\xa0job.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zOWO6cBm82Jckrh20_I8FQ.jpeg\" /></figure><p>Border-crossing is everyone’s least favourite part of international travel. Even with a Canadian passport, arguably one of the best travel documents in the world, you could still get\\xa0hassled.</p><p>A long line of tired passengers snaked through the hall. I sent my messages out, checked my emails and waited for my turn. Shifting one foot in front of the other, as the crowd methodically inched through the three open\\xa0booths.</p><p>The invitation letter I presented to the officer seemed to have immediately put him in a good mood. He waved me in while sharing a joke with his co-worker. I drowsily stumbled across the hall, amused at the amount of grease a sheet of paper has added to the grinding process of being admitted to the\\xa0USA.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JdQVusc62VItFN_GR-Eqhw.jpeg\" /><figcaption>Little Hollywood.</figcaption></figure><p>I took a short Uber ride with two other passengers before arriving at the house. Ish met me with a bear hug and we spent an hour catching up until Arjun, who flew in a little earlier, woke up and we got some\\xa0dinner.</p><h3>The house.</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mcF_iGN8n7_VCgKG5UVTRA.jpeg\" /><figcaption>Ish and I, captured by\\xa0Arjun.</figcaption></figure><p>The house, our HQ, seemed unchanged since the last time I was\\xa0there.</p><p>It resided in San Franciso’s <em>Little Hollywood</em>\\u200a—\\u200aa fairly unknown neighbourhood that warranted a (relatively) affordable rent, a distant view of a park and close proximity to Caltrain\\xa0station.</p><p>We made the garage our office with an array of sticky notes, company posters, a whiteboard and large table space that hosted laptops, spare monitors and a few home automation speakers. A few of my photographs (mostly mountains and trees) were hanging on the walls, but the piano was\\xa0gone.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4bbhbZtVZFXe2P6IW8NVkw.jpeg\" /><figcaption>Arjun.</figcaption></figure><p>Next morning I got to meet Bhargav and Chandra in-person. They were both responsible for developing new features for our product throughout the past few months, though I’ve only spoken to them on the phone until now. It was all business as we were in the rush to prepare for the interview.</p><h3>The interview.</h3><p>It took us about an hour in an old van to get to Mountain View. Our Uber driver did not seem to be in the rush; he drove at or below the speed limit the entire time. Which made me feel uneasy as I tend to speed whenever I’m on the road, though we had more than enough\\xa0time.</p><p>Y Combinator building is a refurbished mini-warehouse that’s been furnished with nicely-painted walls, chairs and sofas. A small plaque, no larger than a mailbox stood in front of it, identifying it as the place we wanted to be\\xa0at.</p><p>Met a few other founders in the parking lot. A horoscope app, a social tool for events, and women’s health cycle tracker. We stood in an awkward circle, wondering if we’d ever see each other\\xa0again.</p><p>There were seven or eight people in the interview room. Naturally, only a few of us spoke as the decisionmakers were trying to determine whether we were the right choice for them. We were asked just a handful of typical “investor” questions. Everything went by uncomfortably quick, leaving only a hazy recollection that felt like a hallucination.</p><p>We took a train back and waited at the house. The rejection email arrived a few hours before my scheduled departure.</p><p>Effectively nothing has changed for the trajectory of our business. There were over a thousand customers in our database that we had to satisfy and convert. A long list of products to be built, bugs to be fixed, and newly scheduled meetings to attend. Still, nobody likes to\\xa0lose.</p><p>I flew home looking forward to seeing Betty and all the comforts of sleeping in my own\\xa0bed.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w2dAR6xB8H8J-sVRBC3i3g.jpeg\" /></figure><p>This story has originally been published on Analog.Cafe\\u200a—\\u200aa film photography publication and features events around Archie.AI founding\\xa0team:</p><ul><li><a href=\"https://www.analog.cafe/zine/return-flight-31p7\">Read the full story at Analog.Cafe</a></li><li><a href=\"https://www.archie.ai\">Archie.AI: Google Analytics Chatbot</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=da9111784266\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/return-flight-da9111784266\">Return Flight</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<p>Entire trip lasted around four days, half of which I spent in the air. Three different planes carried me from Chiang Mai to Bangkok, then Taipei, then San Francisco. Three more did it again in reverse\\xa0order.</p><p>I crossed the Pacific twice for a ten-minute meeting.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*g3osmShBgsheGn7KreX0zw.jpeg\" /><figcaption>All the photos in this essay were taken with my fourty-year-old Yashica Electro 35 camera on Ilford Pan 100\\xa0film.</figcaption></figure><p>A week prior, Ishtiaq called first thing in the morning with the news: Y Combinator invited us for an interview and all three co-founders had to be\\xa0there.</p><p>Y Combinator is the most respected startup accelerator program on the planet. They helped Air BnB, Dropbox and Reddit (amongst hundreds of others) get to the position they are at today. Their unique way of deciding whether we were worth their investment is paying for everyone’s return flights and accommodations to meet us for exactly ten\\xa0minutes.</p><p>Arjun flew from Dubai and I flew from Chiang Mai to meet Ish at our tiny San Francisco HQ.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w8ZUtWId7FgLWSKQWzkFNQ.jpeg\" /></figure><p>My part of the job at <a href=\"https://www.archie.ai/\">the company</a> is managing technical resources, building, and fixing things from my home in Thailand. Last time I flew to SFO I was there for nine months before making it\\xa0back.</p><p>While in California, I was always busy. Surrounded by great people, though I often felt lonely, wishing I was back home with my girlfriend, Betty. This trip brought a lot of those memories back. Of course, the prospect of seeing Arjun and Ishtiaq, my very close friends and co-founders, as well as a shot at being a part of a Silicon Valley’s elite club was exhilarating. I felt as if I was being propelled to the heights of an emotional rollercoaster as I sat in the tail section of the plane, quaking from the turbulence.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*keTy7W6yPIVHlmmTY46yAA.jpeg\" /><figcaption>An edgy stewardess sat facing me directly across the emergency exit route. She didn’t seem to stay still for one minute during the entire flight. Perhaps it was her first year at the\\xa0job.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zOWO6cBm82Jckrh20_I8FQ.jpeg\" /></figure><p>Border-crossing is everyone’s least favourite part of international travel. Even with a Canadian passport, arguably one of the best travel documents in the world, you could still get\\xa0hassled.</p><p>A long line of tired passengers snaked through the hall. I sent my messages out, checked my emails and waited for my turn. Shifting one foot in front of the other, as the crowd methodically inched through the three open\\xa0booths.</p><p>The invitation letter I presented to the officer seemed to have immediately put him in a good mood. He waved me in while sharing a joke with his co-worker. I drowsily stumbled across the hall, amused at the amount of grease a sheet of paper has added to the grinding process of being admitted to the\\xa0USA.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JdQVusc62VItFN_GR-Eqhw.jpeg\" /><figcaption>Little Hollywood.</figcaption></figure><p>I took a short Uber ride with two other passengers before arriving at the house. Ish met me with a bear hug and we spent an hour catching up until Arjun, who flew in a little earlier, woke up and we got some\\xa0dinner.</p><h3>The house.</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mcF_iGN8n7_VCgKG5UVTRA.jpeg\" /><figcaption>Ish and I, captured by\\xa0Arjun.</figcaption></figure><p>The house, our HQ, seemed unchanged since the last time I was\\xa0there.</p><p>It resided in San Franciso’s <em>Little Hollywood</em>\\u200a—\\u200aa fairly unknown neighbourhood that warranted a (relatively) affordable rent, a distant view of a park and close proximity to Caltrain\\xa0station.</p><p>We made the garage our office with an array of sticky notes, company posters, a whiteboard and large table space that hosted laptops, spare monitors and a few home automation speakers. A few of my photographs (mostly mountains and trees) were hanging on the walls, but the piano was\\xa0gone.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4bbhbZtVZFXe2P6IW8NVkw.jpeg\" /><figcaption>Arjun.</figcaption></figure><p>Next morning I got to meet Bhargav and Chandra in-person. They were both responsible for developing new features for our product throughout the past few months, though I’ve only spoken to them on the phone until now. It was all business as we were in the rush to prepare for the interview.</p><h3>The interview.</h3><p>It took us about an hour in an old van to get to Mountain View. Our Uber driver did not seem to be in the rush; he drove at or below the speed limit the entire time. Which made me feel uneasy as I tend to speed whenever I’m on the road, though we had more than enough\\xa0time.</p><p>Y Combinator building is a refurbished mini-warehouse that’s been furnished with nicely-painted walls, chairs and sofas. A small plaque, no larger than a mailbox stood in front of it, identifying it as the place we wanted to be\\xa0at.</p><p>Met a few other founders in the parking lot. A horoscope app, a social tool for events, and women’s health cycle tracker. We stood in an awkward circle, wondering if we’d ever see each other\\xa0again.</p><p>There were seven or eight people in the interview room. Naturally, only a few of us spoke as the decisionmakers were trying to determine whether we were the right choice for them. We were asked just a handful of typical “investor” questions. Everything went by uncomfortably quick, leaving only a hazy recollection that felt like a hallucination.</p><p>We took a train back and waited at the house. The rejection email arrived a few hours before my scheduled departure.</p><p>Effectively nothing has changed for the trajectory of our business. There were over a thousand customers in our database that we had to satisfy and convert. A long list of products to be built, bugs to be fixed, and newly scheduled meetings to attend. Still, nobody likes to\\xa0lose.</p><p>I flew home looking forward to seeing Betty and all the comforts of sleeping in my own\\xa0bed.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w2dAR6xB8H8J-sVRBC3i3g.jpeg\" /></figure><p>This story has originally been published on Analog.Cafe\\u200a—\\u200aa film photography publication and features events around Archie.AI founding\\xa0team:</p><ul><li><a href=\"https://www.analog.cafe/zine/return-flight-31p7\">Read the full story at Analog.Cafe</a></li><li><a href=\"https://www.archie.ai\">Archie.AI: Google Analytics Chatbot</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=da9111784266\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/return-flight-da9111784266\">Return Flight</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Thank you for an incredible year from team Archie.AI',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Thank you for an incredible year from team Archie.AI'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/thank-you-for-an-incredible-year-from-team-archie-ai-fafd2a7c4f4?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/thank-you-for-an-incredible-year-from-team-archie-ai-fafd2a7c4f4?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/fafd2a7c4f4',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'artificial-intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'google-analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'startup', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Dmitri'}],\n",
       "   'author': 'Dmitri',\n",
       "   'author_detail': {'name': 'Dmitri'},\n",
       "   'published': 'Thu, 04 Jan 2018 06:16:19 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=4, tm_hour=6, tm_min=16, tm_sec=19, tm_wday=3, tm_yday=4, tm_isdst=0),\n",
       "   'updated': '2018-01-04T06:19:44.936Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=4, tm_hour=6, tm_min=19, tm_sec=44, tm_wday=3, tm_yday=4, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4>Happy Holidays!</h4><h4>This is Dmitri, CTO and co-founder of Archie.AI.</h4><p>I would like to personally thank you for being our pioneering customer. With your support and feedback, we are able to help over a thousand businesses of various sizes understand and interact with data better. Below is a quick recap of what happened during the past twelve\\xa0months.</p><h3><strong>2017 was a huge! </strong>We launched six products, amongst hundreds of features, including:</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*rQJF3ZOoiXNILfBgpEROXw.jpeg\" /></figure><p><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Bot</a>\\u200a—\\u200aCut through the clutter of Google Analytics with free, weekly email\\xa0reports.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*coJVTsslMQDmcHw9u_aFig.jpeg\" /></figure><p><a href=\"https://www.archie.ai/google-assistant\">Google Assistant Action</a>\\u200a—\\u200aTalk to your Google Analytics with Google Assistant-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*CmZHGDLnyFrhLVlOxJ50CQ.jpeg\" /></figure><p><a href=\"https://www.amazon.com/Archie-AI-Archie-Voice/dp/B07525T7R9\">Alexa Skill</a>\\u200a—\\u200aTalk to you Google Analytics on Amazon Alexa-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*9MOLxnt3fOLY7itlwtjxwg.jpeg\" /></figure><p><a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\">Chrome Extension</a>\\u200a—\\u200aTalk to your Google Analytics with Google Chrome Extension.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*ottjZYv2BgPIYM2yWeo0bA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/funnels\">Funnels</a>\\u200a—\\u200aEffortlessly compare conversion funnels using your existing Google Analytics account.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*vCgCMpWeYM0V7cdPctVEBA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/enterprise\">Enterprise</a>\\u200a—\\u200aAI/ML/Analytics Solution for your\\xa0SME.</p><p>Archie.AI user community has grown from five to 1,521 (as of this writing). The chart that you see below shows the speed at which Archie has attracted new converts to a better, faster and more natural way to understand data\\u200a—\\u200aby talking to\\xa0it.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_OhZTBcHuFYRG2Vt.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/0*VjCNe3RCS8q1NcD7.jpg\" /><figcaption>Archi.AI founding team at the Google NYC headquarters. I’m in the middle, Arjun Mohan is on your left and Ishtiaq Rahman is on your\\xa0right.</figcaption></figure><p>None of this would be possible without your feedback and support. Thank\\xa0you.</p><p>Stay tuned for more awesome launches this coming year. <strong>Expect big things in January\\xa02018!</strong></p><p>Best wishes,<br>Dmitri Tcherbadji<br>Founder/CTO ∙ <strong>Team Archie.AI</strong></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fafd2a7c4f4\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/thank-you-for-an-incredible-year-from-team-archie-ai-fafd2a7c4f4\">Thank you for an incredible year from team Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4>Happy Holidays!</h4><h4>This is Dmitri, CTO and co-founder of Archie.AI.</h4><p>I would like to personally thank you for being our pioneering customer. With your support and feedback, we are able to help over a thousand businesses of various sizes understand and interact with data better. Below is a quick recap of what happened during the past twelve\\xa0months.</p><h3><strong>2017 was a huge! </strong>We launched six products, amongst hundreds of features, including:</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*rQJF3ZOoiXNILfBgpEROXw.jpeg\" /></figure><p><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Bot</a>\\u200a—\\u200aCut through the clutter of Google Analytics with free, weekly email\\xa0reports.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*coJVTsslMQDmcHw9u_aFig.jpeg\" /></figure><p><a href=\"https://www.archie.ai/google-assistant\">Google Assistant Action</a>\\u200a—\\u200aTalk to your Google Analytics with Google Assistant-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*CmZHGDLnyFrhLVlOxJ50CQ.jpeg\" /></figure><p><a href=\"https://www.amazon.com/Archie-AI-Archie-Voice/dp/B07525T7R9\">Alexa Skill</a>\\u200a—\\u200aTalk to you Google Analytics on Amazon Alexa-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*9MOLxnt3fOLY7itlwtjxwg.jpeg\" /></figure><p><a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\">Chrome Extension</a>\\u200a—\\u200aTalk to your Google Analytics with Google Chrome Extension.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*ottjZYv2BgPIYM2yWeo0bA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/funnels\">Funnels</a>\\u200a—\\u200aEffortlessly compare conversion funnels using your existing Google Analytics account.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*vCgCMpWeYM0V7cdPctVEBA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/enterprise\">Enterprise</a>\\u200a—\\u200aAI/ML/Analytics Solution for your\\xa0SME.</p><p>Archie.AI user community has grown from five to 1,521 (as of this writing). The chart that you see below shows the speed at which Archie has attracted new converts to a better, faster and more natural way to understand data\\u200a—\\u200aby talking to\\xa0it.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_OhZTBcHuFYRG2Vt.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/0*VjCNe3RCS8q1NcD7.jpg\" /><figcaption>Archi.AI founding team at the Google NYC headquarters. I’m in the middle, Arjun Mohan is on your left and Ishtiaq Rahman is on your\\xa0right.</figcaption></figure><p>None of this would be possible without your feedback and support. Thank\\xa0you.</p><p>Stay tuned for more awesome launches this coming year. <strong>Expect big things in January\\xa02018!</strong></p><p>Best wishes,<br>Dmitri Tcherbadji<br>Founder/CTO ∙ <strong>Team Archie.AI</strong></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fafd2a7c4f4\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/thank-you-for-an-incredible-year-from-team-archie-ai-fafd2a7c4f4\">Thank you for an incredible year from team Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': '7 painfully obvious lessons I learned in 2017 while building a startup.',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '7 painfully obvious lessons I learned in 2017 while building a startup.'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/7-painfully-obvious-lessons-i-learned-in-2017-while-building-my-startup-655e1b1c99f9?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/7-painfully-obvious-lessons-i-learned-in-2017-while-building-my-startup-655e1b1c99f9?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/655e1b1c99f9',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'product', 'scheme': None, 'label': None},\n",
       "    {'term': 'startup', 'scheme': None, 'label': None},\n",
       "    {'term': '2018', 'scheme': None, 'label': None},\n",
       "    {'term': 'new-year', 'scheme': None, 'label': None},\n",
       "    {'term': 'lessons-learned', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Ishtiaq Rahman'}],\n",
       "   'author': 'Ishtiaq Rahman',\n",
       "   'author_detail': {'name': 'Ishtiaq Rahman'},\n",
       "   'published': 'Mon, 01 Jan 2018 06:16:27 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2018, tm_mon=1, tm_mday=1, tm_hour=6, tm_min=16, tm_sec=27, tm_wday=0, tm_yday=1, tm_isdst=0),\n",
       "   'updated': '2018-02-11T19:54:09.631Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2018, tm_mon=2, tm_mday=11, tm_hour=19, tm_min=54, tm_sec=9, tm_wday=6, tm_yday=42, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<p>Happy New Year Medium!\\xa0🎉</p><p>I didn’t know I suck at so many different things before I started a company.\\xa0🚀</p><p>Building a company requires you to get good at a lot of different things besides your domain expertise. You may be good at product/engineering but you also have to do other things like fundraising, hiring, marketing and taxes etc. As a result, you become self-aware of all the things you’re bad\\xa0at.</p><p>Exhibit A: I am really bad at PR. I’d send press releases to journalists with detailed product description, quotes, image resources and announcements about Archie.AI’s product releases and never hear back. We hit 500 customers, launched on Google Assistant, Alexa, Chrome Webstore, won startup contests, got huge computation grants from IBM and NVIDIA, raised a funding round\\u200a—\\u200apress didn’t even accidentally write about\\xa0us.</p><p>I just sucked at telling a compelling story to write about. But the PR failure pushed us to build our own audience the hard\\xa0way.</p><p>We started getting our message across directly to whoever would\\xa0listen.</p><p>We built our own audience through sharing real insights we learned and people started to\\xa0listen.</p><p>Here are 7 painfully obvious lessons I learned in 2017 while building Archie.AI, in no particular order.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*CB3KH2nTYMnldnVh.gif\" /><figcaption>Gif by <a href=\"https://giphy.com/lisa-vertudaches/\">Lisa Vertudaches</a></figcaption></figure><ol><li>Do not underestimate the power of your vulnerability. Sharing it is hard, but it is instantly relatable to EVERYONE. People like real shit, it’s beautifully simple.</li><li>Empathy is the most useful skill for building any product. Second most useful skill is the ability to rely on Data to make decisions.</li><li>People will never buy something they don’t understand. No matter how intricate your product or service is, a 10-year-old should be able to verbalize it in his/her own\\xa0words.</li><li>Humans have no issue paying for things that give them value. Your customers will look for a good deal, but if you can provide real value, people/market will reward you for your\\xa0efforts.</li><li>If you have real insights\\u200a—\\u200aonly acquired by experiments and experience\\u200a—\\u200apeople will listen. Your audience may be small today but it will grow if you have a real story to tell and you’re willing to put yourself out there in front of the\\xa0world.</li><li>“Done” is always, unequivocally better than “perfect”. Perfection should reside inside your head where all externalities can be\\xa0ignored.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/245/0*42zkp6Xd3zgYYGCa.gif\" /></figure><p>7. Faking courage is the same as having real\\xa0courage.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*Q6Fa6uGL-L76JDLu.gif\" /><figcaption>Bran thought about it. ‘Can a man still be brave if he’s afraid?’<br>‘That is the only time a man can be brave,’ his father told\\xa0him.”</figcaption></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=655e1b1c99f9\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/7-painfully-obvious-lessons-i-learned-in-2017-while-building-my-startup-655e1b1c99f9\">7 painfully obvious lessons I learned in 2017 while building a startup.</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<p>Happy New Year Medium!\\xa0🎉</p><p>I didn’t know I suck at so many different things before I started a company.\\xa0🚀</p><p>Building a company requires you to get good at a lot of different things besides your domain expertise. You may be good at product/engineering but you also have to do other things like fundraising, hiring, marketing and taxes etc. As a result, you become self-aware of all the things you’re bad\\xa0at.</p><p>Exhibit A: I am really bad at PR. I’d send press releases to journalists with detailed product description, quotes, image resources and announcements about Archie.AI’s product releases and never hear back. We hit 500 customers, launched on Google Assistant, Alexa, Chrome Webstore, won startup contests, got huge computation grants from IBM and NVIDIA, raised a funding round\\u200a—\\u200apress didn’t even accidentally write about\\xa0us.</p><p>I just sucked at telling a compelling story to write about. But the PR failure pushed us to build our own audience the hard\\xa0way.</p><p>We started getting our message across directly to whoever would\\xa0listen.</p><p>We built our own audience through sharing real insights we learned and people started to\\xa0listen.</p><p>Here are 7 painfully obvious lessons I learned in 2017 while building Archie.AI, in no particular order.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*CB3KH2nTYMnldnVh.gif\" /><figcaption>Gif by <a href=\"https://giphy.com/lisa-vertudaches/\">Lisa Vertudaches</a></figcaption></figure><ol><li>Do not underestimate the power of your vulnerability. Sharing it is hard, but it is instantly relatable to EVERYONE. People like real shit, it’s beautifully simple.</li><li>Empathy is the most useful skill for building any product. Second most useful skill is the ability to rely on Data to make decisions.</li><li>People will never buy something they don’t understand. No matter how intricate your product or service is, a 10-year-old should be able to verbalize it in his/her own\\xa0words.</li><li>Humans have no issue paying for things that give them value. Your customers will look for a good deal, but if you can provide real value, people/market will reward you for your\\xa0efforts.</li><li>If you have real insights\\u200a—\\u200aonly acquired by experiments and experience\\u200a—\\u200apeople will listen. Your audience may be small today but it will grow if you have a real story to tell and you’re willing to put yourself out there in front of the\\xa0world.</li><li>“Done” is always, unequivocally better than “perfect”. Perfection should reside inside your head where all externalities can be\\xa0ignored.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/245/0*42zkp6Xd3zgYYGCa.gif\" /></figure><p>7. Faking courage is the same as having real\\xa0courage.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*Q6Fa6uGL-L76JDLu.gif\" /><figcaption>Bran thought about it. ‘Can a man still be brave if he’s afraid?’<br>‘That is the only time a man can be brave,’ his father told\\xa0him.”</figcaption></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=655e1b1c99f9\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/7-painfully-obvious-lessons-i-learned-in-2017-while-building-my-startup-655e1b1c99f9\">7 painfully obvious lessons I learned in 2017 while building a startup.</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'Introducing Funnels By Archie.AI',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Introducing Funnels By Archie.AI'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/introducing-funnels-by-archie-ai-a5ff206d530a?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/introducing-funnels-by-archie-ai-a5ff206d530a?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/a5ff206d530a',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'conversations', 'scheme': None, 'label': None},\n",
       "    {'term': 'google-analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'growth-hacking', 'scheme': None, 'label': None},\n",
       "    {'term': 'analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'marketing', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Ishtiaq Rahman'}],\n",
       "   'author': 'Ishtiaq Rahman',\n",
       "   'author_detail': {'name': 'Ishtiaq Rahman'},\n",
       "   'published': 'Thu, 14 Dec 2017 05:51:06 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=14, tm_hour=5, tm_min=51, tm_sec=6, tm_wday=3, tm_yday=348, tm_isdst=0),\n",
       "   'updated': '2017-12-14T22:00:04.997Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2017, tm_mon=12, tm_mday=14, tm_hour=22, tm_min=0, tm_sec=4, tm_wday=3, tm_yday=348, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h3>A tool to effortlessly compare Google Analytics funnels by Archie.AI</h3><p>Team Archie.AI keep dropping hits.\\xa0🚀</p><p>This time we’re back with a tool to help you use Google Analytics data to instantly create and compare conversion funnels side-by-side.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/900/1*QUiooKUO6qqYdwc9R3ZVmQ.gif\" /><figcaption>Funnels by Archie.AI. Try it here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></figcaption></figure><p>Here are some quick use-cases.</p><ul><li>Compare the performance of referrals from different sources.<br>E.g. Facebook Referrals VS Google Referrals: Who’s converting more?</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YsNN0KzhQLmx4NxjmMiP-g.gif\" /><figcaption>Compare campaign performance with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Compare the pages on your website to see what is working and what isn’t<br>E.g: Compare two of your content pages to see which one ends up converting most of your conversions.</li><li>Compare conversion performance over time.<br>E.g. Compare conversion funnels before/after website redesigns to see if performance changed.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sS6gcT441g3_Om8Ao1fvrA.gif\" /><figcaption>Compare conversion performance over time with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Run A/B testing of 2 landing pages and compare effectiveness</li><li>Compare conversion funnels across Device type, Browser type, locations and\\xa0more.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-Qv0qJ9qjQ7nD2I0o7NC4w.jpeg\" /><figcaption>Compare conversion funnels across Device type, Browser type, locations and\\xa0more.</figcaption></figure><p>Following are the roles we built this tool\\xa0for.</p><ul><li>You’re a Product Owner/Product Manager/Founder directly responsible for the performance of your business’s digital\\xa0front.</li><li>You’re part of a business that sells their product/services online through websites, web/mobile apps.</li><li>You’re an engineer trying to find a better way (automated) to sift through data and report actionable analytics, anomalies and patterns to your\\xa0team.</li><li>You’re responsible for allocating how and where Digital Marketing dollars are\\xa0spent.</li></ul><p>We’re offering 15 day trial period so you can play around with it 🎁 and let us know what you\\xa0think.</p><p>Try it out here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a5ff206d530a\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/introducing-funnels-by-archie-ai-a5ff206d530a\">Introducing Funnels By Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h3>A tool to effortlessly compare Google Analytics funnels by Archie.AI</h3><p>Team Archie.AI keep dropping hits.\\xa0🚀</p><p>This time we’re back with a tool to help you use Google Analytics data to instantly create and compare conversion funnels side-by-side.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/900/1*QUiooKUO6qqYdwc9R3ZVmQ.gif\" /><figcaption>Funnels by Archie.AI. Try it here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></figcaption></figure><p>Here are some quick use-cases.</p><ul><li>Compare the performance of referrals from different sources.<br>E.g. Facebook Referrals VS Google Referrals: Who’s converting more?</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YsNN0KzhQLmx4NxjmMiP-g.gif\" /><figcaption>Compare campaign performance with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Compare the pages on your website to see what is working and what isn’t<br>E.g: Compare two of your content pages to see which one ends up converting most of your conversions.</li><li>Compare conversion performance over time.<br>E.g. Compare conversion funnels before/after website redesigns to see if performance changed.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sS6gcT441g3_Om8Ao1fvrA.gif\" /><figcaption>Compare conversion performance over time with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Run A/B testing of 2 landing pages and compare effectiveness</li><li>Compare conversion funnels across Device type, Browser type, locations and\\xa0more.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-Qv0qJ9qjQ7nD2I0o7NC4w.jpeg\" /><figcaption>Compare conversion funnels across Device type, Browser type, locations and\\xa0more.</figcaption></figure><p>Following are the roles we built this tool\\xa0for.</p><ul><li>You’re a Product Owner/Product Manager/Founder directly responsible for the performance of your business’s digital\\xa0front.</li><li>You’re part of a business that sells their product/services online through websites, web/mobile apps.</li><li>You’re an engineer trying to find a better way (automated) to sift through data and report actionable analytics, anomalies and patterns to your\\xa0team.</li><li>You’re responsible for allocating how and where Digital Marketing dollars are\\xa0spent.</li></ul><p>We’re offering 15 day trial period so you can play around with it 🎁 and let us know what you\\xa0think.</p><p>Try it out here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a5ff206d530a\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/introducing-funnels-by-archie-ai-a5ff206d530a\">Introducing Funnels By Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'},\n",
       "  {'title': 'An easier way to get Google Analytics email reports',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'An easier way to get Google Analytics email reports'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://medium.com/archieai/an-easier-way-to-get-google-analytics-email-reports-b456bb5eec7?source=rss----4e8922a89498---4'}],\n",
       "   'link': 'https://medium.com/archieai/an-easier-way-to-get-google-analytics-email-reports-b456bb5eec7?source=rss----4e8922a89498---4',\n",
       "   'id': 'https://medium.com/p/b456bb5eec7',\n",
       "   'guidislink': False,\n",
       "   'tags': [{'term': 'productivity', 'scheme': None, 'label': None},\n",
       "    {'term': 'google-analytics', 'scheme': None, 'label': None},\n",
       "    {'term': 'marketing', 'scheme': None, 'label': None},\n",
       "    {'term': 'artificial-intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'analytics', 'scheme': None, 'label': None}],\n",
       "   'authors': [{'name': 'Dmitri'}],\n",
       "   'author': 'Dmitri',\n",
       "   'author_detail': {'name': 'Dmitri'},\n",
       "   'published': 'Thu, 23 Nov 2017 06:21:36 GMT',\n",
       "   'published_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=23, tm_hour=6, tm_min=21, tm_sec=36, tm_wday=3, tm_yday=327, tm_isdst=0),\n",
       "   'updated': '2017-11-23T21:12:19.767Z',\n",
       "   'updated_parsed': time.struct_time(tm_year=2017, tm_mon=11, tm_mday=23, tm_hour=21, tm_min=12, tm_sec=19, tm_wday=3, tm_yday=327, tm_isdst=0),\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<h4>How to set up weekly email reports from your GA account with traffic &amp; conversion summary, predictions and\\xa0insights</h4><blockquote><strong>TL;DR:</strong> Here’s the <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><strong>link</strong></a> for an app that does it for\\xa0you.</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ui4EJXOWGhhDvgjL4U7Axw.jpeg\" /></figure><p>I spend a lot of my time working with Google Analytics. I measure visitors of an e-commerce website that sells prints, a community blog, a Kickstarter page for when my campaign was live and multiple web properties owned by the start up I co-founded. It’s a real hassle to try and keep up with all that data, let alone making sense of\\xa0it.</p><p>I thought that my problem was unique to serial webmasters, however it turns out that <strong>making sense of Google Analytics can be a challenge, even for a casual blogger</strong>. Seeing the default graph of visitors over time doesn’t provide as much value as one might think. Real-time reporting surely is exciting, but not very insightful. A proper way to get an answer to <em>“What should I do with my website next?”</em> question can only be found by digging through numerous GA views, often importing the data into a spreadsheet and processing it further. Only then you <em>may</em> have some\\xa0answers.</p><h3>Email reporting\\u200a—\\u200aspending less time digging through\\xa0data.</h3><p>A friend once brought up email reporting as a possible solution. He owns a medium-sized blog where he posts reviews of vintage camera lenses and street photography advice. It turns out that Google Analytics provides email reports that could potentially cut down on the time spent digging through data on the daily\\xa0basis.</p><p>Perhaps I could do better if I concentrate on building content, code and design for my websites and let the data get to me, instead of seeking it out? At least that’s what I hoped the email reporting would do: give me the numbers every week or so. I’ve never found the constant stream of traffic reports that useful\\xa0anyways.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/351/1*eYL5tFDQTLcuJJ4yk3EKGQ.jpeg\" /><figcaption>The dream: simple, usable email reporting.</figcaption></figure><h4>Google Analytics’ proprietary email reporting: not very simple, not very valuable.</h4><p>Everything sounded fantastic at the start. Google is an all-powerful tech giant that can whip out amazing software. I’ve got a decade’s worth of programming experience &amp; industry know-how. This is just an email report\\u200a—\\u200ashould be super-easy! Right?</p><p>No. First of all, Google has been revamping its Analytics software for the past few years practically non-stop. Hence finding good instructions with correct screenshots on the web is a challenge. After some digging it became evident that I’d have to create a custom dashboard that can then be sent as a PDF attachment to my email at a frequency of my choosing. Making such dashboard is a lot of work, and if it isn’t properly designed to cater to my application, I’ll be getting <strong>misleading reports, every time</strong>. Which isn’t\\xa0good.</p><p>I have to say that PDF reports look great with the graphics and all, although I’d have to wait for them to download and open in a very mobile un-friendly way: zoom, scroll, zoom,\\xa0scroll…</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*T6ojhkfWCG02gRY2LokViQ.jpeg\" /></figure><p>Long story short, GA email reporting can be an incredibly powerful feature, but to set it up correctly you’d have to do a data requirements inventory on your web property and get it right. Which isn’t\\xa0simple.</p><h3>An easier, better way to get Google Analytics email\\xa0reports.</h3><blockquote>Disclaimer: the product I’m about to recommend was built by my\\xa0startup.</blockquote><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UDjRuV8rs2VeYLM_FMzO4w.jpeg\" /></a><figcaption>The tool is called Archie.AI. It’s free and easy to set up, you can get it here: <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">https://www.archie.ai/email-reporting-for-google-analytics</a></figcaption></figure><p>One of the advantages of Google Analytics that becomes a drawback later on is the way it presents data. Always cut-dry facts, with zero opinions. Which is perfect if you have a data analyst on your payroll. That person would take those facts and let you know what she thinks it all means and what your next steps should\\xa0be.</p><p>My team and I have been working on an algorithm that could perform that very task:<strong> interpret and suggest, according to available data</strong>. The code that does that runs thousands of queries every day, answering questions like “Predict my next week’s traffic.” or “How do I increase my traffic?” This tool is part of a larger suite of medium to advanced Google Analytics AI enhancements:<em> Archie.AI</em>.</p><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BeqMTlg3OVJt-oaGdUYrjA.png\" /></a></figure><p>After trying the email reporting tool that comes with Google Analytics and chatting with some of our clients we decided to use our natural language generation platform to create simple, curated email reports. The goal was to select about seven key metrics and generate insights with predictions and human-like advice. Then send it every seven days, just before the week’s\\xa0start.</p><p>Besides giving human-like opinions and advice on your data we made sure our tool does not require any work on your end, besides clicking “Log in with Google” and selecting the property you’d like to track. You can also add conversion tracking with dollar (or whatever your currency is) value to get some e-commerce or KPI reports\\u200a—\\u200abut that’s up to\\xa0you.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/680/1*8ymsMzKlAjjci1sSdq2yfg.gif\" /><figcaption>The setup process for Google Analytics email reporting with Archie.AI. Simple.</figcaption></figure><p>After tapping those three buttons you would get your first report instantly and all consequent reports every Sunday night (EST). The emails are all text, but the key points are highlighted to get your attention and the entire thing consists of <strong>algorithmic interpretations that can help you drive your decisions much better than any fancy graph\\xa0could.</strong></p><p>Although it’s a part of a larger suite of tools available with full Archie.AI membership we decided to make it 100% free, leaving the choice up to you on whether you want to upgrade or\\xa0not.</p><p>This is a fairly new product and we’re constantly looking for your feedback. If you’ve got some advice, criticism or ideas\\u200a—\\u200aplease don’t hesitate to let us know. In any case, follow <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">this link</a> to try it\\xa0out.</p><h3>🍻</h3><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b456bb5eec7\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/an-easier-way-to-get-google-analytics-email-reports-b456bb5eec7\">An easier way to get Google Analytics email reports</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       "   'summary': '<h4>How to set up weekly email reports from your GA account with traffic &amp; conversion summary, predictions and\\xa0insights</h4><blockquote><strong>TL;DR:</strong> Here’s the <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><strong>link</strong></a> for an app that does it for\\xa0you.</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ui4EJXOWGhhDvgjL4U7Axw.jpeg\" /></figure><p>I spend a lot of my time working with Google Analytics. I measure visitors of an e-commerce website that sells prints, a community blog, a Kickstarter page for when my campaign was live and multiple web properties owned by the start up I co-founded. It’s a real hassle to try and keep up with all that data, let alone making sense of\\xa0it.</p><p>I thought that my problem was unique to serial webmasters, however it turns out that <strong>making sense of Google Analytics can be a challenge, even for a casual blogger</strong>. Seeing the default graph of visitors over time doesn’t provide as much value as one might think. Real-time reporting surely is exciting, but not very insightful. A proper way to get an answer to <em>“What should I do with my website next?”</em> question can only be found by digging through numerous GA views, often importing the data into a spreadsheet and processing it further. Only then you <em>may</em> have some\\xa0answers.</p><h3>Email reporting\\u200a—\\u200aspending less time digging through\\xa0data.</h3><p>A friend once brought up email reporting as a possible solution. He owns a medium-sized blog where he posts reviews of vintage camera lenses and street photography advice. It turns out that Google Analytics provides email reports that could potentially cut down on the time spent digging through data on the daily\\xa0basis.</p><p>Perhaps I could do better if I concentrate on building content, code and design for my websites and let the data get to me, instead of seeking it out? At least that’s what I hoped the email reporting would do: give me the numbers every week or so. I’ve never found the constant stream of traffic reports that useful\\xa0anyways.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/351/1*eYL5tFDQTLcuJJ4yk3EKGQ.jpeg\" /><figcaption>The dream: simple, usable email reporting.</figcaption></figure><h4>Google Analytics’ proprietary email reporting: not very simple, not very valuable.</h4><p>Everything sounded fantastic at the start. Google is an all-powerful tech giant that can whip out amazing software. I’ve got a decade’s worth of programming experience &amp; industry know-how. This is just an email report\\u200a—\\u200ashould be super-easy! Right?</p><p>No. First of all, Google has been revamping its Analytics software for the past few years practically non-stop. Hence finding good instructions with correct screenshots on the web is a challenge. After some digging it became evident that I’d have to create a custom dashboard that can then be sent as a PDF attachment to my email at a frequency of my choosing. Making such dashboard is a lot of work, and if it isn’t properly designed to cater to my application, I’ll be getting <strong>misleading reports, every time</strong>. Which isn’t\\xa0good.</p><p>I have to say that PDF reports look great with the graphics and all, although I’d have to wait for them to download and open in a very mobile un-friendly way: zoom, scroll, zoom,\\xa0scroll…</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*T6ojhkfWCG02gRY2LokViQ.jpeg\" /></figure><p>Long story short, GA email reporting can be an incredibly powerful feature, but to set it up correctly you’d have to do a data requirements inventory on your web property and get it right. Which isn’t\\xa0simple.</p><h3>An easier, better way to get Google Analytics email\\xa0reports.</h3><blockquote>Disclaimer: the product I’m about to recommend was built by my\\xa0startup.</blockquote><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UDjRuV8rs2VeYLM_FMzO4w.jpeg\" /></a><figcaption>The tool is called Archie.AI. It’s free and easy to set up, you can get it here: <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">https://www.archie.ai/email-reporting-for-google-analytics</a></figcaption></figure><p>One of the advantages of Google Analytics that becomes a drawback later on is the way it presents data. Always cut-dry facts, with zero opinions. Which is perfect if you have a data analyst on your payroll. That person would take those facts and let you know what she thinks it all means and what your next steps should\\xa0be.</p><p>My team and I have been working on an algorithm that could perform that very task:<strong> interpret and suggest, according to available data</strong>. The code that does that runs thousands of queries every day, answering questions like “Predict my next week’s traffic.” or “How do I increase my traffic?” This tool is part of a larger suite of medium to advanced Google Analytics AI enhancements:<em> Archie.AI</em>.</p><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BeqMTlg3OVJt-oaGdUYrjA.png\" /></a></figure><p>After trying the email reporting tool that comes with Google Analytics and chatting with some of our clients we decided to use our natural language generation platform to create simple, curated email reports. The goal was to select about seven key metrics and generate insights with predictions and human-like advice. Then send it every seven days, just before the week’s\\xa0start.</p><p>Besides giving human-like opinions and advice on your data we made sure our tool does not require any work on your end, besides clicking “Log in with Google” and selecting the property you’d like to track. You can also add conversion tracking with dollar (or whatever your currency is) value to get some e-commerce or KPI reports\\u200a—\\u200abut that’s up to\\xa0you.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/680/1*8ymsMzKlAjjci1sSdq2yfg.gif\" /><figcaption>The setup process for Google Analytics email reporting with Archie.AI. Simple.</figcaption></figure><p>After tapping those three buttons you would get your first report instantly and all consequent reports every Sunday night (EST). The emails are all text, but the key points are highlighted to get your attention and the entire thing consists of <strong>algorithmic interpretations that can help you drive your decisions much better than any fancy graph\\xa0could.</strong></p><p>Although it’s a part of a larger suite of tools available with full Archie.AI membership we decided to make it 100% free, leaving the choice up to you on whether you want to upgrade or\\xa0not.</p><p>This is a fairly new product and we’re constantly looking for your feedback. If you’ve got some advice, criticism or ideas\\u200a—\\u200aplease don’t hesitate to let us know. In any case, follow <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">this link</a> to try it\\xa0out.</p><h3>🍻</h3><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b456bb5eec7\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/an-easier-way-to-get-google-analytics-email-reports-b456bb5eec7\">An easier way to get Google Analytics email reports</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>'}],\n",
       " 'bozo': 0,\n",
       " 'encoding': 'utf-8',\n",
       " 'version': 'rss20',\n",
       " 'namespaces': {'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  'content': 'http://purl.org/rss/1.0/modules/content/',\n",
       "  '': 'http://www.w3.org/2005/Atom',\n",
       "  'cc': 'http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archie_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got everything processed for the `ai_trends` collection (which was in *RSS* format), now we'll need to do the same thing for the `archie_ai` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archie.AI - Medium\n",
      "ML &amp; Tech Articles from the team behind Archie.AI - Medium\n",
      "Sat, 19 Oct 2019 22:54:51 GMT\n"
     ]
    }
   ],
   "source": [
    "print(archie_ai['feed']['title'])\n",
    "print(archie_ai['feed']['subtitle'])\n",
    "print(archie_ai['feed']['updated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good...\n",
    "\n",
    "> I am not nearly as cofident in `archie_ai` as I was in the `ai_trends`, so we're taking babysteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTag: ethereum\n",
      "\tTag: bitcoin\n",
      "\tTag: investing\n",
      "\tTag: cryptocurrency\n",
      "How Much Money Do You Need to Move the Bitcoin Market?\n",
      "Thu, 12 Jul 2018 03:46:18 GMT\n",
      "Ishtiaq Rahman\n",
      "<h4>Whale Science 🐋</h4><p>I did a quick estimation to figure out what kind of investment you’d need to be able to move the Bitcoin market in the short term, in a particular direction.</p><p>I looked at Gdax trading data which handled about 2.98% of all BTC trading volume on February 26th, 2018.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZNfAigHdJMdvAk1J6T-1kQ.png\" /><figcaption>Source: Coinmarkercap.com</figcaption></figure><p>On February 26, between 11: 54 PM PST and 11:55 PM PST, the total volume traded on Gdax was 65 Bitcoins which was worth around $686,440 USD at the time. This resulted in a .557% increase in the price of Bitcoin.</p><p>I picked this particular minute for my example because it had visibly higher trading volume compared to the minutes before it.(See image below).</p><p>We can now estimate that the total volume of Bitcoins traded in ALL markets during that 1-minute was about 2181 Bitcoins (~23 million USD worth) from the fact 65 Bitcoins traded on Gdax represented 2.98% of all Bitcoin trade volume in the world.</p><p>The actual total volume should be lower since it is unlikely that all markets are completely efficient and received the same magnitude of above average volume like Gdax did during that 1-minute in question — But we will continue with this estimation for simplicity.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aRn7JH5cccHoXBThSvBJ2Q.jpeg\" /><figcaption>Data Source: Gdax.com</figcaption></figure><p>This means that during that 1-minute, $23 million USD worth of bullish trades increased total market value of Bitcoin by over $1 billion USD (.557% of $180.77 billion total value of all Bitcoins)</p><p>Crudely put — It is possible for someone with access to $23 million USD to pump the price up by .557% in one minute.</p><h3><strong>What About Ethereum?</strong></h3><p>I did the same calculation for Ethereum for that exact same minute — between 11: 54 PM PST and 11:55 PM PST on February 26th, 2018.</p><p>Total volume traded on Gdax during that one minute was 120 ETH and resulted in a .41% increase in the price of Ethereum.</p><p>Gdax represented 2.97% of all ETH trades which puts the total estimated trade volume during that minute at 4040 ETH which was worth around $3.57 million USD at the time.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pqsAybAJixL0W4CZ3ybt7A.jpeg\" /><figcaption>Data Source: Gdax.com</figcaption></figure><p>Therefore, we can estimate that a $3.57 million USD worth of bullish trades in Ethereum resulted in an increase of $363 million to the total market value of all ETH(.42% of $86.44 billion USD, total market value of Ethereum)</p><h3>WHAT DOES IT ALL MEAN?</h3><ol><li>A lot more extensive analysis is required before any conclusion can be drawn from this. In future, I’d like to look at different time cycles besides one minute and include a lot more data than just the one minute I picked on a random day to do my calculations. However, this simplified calculation does give us some idea about the sensitivity of the market.</li><li>It would also be interesting to look at how this “whale-effect” has changed over time.</li><li>I assume it was much cheaper to move the market when Bitcoin had a substantially smaller number of hodlers. I also do not doubt that it will get progressively more and more expensive to be able to move price.</li><li>This may sound counter-intuitive but Bitcoin needs a lot more whales and deep pockets. It is relatively easier and cheaper for a whale to influence the market if there are not enough other big players. But with a lot of whales in the market, a single whale no longer has the same influence. For reference: There are 2,043 billionaires worldwide (Forbes) and 35 million millionaires worldwide (Credit Suisse)</li><li>This is not meant to be a financial advice. Please invest responsibly.</li></ol><p>Note:</p><ul><li>Glad you stopped by. When I’m not staring at crypto prices, I am usually working on my AI/ML startup <a href=\"http://www.archie.ai\">Archie.AI — The Artificially Intelligent Data Scientist.</a> Do check it out if you’re interested in that sort of thing.</li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=202f4316f277\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/how-much-money-do-you-need-to-move-the-bitcoin-market-202f4316f277\">How Much Money Do You Need to Move the Bitcoin Market?</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4>Whale Science 🐋</h4><p>I did a quick estimation to figure out what kind of investment you’d need to be able to move the Bitcoin market in the short term, in a particular direction.</p><p>I looked at Gdax trading data which handled about 2.98% of all BTC trading volume on February 26th, 2018.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ZNfAigHdJMdvAk1J6T-1kQ.png\" /><figcaption>Source: Coinmarkercap.com</figcaption></figure><p>On February 26, between 11: 54 PM PST and 11:55 PM PST, the total volume traded on Gdax was 65 Bitcoins which was worth around $686,440 USD at the time. This resulted in a .557% increase in the price of Bitcoin.</p><p>I picked this particular minute for my example because it had visibly higher trading volume compared to the minutes before it.(See image below).</p><p>We can now estimate that the total volume of Bitcoins traded in ALL markets during that 1-minute was about 2181 Bitcoins (~23 million USD worth) from the fact 65 Bitcoins traded on Gdax represented 2.98% of all Bitcoin trade volume in the world.</p><p>The actual total volume should be lower since it is unlikely that all markets are completely efficient and received the same magnitude of above average volume like Gdax did during that 1-minute in question — But we will continue with this estimation for simplicity.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*aRn7JH5cccHoXBThSvBJ2Q.jpeg\" /><figcaption>Data Source: Gdax.com</figcaption></figure><p>This means that during that 1-minute, $23 million USD worth of bullish trades increased total market value of Bitcoin by over $1 billion USD (.557% of $180.77 billion total value of all Bitcoins)</p><p>Crudely put — It is possible for someone with access to $23 million USD to pump the price up by .557% in one minute.</p><h3><strong>What About Ethereum?</strong></h3><p>I did the same calculation for Ethereum for that exact same minute — between 11: 54 PM PST and 11:55 PM PST on February 26th, 2018.</p><p>Total volume traded on Gdax during that one minute was 120 ETH and resulted in a .41% increase in the price of Ethereum.</p><p>Gdax represented 2.97% of all ETH trades which puts the total estimated trade volume during that minute at 4040 ETH which was worth around $3.57 million USD at the time.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pqsAybAJixL0W4CZ3ybt7A.jpeg\" /><figcaption>Data Source: Gdax.com</figcaption></figure><p>Therefore, we can estimate that a $3.57 million USD worth of bullish trades in Ethereum resulted in an increase of $363 million to the total market value of all ETH(.42% of $86.44 billion USD, total market value of Ethereum)</p><h3>WHAT DOES IT ALL MEAN?</h3><ol><li>A lot more extensive analysis is required before any conclusion can be drawn from this. In future, I’d like to look at different time cycles besides one minute and include a lot more data than just the one minute I picked on a random day to do my calculations. However, this simplified calculation does give us some idea about the sensitivity of the market.</li><li>It would also be interesting to look at how this “whale-effect” has changed over time.</li><li>I assume it was much cheaper to move the market when Bitcoin had a substantially smaller number of hodlers. I also do not doubt that it will get progressively more and more expensive to be able to move price.</li><li>This may sound counter-intuitive but Bitcoin needs a lot more whales and deep pockets. It is relatively easier and cheaper for a whale to influence the market if there are not enough other big players. But with a lot of whales in the market, a single whale no longer has the same influence. For reference: There are 2,043 billionaires worldwide (Forbes) and 35 million millionaires worldwide (Credit Suisse)</li><li>This is not meant to be a financial advice. Please invest responsibly.</li></ol><p>Note:</p><ul><li>Glad you stopped by. When I’m not staring at crypto prices, I am usually working on my AI/ML startup <a href=\"http://www.archie.ai\">Archie.AI — The Artificially Intelligent Data Scientist.</a> Do check it out if you’re interested in that sort of thing.</li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=202f4316f277\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/how-much-money-do-you-need-to-move-the-bitcoin-market-202f4316f277\">How Much Money Do You Need to Move the Bitcoin Market?</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: blogging\n",
      "\tTag: web-development\n",
      "\tTag: google-analytics\n",
      "\tTag: personal-development\n",
      "\tTag: photography\n",
      "Why Data is Important for Small, Personal Web Projects​\n",
      "Mon, 11 Jun 2018 07:36:49 GMT\n",
      "Dmitri\n",
      "<h4>It’s about connecting with the fans, not creeping them out</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sMoHJ8PNMA2UgtlYlNaxfw.jpeg\" /></figure><p>To me, small, personal projects are always opportunities. Opportunities to learn, to be creative, and to be heard.</p><p>During the past five years, I’ve run and managed nearly a dozen web projects, with traffic ranging from tens to tens of thousands visitors each day. Naturally, larger websites have more at stake. They demand round-the-clock monitoring and weekly analysis. But <strong>analytics play a huge role in small, personal projects, too</strong>.</p><p>With less-frequently visited properties it’s a lot harder to derive statistically-significant conclusions. Data is noisy and takes a long time to collect. Acting on that data is also difficult. But this knowledge is <strong>valuable for understanding the people </strong>who take the time to watch, read, and react to your creative expressions.</p><p>A few years ago I was very much into making music. I performed live and distributed records online. Being an introvert I eventually gravitated towards hiding with my guitar in the bedroom and creating sounds in private. Still, I loved being on the stage, as there is no better way to be with people who happen to like you and/or your work.</p><p>Never the less, my public appearances have receded over time. Most of my creative work is now online (as <a href=\"https://www.analog.cafe/\">a film photography publication</a> and a community blogging platform). The people who happen to like it and consume regularly only manifest themselves as tiny spikes on the traffic curve reported by Google Analytics. Knowing this little about the audience creates a significant interaction void.</p><p>As there wasn’t much that I could do with my analytics I switched to Archie <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Reporting</a> product for casual weekly digests. Interestingly, a few months in I began to understand my audience a little better, or, at least, it felt like I did. I knew whether my work is getting more or less popular, where the visitors came from, whether the people are interacting with my content, and what pages, according to the bot, deserve my attention. All without having to obsess about the data via analytics dashboard.</p><p>My resulting understanding of the audience isn’t very scientific. But a rough overview of the crowd does draw a decent picture on seasonal and hourly popularity (like the busy months, or, what time of the day do people visit my site most often). Going beyond this kind of knowledge requires more traffic to come up with statistically significant answers. But <strong>the real advantage of being small is to be able to talk to people on a personal level and spend less time data mining (while still keeping track)</strong>.</p><p>Large businesses are spending a lot of money on advanced intelligence, which today is backfiring with harsher compliance requirements (like GDPR) and overall public mistrust. At the same time, small ventures have an advantage in the ability to use analytics reports as a rough gauge of performance and to focus on interacting with fans and customers, something we can do without having to scale.</p><p>On Twitter, I regularly engage in conversations, many of which are taken as invaluable feedback or messages of support. I spend my time at the places of gathering for the likeminded individuals, like film development labs and exhibition galleries. All of which have a much greater impact on the success of my small venture, defined by the size of the audience and their ability to appreciate my efforts.</p><p>To get to this balance between guestimation and science, automation and personal approach I had to try a lot of different techniques. In the end, for any website that receives less than 5K unique visitors per month this method is perhaps the best. No excessive tracking or obsessive analysis. Instead, a healthy presence online (outside of the publishing platform) and a strong reliance on physical/real-world connections.</p><p>With the casual data approach, I get to have meaningful, guided interactions with the community without having to spend time serving and dissecting non-existent crowds.</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/why-data-is-important-for-small-personal-web-projects\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=355cf0bba2fe\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/why-data-is-important-for-small-personal-web-projects-355cf0bba2fe\">Why Data is Important for Small, Personal Web Projects​</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4>It’s about connecting with the fans, not creeping them out</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sMoHJ8PNMA2UgtlYlNaxfw.jpeg\" /></figure><p>To me, small, personal projects are always opportunities. Opportunities to learn, to be creative, and to be heard.</p><p>During the past five years, I’ve run and managed nearly a dozen web projects, with traffic ranging from tens to tens of thousands visitors each day. Naturally, larger websites have more at stake. They demand round-the-clock monitoring and weekly analysis. But <strong>analytics play a huge role in small, personal projects, too</strong>.</p><p>With less-frequently visited properties it’s a lot harder to derive statistically-significant conclusions. Data is noisy and takes a long time to collect. Acting on that data is also difficult. But this knowledge is <strong>valuable for understanding the people </strong>who take the time to watch, read, and react to your creative expressions.</p><p>A few years ago I was very much into making music. I performed live and distributed records online. Being an introvert I eventually gravitated towards hiding with my guitar in the bedroom and creating sounds in private. Still, I loved being on the stage, as there is no better way to be with people who happen to like you and/or your work.</p><p>Never the less, my public appearances have receded over time. Most of my creative work is now online (as <a href=\"https://www.analog.cafe/\">a film photography publication</a> and a community blogging platform). The people who happen to like it and consume regularly only manifest themselves as tiny spikes on the traffic curve reported by Google Analytics. Knowing this little about the audience creates a significant interaction void.</p><p>As there wasn’t much that I could do with my analytics I switched to Archie <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Reporting</a> product for casual weekly digests. Interestingly, a few months in I began to understand my audience a little better, or, at least, it felt like I did. I knew whether my work is getting more or less popular, where the visitors came from, whether the people are interacting with my content, and what pages, according to the bot, deserve my attention. All without having to obsess about the data via analytics dashboard.</p><p>My resulting understanding of the audience isn’t very scientific. But a rough overview of the crowd does draw a decent picture on seasonal and hourly popularity (like the busy months, or, what time of the day do people visit my site most often). Going beyond this kind of knowledge requires more traffic to come up with statistically significant answers. But <strong>the real advantage of being small is to be able to talk to people on a personal level and spend less time data mining (while still keeping track)</strong>.</p><p>Large businesses are spending a lot of money on advanced intelligence, which today is backfiring with harsher compliance requirements (like GDPR) and overall public mistrust. At the same time, small ventures have an advantage in the ability to use analytics reports as a rough gauge of performance and to focus on interacting with fans and customers, something we can do without having to scale.</p><p>On Twitter, I regularly engage in conversations, many of which are taken as invaluable feedback or messages of support. I spend my time at the places of gathering for the likeminded individuals, like film development labs and exhibition galleries. All of which have a much greater impact on the success of my small venture, defined by the size of the audience and their ability to appreciate my efforts.</p><p>To get to this balance between guestimation and science, automation and personal approach I had to try a lot of different techniques. In the end, for any website that receives less than 5K unique visitors per month this method is perhaps the best. No excessive tracking or obsessive analysis. Instead, a healthy presence online (outside of the publishing platform) and a strong reliance on physical/real-world connections.</p><p>With the casual data approach, I get to have meaningful, guided interactions with the community without having to spend time serving and dissecting non-existent crowds.</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/why-data-is-important-for-small-personal-web-projects\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=355cf0bba2fe\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/why-data-is-important-for-small-personal-web-projects-355cf0bba2fe\">Why Data is Important for Small, Personal Web Projects​</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: programming\n",
      "\tTag: javascript\n",
      "\tTag: reactjs\n",
      "\tTag: react\n",
      "\tTag: refactoring\n",
      "Structuring React.js Web Applications​\n",
      "Sat, 05 May 2018 15:42:51 GMT\n",
      "Dmitri\n",
      "<h4><strong><em>A Better Naming and File Organization System</em></strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/1*FKdNcdYWDyafzIApir7dnQ.jpeg\" /></figure><p>The curse and the gift of React.js is the fact that it is not opinionated in terms of how you structure your components and files. Do what you want and it’ll work. But with every new project it’s a “blank slate” problem.</p><p>This article is written from a perspective of a person building (and finally refactoring) the front-end of a blogging platform designed for film photography enthusiasts. Besides listing and displaying articles, the app provides admin controls and a full rich text editorial suite, comprised of <strong>280 files and folders</strong>. The app in question is <a href=\"https://www.analog.cafe/\">Analog.Cafe</a>.</p><h3>Preface 1: “dumb” and “smart” components: not a good way to sort your files.</h3><pre>- app/<br>  - components/<br>  - containers/</pre><p>When I began working on my application, coming from an intensive year with Ruby on Rails builds for <a href=\"https://www.archie.ai/\">Archie.AI</a> (a fairly opinionated framework) I’ve hit the wall trying to figure out how to structure and name the numerous files with React. The most common advice at the time was to segregate the components into pure functions and stateful components.</p><p>The expectation with this method is that your components will inevitably get reused elsewhere. Although this may be true for many projects, I can’t see how it could be the case for all applications. Furthermore, ripping the functionality apart and placing the pieces of a component that performs the same function into separate corners of your filesystem is counter-productive and counter-intuitive.</p><p>With some experementation I’ve come up with a better system (below).</p><h3>Preface 2: styled-components, they aren’t CSS; they are components.</h3><p>​<a href=\"https://github.com/styled-components/styled-components\">styled-components</a> is my library of choice when it comes to baking CSS into React projects. It’s very good.</p><p>A common pattern of usage with it is to separate styles into styles.js, a reminiscent of the file structure we used to have with simpler hand-written HTML files not too long ago.</p><p>Turns out this is not a practically good idea. Namely, because this method creates a third type of component (in addition to above-mentioned smart and dumb). What’s worse, this type of component has a completely separate organizational method, which attempts to mimic conflicting paradigms.</p><p>I recommend treating styled-components just as what they are — React components.</p><h3>The Interface Pattern.</h3><p><em>The Interface Pattern</em> is a reminder that we are building a front-end application, which is easier to understand and structure when it’s thought of as a compilation of visual interface elements. This pattern consists of suggestions on <strong>file and folder structure, preferred export types, commenting practices, and file size recommendations</strong>.</p><h3>File and folder structure shape.</h3><pre>- app/<br>  - core/<br>  - admin/<br>  - user/<br>  - constants.js<br>  - index.js<br>  - store.js<br>  - utils.js</pre><p><strong><em>Note:</em></strong><em> you can browse the entire application structure for Analog.Cafe in </em><a href=\"http://github.com/dmitrizzle/Analog.Cafe\"><em>this repo</em></a><em>.</em></p><p>My application is divided into three major <strong>sections</strong>: core/ admin/ and user/. In your case, you may not have any sections if the app isn’t big enough. Then you can structure your app/ folder just like the contents of the above sections (see below).</p><p>The four JavaScript files above should be self-explanatory, but with a few caveats. In this example they serve as index files, where they store only the most basic and commonly-used exports: index.js contains the main wrapper React component for the app, store.js<em> </em>combines the reducers found inside the above three application sections and exports a Redux store, while utils.js and constants.js contain the most common JavaScripit function snippets and reusable constants.</p><pre>- core/<br>  - components/<br>  - constants/<br>  - store/<br>  - utils/</pre><p>Inside each of the application sections are four folders which resemble the shape of the app/ directory. The only difference is that this shape forces you to create more files in your utils/and constants/folders which is <a href=\"https://github.com/airbnb/javascript/issues/1365\">better</a> for the organization and should make tree-shaking work better too.</p><p>If you are not splitting your app into <strong>sections</strong> the above folders could be placed inside your app/ folder, instead of core/.</p><pre>- constants/<br>  - messages-.js<br>  - messages-article.js<br>  - routes-article.js<br>  - rules-submission.js<br>- utils/<br>  - actions-session.js<br>  - messages-profile.js</pre><p>Both constants/and utils/ folders have similar file-naming patterns. The first keyword is either messages, routes, rules, or actions. Followed by a dash and a keyword describing a specific part of your application view. I understand that this is not the most foolproof naming convention, however, you may be able to understand it much better in practice. The main objectives should be <strong>consistency and clarity</strong>.</p><p>Note the file named <em>messages-.js</em> which contains strings and objects designated as user-facing messages, not assigned to any specific part of the application view.</p><pre>- store/<br>  - actions-article.js<br>  - actions-submission.js<br>  - reducers-article.js<br>  - reducers-submission.js</pre><p>The store/ folder is for Redux. It contains pairs of files (actions- and reducers-) for each part of your application view. Simple; all in one place.</p><pre>- components/<br>  - controls/<br>  - icons/<br>  - pages/<br>  - routes/<br>  - forms/<br>  - vignettes/</pre><p>components/ folder: I found the above six types of components to be fairly inclusive way to organize an application. It’s required to have such sub-folders to quickly find what you are looking for and understand application structure. Otherwise you may be stuck with hundreds of folders in this part of your app. This is how I distinguish them:</p><p><strong><em>controls/</em> — </strong>Buttons &amp; button arrays, modal boxes, links, nav bars, menus, etc.</p><p><strong><em>icons/</em></strong> — Graphic elements made with React and meant to stay as part of an app, such as integral SVGs or CSSs.</p><p><strong>pages/</strong> — Components that are meant to take over a whole or a meaningful part of a screen space.</p><p><strong><em>routes/</em></strong> — This folder is specifically for React Router route components.</p><p><strong>forms/</strong> — Input elements.</p><p><strong>vignettes/</strong> — Smaller components that do not belong anywhere else.</p><pre>- controls/<br>  - Card/<br>    - index.js<br>    - components/<br>      - CardFigure.js<br>      - CardHeader.js</pre><p>Each of the component folders would have names written in CamelCase, with an optional index.js at their root, which would tie everything together. If necessary, components/ folder could be placed inside, which can contain styled-components or React.js components which would directly help compose the main component (in this case, <em>Card/ </em>component).</p><p><strong><em>Note 1:</em></strong><em> There is no distinction or rule here between “smart” and “dumb” components, but the “smart” components naturally tend to end up at the root of the main component in index.js — which you could use to your advantage.</em></p><p><strong><em>Note 2:</em></strong><em> There is nothing preventing you importing from files located in other application sections; a lot of the time it’s required and there’s nothing wrong with that. Feel free to require </em><em>admin/ utils in your </em><em>core/ components.</em></p><p><strong><em>Note 3:</em></strong><em> You may have noticed that sub-components do not have their own folders. That makes for easier readability and better folder structure. They could, of course, be placed in their own folders if they in-turn have their own sub-components, but that would be messy. Try to keep your file tree as flat as possible.</em></p><h3>Preferred export types.</h3><p>A simple rule is to <strong>prefer named exports</strong> like export const function Name ()=&gt;{} in constants/<em> </em>utils/ and store/ — this will encourage you to balance the number of files in those folders nicely.</p><p>However, all components should strive to export<strong> only default exports</strong> with some exceptions where they could contain both default and named exports in very small files. This simple rule will force you to create more components (which are by the way a lot easier to name than more rigidly-structured <em>constants</em> and <em>utils</em> files), which in turn will create a number of benefits in terms of the final bundle size and app readability (fewer lines of code per file).</p><h3>File size recommendations.</h3><p>No more than 300 lines per file. Anything bigger than that warrants splitting it.</p><h3>Commenting practices.</h3><p>I used to think that more comments in the code is better. Until I learned otherwise. Plentiful comments could be useful when creating a tutorial, however, they tend to pollute application files and encourage bad variable naming practices. So if the code feels difficult to understand, it should be reviewed and corrected for a more comprehensible namings and style. Use tools like <a href=\"https://github.com/prettier/prettier\">Prettier</a> to your advantage.</p><p>Write readable code instead of something that you needs a manual.</p><p>It may seem like there’s a lot to deal with, but in practice, it could be easily achieved and understood by the whole team. Have a look at <a href=\"http://github.com/dmitrizzle/Analog.Cafe\">the repo</a> that already uses this method to get yourself acquainted. Refer back to this text to get the details and the reasoning behind each choice.</p><p>As you may have noticed I haven’t mentioned anything about where to place tests. This method also hasn’t been tried in a great diversity of production systems so there may be some things I missed or got wrong. In those cases, you may have to adapt, and if you got time please let me know so that I could make this guide better.</p><p>🍻</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/structuring-react-applications\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=11271643e941\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/structuring-react-js-web-applications-11271643e941\">Structuring React.js Web Applications​</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4><strong><em>A Better Naming and File Organization System</em></strong></h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/proxy/1*FKdNcdYWDyafzIApir7dnQ.jpeg\" /></figure><p>The curse and the gift of React.js is the fact that it is not opinionated in terms of how you structure your components and files. Do what you want and it’ll work. But with every new project it’s a “blank slate” problem.</p><p>This article is written from a perspective of a person building (and finally refactoring) the front-end of a blogging platform designed for film photography enthusiasts. Besides listing and displaying articles, the app provides admin controls and a full rich text editorial suite, comprised of <strong>280 files and folders</strong>. The app in question is <a href=\"https://www.analog.cafe/\">Analog.Cafe</a>.</p><h3>Preface 1: “dumb” and “smart” components: not a good way to sort your files.</h3><pre>- app/<br>  - components/<br>  - containers/</pre><p>When I began working on my application, coming from an intensive year with Ruby on Rails builds for <a href=\"https://www.archie.ai/\">Archie.AI</a> (a fairly opinionated framework) I’ve hit the wall trying to figure out how to structure and name the numerous files with React. The most common advice at the time was to segregate the components into pure functions and stateful components.</p><p>The expectation with this method is that your components will inevitably get reused elsewhere. Although this may be true for many projects, I can’t see how it could be the case for all applications. Furthermore, ripping the functionality apart and placing the pieces of a component that performs the same function into separate corners of your filesystem is counter-productive and counter-intuitive.</p><p>With some experementation I’ve come up with a better system (below).</p><h3>Preface 2: styled-components, they aren’t CSS; they are components.</h3><p>​<a href=\"https://github.com/styled-components/styled-components\">styled-components</a> is my library of choice when it comes to baking CSS into React projects. It’s very good.</p><p>A common pattern of usage with it is to separate styles into styles.js, a reminiscent of the file structure we used to have with simpler hand-written HTML files not too long ago.</p><p>Turns out this is not a practically good idea. Namely, because this method creates a third type of component (in addition to above-mentioned smart and dumb). What’s worse, this type of component has a completely separate organizational method, which attempts to mimic conflicting paradigms.</p><p>I recommend treating styled-components just as what they are — React components.</p><h3>The Interface Pattern.</h3><p><em>The Interface Pattern</em> is a reminder that we are building a front-end application, which is easier to understand and structure when it’s thought of as a compilation of visual interface elements. This pattern consists of suggestions on <strong>file and folder structure, preferred export types, commenting practices, and file size recommendations</strong>.</p><h3>File and folder structure shape.</h3><pre>- app/<br>  - core/<br>  - admin/<br>  - user/<br>  - constants.js<br>  - index.js<br>  - store.js<br>  - utils.js</pre><p><strong><em>Note:</em></strong><em> you can browse the entire application structure for Analog.Cafe in </em><a href=\"http://github.com/dmitrizzle/Analog.Cafe\"><em>this repo</em></a><em>.</em></p><p>My application is divided into three major <strong>sections</strong>: core/ admin/ and user/. In your case, you may not have any sections if the app isn’t big enough. Then you can structure your app/ folder just like the contents of the above sections (see below).</p><p>The four JavaScript files above should be self-explanatory, but with a few caveats. In this example they serve as index files, where they store only the most basic and commonly-used exports: index.js contains the main wrapper React component for the app, store.js<em> </em>combines the reducers found inside the above three application sections and exports a Redux store, while utils.js and constants.js contain the most common JavaScripit function snippets and reusable constants.</p><pre>- core/<br>  - components/<br>  - constants/<br>  - store/<br>  - utils/</pre><p>Inside each of the application sections are four folders which resemble the shape of the app/ directory. The only difference is that this shape forces you to create more files in your utils/and constants/folders which is <a href=\"https://github.com/airbnb/javascript/issues/1365\">better</a> for the organization and should make tree-shaking work better too.</p><p>If you are not splitting your app into <strong>sections</strong> the above folders could be placed inside your app/ folder, instead of core/.</p><pre>- constants/<br>  - messages-.js<br>  - messages-article.js<br>  - routes-article.js<br>  - rules-submission.js<br>- utils/<br>  - actions-session.js<br>  - messages-profile.js</pre><p>Both constants/and utils/ folders have similar file-naming patterns. The first keyword is either messages, routes, rules, or actions. Followed by a dash and a keyword describing a specific part of your application view. I understand that this is not the most foolproof naming convention, however, you may be able to understand it much better in practice. The main objectives should be <strong>consistency and clarity</strong>.</p><p>Note the file named <em>messages-.js</em> which contains strings and objects designated as user-facing messages, not assigned to any specific part of the application view.</p><pre>- store/<br>  - actions-article.js<br>  - actions-submission.js<br>  - reducers-article.js<br>  - reducers-submission.js</pre><p>The store/ folder is for Redux. It contains pairs of files (actions- and reducers-) for each part of your application view. Simple; all in one place.</p><pre>- components/<br>  - controls/<br>  - icons/<br>  - pages/<br>  - routes/<br>  - forms/<br>  - vignettes/</pre><p>components/ folder: I found the above six types of components to be fairly inclusive way to organize an application. It’s required to have such sub-folders to quickly find what you are looking for and understand application structure. Otherwise you may be stuck with hundreds of folders in this part of your app. This is how I distinguish them:</p><p><strong><em>controls/</em> — </strong>Buttons &amp; button arrays, modal boxes, links, nav bars, menus, etc.</p><p><strong><em>icons/</em></strong> — Graphic elements made with React and meant to stay as part of an app, such as integral SVGs or CSSs.</p><p><strong>pages/</strong> — Components that are meant to take over a whole or a meaningful part of a screen space.</p><p><strong><em>routes/</em></strong> — This folder is specifically for React Router route components.</p><p><strong>forms/</strong> — Input elements.</p><p><strong>vignettes/</strong> — Smaller components that do not belong anywhere else.</p><pre>- controls/<br>  - Card/<br>    - index.js<br>    - components/<br>      - CardFigure.js<br>      - CardHeader.js</pre><p>Each of the component folders would have names written in CamelCase, with an optional index.js at their root, which would tie everything together. If necessary, components/ folder could be placed inside, which can contain styled-components or React.js components which would directly help compose the main component (in this case, <em>Card/ </em>component).</p><p><strong><em>Note 1:</em></strong><em> There is no distinction or rule here between “smart” and “dumb” components, but the “smart” components naturally tend to end up at the root of the main component in index.js — which you could use to your advantage.</em></p><p><strong><em>Note 2:</em></strong><em> There is nothing preventing you importing from files located in other application sections; a lot of the time it’s required and there’s nothing wrong with that. Feel free to require </em><em>admin/ utils in your </em><em>core/ components.</em></p><p><strong><em>Note 3:</em></strong><em> You may have noticed that sub-components do not have their own folders. That makes for easier readability and better folder structure. They could, of course, be placed in their own folders if they in-turn have their own sub-components, but that would be messy. Try to keep your file tree as flat as possible.</em></p><h3>Preferred export types.</h3><p>A simple rule is to <strong>prefer named exports</strong> like export const function Name ()=&gt;{} in constants/<em> </em>utils/ and store/ — this will encourage you to balance the number of files in those folders nicely.</p><p>However, all components should strive to export<strong> only default exports</strong> with some exceptions where they could contain both default and named exports in very small files. This simple rule will force you to create more components (which are by the way a lot easier to name than more rigidly-structured <em>constants</em> and <em>utils</em> files), which in turn will create a number of benefits in terms of the final bundle size and app readability (fewer lines of code per file).</p><h3>File size recommendations.</h3><p>No more than 300 lines per file. Anything bigger than that warrants splitting it.</p><h3>Commenting practices.</h3><p>I used to think that more comments in the code is better. Until I learned otherwise. Plentiful comments could be useful when creating a tutorial, however, they tend to pollute application files and encourage bad variable naming practices. So if the code feels difficult to understand, it should be reviewed and corrected for a more comprehensible namings and style. Use tools like <a href=\"https://github.com/prettier/prettier\">Prettier</a> to your advantage.</p><p>Write readable code instead of something that you needs a manual.</p><p>It may seem like there’s a lot to deal with, but in practice, it could be easily achieved and understood by the whole team. Have a look at <a href=\"http://github.com/dmitrizzle/Analog.Cafe\">the repo</a> that already uses this method to get yourself acquainted. Refer back to this text to get the details and the reasoning behind each choice.</p><p>As you may have noticed I haven’t mentioned anything about where to place tests. This method also hasn’t been tried in a great diversity of production systems so there may be some things I missed or got wrong. In those cases, you may have to adapt, and if you got time please let me know so that I could make this guide better.</p><p>🍻</p><p><em>Originally published at </em><a href=\"https://www.archie.ai/blog/structuring-react-applications\"><em>www.archie.ai</em></a><em>.</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=11271643e941\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/structuring-react-js-web-applications-11271643e941\">Structuring React.js Web Applications​</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: machine-learning\n",
      "\tTag: artificial-intelligence\n",
      "\tTag: data-science\n",
      "\tTag: startup\n",
      "\tTag: healthcare\n",
      "Stop Sitting On All That Data & Do Something With It ⚙️\n",
      "Tue, 06 Feb 2018 05:34:21 GMT\n",
      "Ishtiaq Rahman\n",
      "<h4>Please, feed your data to the machines.</h4><p>Artificial intelligence is taking the demand for data to a new level. 📈</p><p>Let’s say you have access to 5,000 X-ray images of patients who were correctly diagnosed with a particular type of cancer — Type A.</p><p>Today, it is surprisingly easy to use this data to train a bot to detect this cancer in new patients.</p><p>To build this bot, you’d build an image classifier powered by a neural net and the 5,000 X-ray images would be your training data set.</p><p>You’d add another 5,000 X-rays of patients without cancer so the classifier has examples of both healthy and affected X-rays.</p><p>In essence, this image classifier bot would look for common patterns at pixel level using image gradients and correlate that pattern to Type-A cancer using a widely used machine learning algorithm called back-propagation.</p><p>Note that YOU don’t have to specify the patterns at the pixel level to the bot for it to detect the cancer. That would be a highly inefficient process and possibly inaccurate as well.</p><p>Instead, in our deep learning model, the bot looks for the patterns itself. It painstakingly evaluates small grids of pixels of an image with the cancer and compares it to the corresponding grid in ALL the other images to find the patterns that exist. For further reading, you can check out concepts like <a href=\"https://en.wikipedia.org/wiki/Kernel_(image_processing)\">kernel convolutions </a>or how bots are <a href=\"https://www.kaggle.com/competitions\">detecting various object in Kaggle competitions</a>.</p><p>If you want to dive deeper into the tech, you can read my essay “<a href=\"https://medium.com/archieai/learning-at-scale-the-end-of-if-then-logic-bd3a4e292222\">Learning at Scale &amp; The End of ‘If-Then’ Logic</a>”.</p><p>The point is, using currently available open-source/SaaS deep learning platforms, a bit of motivation and access to the right data set, one could set this bot up in no time.</p><p>Once trained, if you input a new patient’s X-ray, the classifier would be able to say things like “There’s a 98% chance that this is a Type A Cancer”.</p><p>If you’ve been through a cancer diagnosis process of a loved one, you know how important it is to be certain. That’s why people get the second, the third and the fourth opinion from different doctors.</p><p>Using this bot, every patient can be more confident about a diagnosis, a lot faster.</p><p>The best part is that if you continue to add more X-ray images of correctly diagnosed Type A cancer, the bot will continue to get better at detecting it.</p><p><strong>As machine learning techniques become more mainstream, a lot more value will be placed on data because machines can learn from it to do our jobs better than us.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/898/0*D7foQzC-k8VBUWpB.png\" /><figcaption>Identifying cats or malignant cancer, it’s all the same for the bot as long as you have training data. Photo: Deep Learning visualized by mapr.com</figcaption></figure><p>This above use-case isn’t science fiction.</p><p>At John Radcliffe Hospital, a team of <a href=\"http://www.ultromics.com/\">researchers from Oxford University</a> are using electrocardiogram images (Eco test) of the heart to detect heart diseases. The system is called <a href=\"http://www.ultromics.com\">Ultromics</a> and it consistently performs better than human cardiologists. The team has access to Oxford University’s heart imaging database and they are training their machine learning algorithms with these images to detect various heart diseases.</p><p>Google’s DeepMind is using a similar system to train an AI to detect eye disease by looking at thousands of retina scans at <a href=\"https://www.thenational.ae/world/europe/google-s-deepmind-training-ai-to-diagnose-eye-disease-1.702022\">London’s Moorfields Eye Hospital.</a></p><p>In a double blind study, <a href=\"https://www.ibm.com/watson/health/oncology-and-genomics\">IBM Watson for Oncology’s</a> breast cancer treatment recommendations was 90% concordance with the recommendation of a tumor board consisting of multi-disciplinary doctors and practitioners. Here, the training data comes from medical records of past patients, medical journal and books.</p><p>Needless to say, AI/ML use-cases are not limited to healthcare but they show us how valuable data is to solve real problems.</p><p>Most organizations/businesses/governments are sitting on top of literal goldmines of data that could be made into powerful AI products.</p><p>Unfortunately, not enough is being done. Not fast enough.</p><p>Data is a source of great power. And with great power comes great responsibility.*</p><p>So if you’ve got access to valuable data, you better be building something useful with it.</p><p><strong>Note:</strong></p><p>🤖If you’re interested in learning more about my work with AI/ML, check out my startup <a href=\"http://www.archie.ai\">Archie.AI</a>- The Artificially Intelligent Data Scientist.</p><p>🤖If you’re interested in building machine learning models, check out our workshops on <a href=\"https://www.youtube.com/channel/UCkm-zUm8tAfyDIRoOVqNZ_Q/videos\">YouTube.</a></p><p>🤖Want me to help you build your AI/ML project? Email me: i@eurekaking.com</p><p>Additional recommended essays on machine learning/artificial intelligence from team Archie.AI</p><h4>👉<a href=\"https://medium.com/archieai/a-dozen-times-artificial-intelligence-startled-the-world-eae5005153db\">A Dozen Times Artificial Intelligence Startled The World.</a></h4><h4>👉<a href=\"https://medium.com/archieai/the-power-of-natural-language-processing-f1ab0aa7d8c4\">The Power of Natural Language Processing.</a></h4><h4>👉<a href=\"https://medium.com/archieai/artificially-intelligent-engineers-how-ai-will-kill-all-engineering-jobs-3fd6dac55a06\">Artificially Intelligent Engineers — How AI Will Kill All Engineering Jobs. <em>And Why It Is a Good Thing.</em></a></h4><p><em>*Spiderman, David Lapham</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ee9c966ace27\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/stop-sitting-on-all-that-data-do-something-with-it-ee9c966ace27\">Stop Sitting On All That Data &amp; Do Something With It ⚙️</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4>Please, feed your data to the machines.</h4><p>Artificial intelligence is taking the demand for data to a new level. 📈</p><p>Let’s say you have access to 5,000 X-ray images of patients who were correctly diagnosed with a particular type of cancer — Type A.</p><p>Today, it is surprisingly easy to use this data to train a bot to detect this cancer in new patients.</p><p>To build this bot, you’d build an image classifier powered by a neural net and the 5,000 X-ray images would be your training data set.</p><p>You’d add another 5,000 X-rays of patients without cancer so the classifier has examples of both healthy and affected X-rays.</p><p>In essence, this image classifier bot would look for common patterns at pixel level using image gradients and correlate that pattern to Type-A cancer using a widely used machine learning algorithm called back-propagation.</p><p>Note that YOU don’t have to specify the patterns at the pixel level to the bot for it to detect the cancer. That would be a highly inefficient process and possibly inaccurate as well.</p><p>Instead, in our deep learning model, the bot looks for the patterns itself. It painstakingly evaluates small grids of pixels of an image with the cancer and compares it to the corresponding grid in ALL the other images to find the patterns that exist. For further reading, you can check out concepts like <a href=\"https://en.wikipedia.org/wiki/Kernel_(image_processing)\">kernel convolutions </a>or how bots are <a href=\"https://www.kaggle.com/competitions\">detecting various object in Kaggle competitions</a>.</p><p>If you want to dive deeper into the tech, you can read my essay “<a href=\"https://medium.com/archieai/learning-at-scale-the-end-of-if-then-logic-bd3a4e292222\">Learning at Scale &amp; The End of ‘If-Then’ Logic</a>”.</p><p>The point is, using currently available open-source/SaaS deep learning platforms, a bit of motivation and access to the right data set, one could set this bot up in no time.</p><p>Once trained, if you input a new patient’s X-ray, the classifier would be able to say things like “There’s a 98% chance that this is a Type A Cancer”.</p><p>If you’ve been through a cancer diagnosis process of a loved one, you know how important it is to be certain. That’s why people get the second, the third and the fourth opinion from different doctors.</p><p>Using this bot, every patient can be more confident about a diagnosis, a lot faster.</p><p>The best part is that if you continue to add more X-ray images of correctly diagnosed Type A cancer, the bot will continue to get better at detecting it.</p><p><strong>As machine learning techniques become more mainstream, a lot more value will be placed on data because machines can learn from it to do our jobs better than us.</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/898/0*D7foQzC-k8VBUWpB.png\" /><figcaption>Identifying cats or malignant cancer, it’s all the same for the bot as long as you have training data. Photo: Deep Learning visualized by mapr.com</figcaption></figure><p>This above use-case isn’t science fiction.</p><p>At John Radcliffe Hospital, a team of <a href=\"http://www.ultromics.com/\">researchers from Oxford University</a> are using electrocardiogram images (Eco test) of the heart to detect heart diseases. The system is called <a href=\"http://www.ultromics.com\">Ultromics</a> and it consistently performs better than human cardiologists. The team has access to Oxford University’s heart imaging database and they are training their machine learning algorithms with these images to detect various heart diseases.</p><p>Google’s DeepMind is using a similar system to train an AI to detect eye disease by looking at thousands of retina scans at <a href=\"https://www.thenational.ae/world/europe/google-s-deepmind-training-ai-to-diagnose-eye-disease-1.702022\">London’s Moorfields Eye Hospital.</a></p><p>In a double blind study, <a href=\"https://www.ibm.com/watson/health/oncology-and-genomics\">IBM Watson for Oncology’s</a> breast cancer treatment recommendations was 90% concordance with the recommendation of a tumor board consisting of multi-disciplinary doctors and practitioners. Here, the training data comes from medical records of past patients, medical journal and books.</p><p>Needless to say, AI/ML use-cases are not limited to healthcare but they show us how valuable data is to solve real problems.</p><p>Most organizations/businesses/governments are sitting on top of literal goldmines of data that could be made into powerful AI products.</p><p>Unfortunately, not enough is being done. Not fast enough.</p><p>Data is a source of great power. And with great power comes great responsibility.*</p><p>So if you’ve got access to valuable data, you better be building something useful with it.</p><p><strong>Note:</strong></p><p>🤖If you’re interested in learning more about my work with AI/ML, check out my startup <a href=\"http://www.archie.ai\">Archie.AI</a>- The Artificially Intelligent Data Scientist.</p><p>🤖If you’re interested in building machine learning models, check out our workshops on <a href=\"https://www.youtube.com/channel/UCkm-zUm8tAfyDIRoOVqNZ_Q/videos\">YouTube.</a></p><p>🤖Want me to help you build your AI/ML project? Email me: i@eurekaking.com</p><p>Additional recommended essays on machine learning/artificial intelligence from team Archie.AI</p><h4>👉<a href=\"https://medium.com/archieai/a-dozen-times-artificial-intelligence-startled-the-world-eae5005153db\">A Dozen Times Artificial Intelligence Startled The World.</a></h4><h4>👉<a href=\"https://medium.com/archieai/the-power-of-natural-language-processing-f1ab0aa7d8c4\">The Power of Natural Language Processing.</a></h4><h4>👉<a href=\"https://medium.com/archieai/artificially-intelligent-engineers-how-ai-will-kill-all-engineering-jobs-3fd6dac55a06\">Artificially Intelligent Engineers — How AI Will Kill All Engineering Jobs. <em>And Why It Is a Good Thing.</em></a></h4><p><em>*Spiderman, David Lapham</em></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ee9c966ace27\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/stop-sitting-on-all-that-data-do-something-with-it-ee9c966ace27\">Stop Sitting On All That Data &amp; Do Something With It ⚙️</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: open-source\n",
      "\tTag: ui\n",
      "\tTag: javascript\n",
      "\tTag: web-development\n",
      "\tTag: bots\n",
      "Storing & recalling bot interactions☝️\n",
      "Mon, 05 Feb 2018 00:03:04 GMT\n",
      "Dmitri\n",
      "<h4>Enhancing JavaScript bot UI with localStorage</h4><p>Bot interfaces are fun for the users and advantageous for those who build them (if done right). The concept isn’t new, though today it’s especially powerful.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/525/1*svec126KHXrwAVO2ut0XPw.gif\" /><figcaption>An implementation of a JavaScript <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">bot library</a> with localStorage in-place to memorize previous interactions. Notice the greyed-out text. This screenshot is of a production release of<a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\"> Archie.AI Google Chrome app</a>.</figcaption></figure><p>For developers, bots mean less time spent designing and building custom interfaces. It’s just text bubbles; plus many existing platforms offer to completely avoid this process with their already-successful apps’ APIs (i.e. Google Assistant).</p><p>For users, bots mean a possibility of hands-free interaction (via voice) and a more natural and/or seamless way to converse with machines.</p><h3>A simple solution.</h3><p>When I build things I tend to look for simple solutions, sans bloat, which could be easily understood and customized. Unfortunately, when I was looking for one last year there were none for my use case…</p><p>My team and I have implemented and trained a natural language classification engine, <a href=\"https://www.archie.ai\"><em>Archie.AI</em></a>, and gave it the power to understand and generate answers from Google Analytics. The bot can give daily briefings about users’ state of business, predict the number of future visitors and answer over <a href=\"https://www.archie.ai/ask-me\">430 related questions</a>. It’s an excellent way to save time when looking for a particular metric or an instant business advice.</p><p>It works wonderfully with Google Assistant and Alexa, however, when the time came to get a fast, clean interface for the web, there were no good-enough options. So I built one and kept it open-source. <a href=\"https://www.archie.ai/open-source\">chat-bubble</a> is the one-kilobyte JavaScript file with no dependencies that’s really easy to implement and understand:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;<br>);<br>chatWindow.talk({<br>  &quot;ice&quot;: { &quot;says&quot; : [ &quot;Hello!&quot; ] }<br>});</pre><pre>// <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples</a></pre><p><strong>Batteries included:</strong> a complete set of CSS styles and percision-timed animations, an ability to safely run functions in response to user actions, and a <em>pluggable processing engine</em>.</p><p>By “pluggable processing engine” I mean that the script is not going to tell you how to understand your user’s queries. It’s <em>up to you</em> to implement your own NLC. It’s <em>up to you</em> to either dynamically generate or write response scripts. However, it doesn’t leave you hanging. There are currently three ways to have it respond to your users:</p><ol><li>Give your users options, which appear as buttons (see gif below). Nothing needs to be done here, this is built-in.</li><li>Use the provided sample code that utilizes a simple fuzzy-matching logic to map your users’ input to the options you prescribe (see gif below).</li><li>Plug-in your own NLC engine (see gif above).</li></ol><p>Those options are for recognizing user input. The output (what the bot says) is just as customizable. It could be as simple as a structured JavaScript object variable. Or it could be dynamically imported JSON data. Of course, it doesn’t have to be just one huge JSON file — that would be inefficient! In our case (again, see gif above), we broke it up into individual answers for the responses that require a trip to the server (on-demand) and some calculations on our end.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/410/1*9sMLEpk7ZVFv-H6RPsCSow.gif\" /><figcaption>Bot library example with built-in button controls and input keyboard with fuzzy-match logic implemented. The JSON script that prescribes this conversation structure is below:</figcaption></figure><pre>// a simple conversation script written with JSON</pre><pre>var conversationScript = {<br>  ice: {<br>    says: [&quot;Hi&quot;, &quot;Would you like banana or ice cream?&quot;],<br>    reply: [<br>      {<br>        question: &quot;Banana&quot;,<br>        answer: &quot;banana&quot;<br>      },<br>      {<br>        question: &quot;Ice Cream&quot;,<br>        answer: &quot;ice-cream&quot;<br>      }<br>    ]<br>  },<br>  banana: {<br>    says: [&quot;🍌&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  },<br>  &quot;ice-cream&quot;: {<br>    says: [&quot;🍦&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  }<br>}</pre><h3>Local memory.</h3><p>Over the next few months, we tested the script in production with about a thousand users, while adding a few tweaks and improving performance on older browsers. It has also been downloaded over 700 times as of today.</p><p>The library works equally well on desktop and mobile. However, when it came time to publish it as a part of our Google Chrome browser extension user experience suffered. Because chat-bubble had no inherit persistence, the conversation history would evaporate every time the plugin window is closed. And that happened quite often as Chrome tends to kill the DOM of the plugins entirely each time the user shifts focus.</p><p>That has to be fixed.</p><p>There is no one way to keep the conversation history in on disk. I considered using Redux to manage the state, however, that’s a dependency and the philosophy so far is not to have one. That would also over-complicate things.</p><p>Instead, I decided to store a modified JSON object that would share the same structure as the conversation script in localStorage. It would be recalled every time the bot is brought up, however, it would also need to:</p><ol><li>Have the potential to be used with a database or any other data storage method.</li><li>Have different UI interactivity and style than the rest of the bot (a visual cue for the user).</li><li>Be a progressive enhancement that doesn’t break the rest of the app.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eQc_eyPCOSPRgt_UqMLSdA.png\" /><figcaption>chat-bubble-interactions is the LS key for keeping in-touch with the chat history.</figcaption></figure><h4>Future-proofing.</h4><p>Keeping an option open for implementing a server-side storage solution is pretty straight-forward. The entire library is less than 340 lines of non-compressed, commented JavaScript. Shall anyone attempt to implement that, all that would need to be changed is JSON.parse(localStorage.getItem(interactionsLS)) method for accessing the history and localStorage.setItem(interactionsLS, JSON.stringify(interactionsHistory)) method for saving the history.</p><p>The only roadblock I can see here is having to add a Promise -type checks to make sure that everything needed to display history is downloaded before proceeding. Something like this might take some work as there would need to be a few decisions made regarding when the download should start and what functions should it block. I’m leaving that for tomorrow.</p><h4>Custom UI for recalled conversations.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/957/1*ZkXx_a2X6pa46NSCkDD23Q.png\" /><figcaption>Note the “greyed-out” style for this recollected conversation up top.</figcaption></figure><p>To keep things simple, previous conversations would appear in the chat as soon as the user opens it.</p><p>However, as a side-effect of that decision, those conversations would <em>have</em> to be styled differently to avoid confusing the user. Additionally, the user responses would need special attention when stored and recalled, since user responses <strong>can not have any interactivity associated with them</strong>.</p><p>What I mean is that while highlighting chat bubbles in black and floating them right for user responses isn’t that hard there are implications when the chat uses buttons instead of keyboard input messages. Read on.</p><p>Consider the example (below) when the user is presented with options to select one of the two or more buttons as a way of answering to the bot. Obviously storing answer options in history isn’t helpful — they have nothing to do with conversation structure after they’ve been interacted with. Only the user’s response (their selected answer bubble) is relevant. The trick is not storing anything in history until the user has created their final interaction.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*SeO8giseO7LVQ_4D5O3p6w.gif\" /><figcaption>Note how the <strong>answer options</strong> no longer appear in the conversation history.</figcaption></figure><p>For this purpose, I’ve created two functions for saving history: interactionsSave() and interactionsSaveCommit() — where the former would be called to mutate the proposed save object in RAM and the latter would commit that object to localStorage.</p><p>interactionSave() would be called every time the bot produces a response, but only after the user has committed their answer. Because when the user clicks a bubble our script has already “forgotten” what that button looked like in terms of DOM structure, a new one would be made, specifically for committing to conversation history:</p><pre>// add re-generated user picks to the history stack<br>if (_convo[key] !== undefined &amp;&amp; content !== undefined) {<br>  interactionsSave(<br>    &#39;&lt;span class=&quot;bubble-button reply-pick&quot;&gt;&#39; + content + &quot;&lt;/span&gt;&quot;,<br>    &quot;reply reply-pick&quot;<br>  )<br>}</pre><p>interactionsSaveCommit() would be called every time a new speech bubble is created in DOM by the means of addBubble() function.</p><h4><strong>Progressively enhancing.</strong></h4><p>This is a relatively new feature that not everyone would want to use, of course. It is also experimental and could easily be overdone (should someone try to remember a 1,000 interactions the performance and user experience would drop every time the boat would load). So by default I left it off:</p><pre>recallInteractions = options.recallInteractions || 0</pre><p>Getting it to function is super simple though:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;,<br>  { recallInteractions: 10 }<br>);</pre><p>…All that does is tells this interactionsSave() to toss unnecessary stuff away:</p><pre>if (interactionsHistory.length &gt; recallInteractions)<br>      interactionsHistory.shift()</pre><p>For simplicity’s sake, all work on chat-bubble is done without any kind of build steps. All JavaScript is written and ran immediately in-browser (even though developers who implement it are given an option to use ES6 Import method). Because the browsers read JavaScript from the hard-drive in develop mode, any attempt to use localStorage breaks the entire code base as it’s not allowed (due to security restrictions). Which made me think: this could happen quite often in other environments. So I’ve implemented a fallback with a warning:</p><pre>// local storage for recalling conversations upon restart<br>  var localStorageCheck = function() {<br>    var test = &quot;chat-bubble-storage-test&quot;<br>    try {<br>      localStorage.setItem(test, test)<br>      localStorage.removeItem(test)<br>      return true<br>    } catch (error) {<br>      console.error(<br>        &quot;Your server does not allow storing data locally. Most likely it&#39;s because you&#39;ve opened this page from your hard-drive. For testing, you can disable your browser&#39;s security or start a localhost environment.&quot;<br>      )<br>      return false<br>    }<br>  }<br>  var localStorageAvailable = localStorageCheck() &amp;&amp; recallInteractions &gt; 0</pre><p>Now everything should still work even if the browser can not access disk memory.</p><p>As of today, the updated script is available through NPM as chat-bubble@next. It is already performing on our <a href=\"https://www.archie.ai/chrome-extension\">Google Chrome extension</a> and so far is able to save a lot of headache for the users, as well as dramatically reduce perceived loading time.</p><p>All of the code described here is available on <a href=\"https://github.com/dmitrizzle/chat-bubble\">this</a> GitHub repo.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f0d17e015401\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/storing-recalling-bot-interactions-%EF%B8%8F-f0d17e015401\">Storing &amp; recalling bot interactions☝️🤖</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4>Enhancing JavaScript bot UI with localStorage</h4><p>Bot interfaces are fun for the users and advantageous for those who build them (if done right). The concept isn’t new, though today it’s especially powerful.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/525/1*svec126KHXrwAVO2ut0XPw.gif\" /><figcaption>An implementation of a JavaScript <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">bot library</a> with localStorage in-place to memorize previous interactions. Notice the greyed-out text. This screenshot is of a production release of<a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\"> Archie.AI Google Chrome app</a>.</figcaption></figure><p>For developers, bots mean less time spent designing and building custom interfaces. It’s just text bubbles; plus many existing platforms offer to completely avoid this process with their already-successful apps’ APIs (i.e. Google Assistant).</p><p>For users, bots mean a possibility of hands-free interaction (via voice) and a more natural and/or seamless way to converse with machines.</p><h3>A simple solution.</h3><p>When I build things I tend to look for simple solutions, sans bloat, which could be easily understood and customized. Unfortunately, when I was looking for one last year there were none for my use case…</p><p>My team and I have implemented and trained a natural language classification engine, <a href=\"https://www.archie.ai\"><em>Archie.AI</em></a>, and gave it the power to understand and generate answers from Google Analytics. The bot can give daily briefings about users’ state of business, predict the number of future visitors and answer over <a href=\"https://www.archie.ai/ask-me\">430 related questions</a>. It’s an excellent way to save time when looking for a particular metric or an instant business advice.</p><p>It works wonderfully with Google Assistant and Alexa, however, when the time came to get a fast, clean interface for the web, there were no good-enough options. So I built one and kept it open-source. <a href=\"https://www.archie.ai/open-source\">chat-bubble</a> is the one-kilobyte JavaScript file with no dependencies that’s really easy to implement and understand:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;<br>);<br>chatWindow.talk({<br>  &quot;ice&quot;: { &quot;says&quot; : [ &quot;Hello!&quot; ] }<br>});</pre><pre>// <a href=\"https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples\">https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examples</a></pre><p><strong>Batteries included:</strong> a complete set of CSS styles and percision-timed animations, an ability to safely run functions in response to user actions, and a <em>pluggable processing engine</em>.</p><p>By “pluggable processing engine” I mean that the script is not going to tell you how to understand your user’s queries. It’s <em>up to you</em> to implement your own NLC. It’s <em>up to you</em> to either dynamically generate or write response scripts. However, it doesn’t leave you hanging. There are currently three ways to have it respond to your users:</p><ol><li>Give your users options, which appear as buttons (see gif below). Nothing needs to be done here, this is built-in.</li><li>Use the provided sample code that utilizes a simple fuzzy-matching logic to map your users’ input to the options you prescribe (see gif below).</li><li>Plug-in your own NLC engine (see gif above).</li></ol><p>Those options are for recognizing user input. The output (what the bot says) is just as customizable. It could be as simple as a structured JavaScript object variable. Or it could be dynamically imported JSON data. Of course, it doesn’t have to be just one huge JSON file — that would be inefficient! In our case (again, see gif above), we broke it up into individual answers for the responses that require a trip to the server (on-demand) and some calculations on our end.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/410/1*9sMLEpk7ZVFv-H6RPsCSow.gif\" /><figcaption>Bot library example with built-in button controls and input keyboard with fuzzy-match logic implemented. The JSON script that prescribes this conversation structure is below:</figcaption></figure><pre>// a simple conversation script written with JSON</pre><pre>var conversationScript = {<br>  ice: {<br>    says: [&quot;Hi&quot;, &quot;Would you like banana or ice cream?&quot;],<br>    reply: [<br>      {<br>        question: &quot;Banana&quot;,<br>        answer: &quot;banana&quot;<br>      },<br>      {<br>        question: &quot;Ice Cream&quot;,<br>        answer: &quot;ice-cream&quot;<br>      }<br>    ]<br>  },<br>  banana: {<br>    says: [&quot;🍌&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  },<br>  &quot;ice-cream&quot;: {<br>    says: [&quot;🍦&quot;],<br>    reply: [<br>      {<br>        question: &quot;Start Over&quot;,<br>        answer: &quot;ice&quot;<br>      }<br>    ]<br>  }<br>}</pre><h3>Local memory.</h3><p>Over the next few months, we tested the script in production with about a thousand users, while adding a few tweaks and improving performance on older browsers. It has also been downloaded over 700 times as of today.</p><p>The library works equally well on desktop and mobile. However, when it came time to publish it as a part of our Google Chrome browser extension user experience suffered. Because chat-bubble had no inherit persistence, the conversation history would evaporate every time the plugin window is closed. And that happened quite often as Chrome tends to kill the DOM of the plugins entirely each time the user shifts focus.</p><p>That has to be fixed.</p><p>There is no one way to keep the conversation history in on disk. I considered using Redux to manage the state, however, that’s a dependency and the philosophy so far is not to have one. That would also over-complicate things.</p><p>Instead, I decided to store a modified JSON object that would share the same structure as the conversation script in localStorage. It would be recalled every time the bot is brought up, however, it would also need to:</p><ol><li>Have the potential to be used with a database or any other data storage method.</li><li>Have different UI interactivity and style than the rest of the bot (a visual cue for the user).</li><li>Be a progressive enhancement that doesn’t break the rest of the app.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eQc_eyPCOSPRgt_UqMLSdA.png\" /><figcaption>chat-bubble-interactions is the LS key for keeping in-touch with the chat history.</figcaption></figure><h4>Future-proofing.</h4><p>Keeping an option open for implementing a server-side storage solution is pretty straight-forward. The entire library is less than 340 lines of non-compressed, commented JavaScript. Shall anyone attempt to implement that, all that would need to be changed is JSON.parse(localStorage.getItem(interactionsLS)) method for accessing the history and localStorage.setItem(interactionsLS, JSON.stringify(interactionsHistory)) method for saving the history.</p><p>The only roadblock I can see here is having to add a Promise -type checks to make sure that everything needed to display history is downloaded before proceeding. Something like this might take some work as there would need to be a few decisions made regarding when the download should start and what functions should it block. I’m leaving that for tomorrow.</p><h4>Custom UI for recalled conversations.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/957/1*ZkXx_a2X6pa46NSCkDD23Q.png\" /><figcaption>Note the “greyed-out” style for this recollected conversation up top.</figcaption></figure><p>To keep things simple, previous conversations would appear in the chat as soon as the user opens it.</p><p>However, as a side-effect of that decision, those conversations would <em>have</em> to be styled differently to avoid confusing the user. Additionally, the user responses would need special attention when stored and recalled, since user responses <strong>can not have any interactivity associated with them</strong>.</p><p>What I mean is that while highlighting chat bubbles in black and floating them right for user responses isn’t that hard there are implications when the chat uses buttons instead of keyboard input messages. Read on.</p><p>Consider the example (below) when the user is presented with options to select one of the two or more buttons as a way of answering to the bot. Obviously storing answer options in history isn’t helpful — they have nothing to do with conversation structure after they’ve been interacted with. Only the user’s response (their selected answer bubble) is relevant. The trick is not storing anything in history until the user has created their final interaction.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/632/1*SeO8giseO7LVQ_4D5O3p6w.gif\" /><figcaption>Note how the <strong>answer options</strong> no longer appear in the conversation history.</figcaption></figure><p>For this purpose, I’ve created two functions for saving history: interactionsSave() and interactionsSaveCommit() — where the former would be called to mutate the proposed save object in RAM and the latter would commit that object to localStorage.</p><p>interactionSave() would be called every time the bot produces a response, but only after the user has committed their answer. Because when the user clicks a bubble our script has already “forgotten” what that button looked like in terms of DOM structure, a new one would be made, specifically for committing to conversation history:</p><pre>// add re-generated user picks to the history stack<br>if (_convo[key] !== undefined &amp;&amp; content !== undefined) {<br>  interactionsSave(<br>    &#39;&lt;span class=&quot;bubble-button reply-pick&quot;&gt;&#39; + content + &quot;&lt;/span&gt;&quot;,<br>    &quot;reply reply-pick&quot;<br>  )<br>}</pre><p>interactionsSaveCommit() would be called every time a new speech bubble is created in DOM by the means of addBubble() function.</p><h4><strong>Progressively enhancing.</strong></h4><p>This is a relatively new feature that not everyone would want to use, of course. It is also experimental and could easily be overdone (should someone try to remember a 1,000 interactions the performance and user experience would drop every time the boat would load). So by default I left it off:</p><pre>recallInteractions = options.recallInteractions || 0</pre><p>Getting it to function is super simple though:</p><pre>var chatWindow = new Bubbles(<br>  document.getElementById(&quot;chat&quot;),<br>  &quot;chatWindow&quot;,<br>  { recallInteractions: 10 }<br>);</pre><p>…All that does is tells this interactionsSave() to toss unnecessary stuff away:</p><pre>if (interactionsHistory.length &gt; recallInteractions)<br>      interactionsHistory.shift()</pre><p>For simplicity’s sake, all work on chat-bubble is done without any kind of build steps. All JavaScript is written and ran immediately in-browser (even though developers who implement it are given an option to use ES6 Import method). Because the browsers read JavaScript from the hard-drive in develop mode, any attempt to use localStorage breaks the entire code base as it’s not allowed (due to security restrictions). Which made me think: this could happen quite often in other environments. So I’ve implemented a fallback with a warning:</p><pre>// local storage for recalling conversations upon restart<br>  var localStorageCheck = function() {<br>    var test = &quot;chat-bubble-storage-test&quot;<br>    try {<br>      localStorage.setItem(test, test)<br>      localStorage.removeItem(test)<br>      return true<br>    } catch (error) {<br>      console.error(<br>        &quot;Your server does not allow storing data locally. Most likely it&#39;s because you&#39;ve opened this page from your hard-drive. For testing, you can disable your browser&#39;s security or start a localhost environment.&quot;<br>      )<br>      return false<br>    }<br>  }<br>  var localStorageAvailable = localStorageCheck() &amp;&amp; recallInteractions &gt; 0</pre><p>Now everything should still work even if the browser can not access disk memory.</p><p>As of today, the updated script is available through NPM as chat-bubble@next. It is already performing on our <a href=\"https://www.archie.ai/chrome-extension\">Google Chrome extension</a> and so far is able to save a lot of headache for the users, as well as dramatically reduce perceived loading time.</p><p>All of the code described here is available on <a href=\"https://github.com/dmitrizzle/chat-bubble\">this</a> GitHub repo.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f0d17e015401\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/storing-recalling-bot-interactions-%EF%B8%8F-f0d17e015401\">Storing &amp; recalling bot interactions☝️🤖</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: travel\n",
      "\tTag: startup-lessons\n",
      "\tTag: ycombinator\n",
      "\tTag: startup\n",
      "\tTag: silicon-valley\n",
      "Return Flight\n",
      "Wed, 10 Jan 2018 06:17:06 GMT\n",
      "Dmitri\n",
      "<p>Entire trip lasted around four days, half of which I spent in the air. Three different planes carried me from Chiang Mai to Bangkok, then Taipei, then San Francisco. Three more did it again in reverse order.</p><p>I crossed the Pacific twice for a ten-minute meeting.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*g3osmShBgsheGn7KreX0zw.jpeg\" /><figcaption>All the photos in this essay were taken with my fourty-year-old Yashica Electro 35 camera on Ilford Pan 100 film.</figcaption></figure><p>A week prior, Ishtiaq called first thing in the morning with the news: Y Combinator invited us for an interview and all three co-founders had to be there.</p><p>Y Combinator is the most respected startup accelerator program on the planet. They helped Air BnB, Dropbox and Reddit (amongst hundreds of others) get to the position they are at today. Their unique way of deciding whether we were worth their investment is paying for everyone’s return flights and accommodations to meet us for exactly ten minutes.</p><p>Arjun flew from Dubai and I flew from Chiang Mai to meet Ish at our tiny San Francisco HQ.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w8ZUtWId7FgLWSKQWzkFNQ.jpeg\" /></figure><p>My part of the job at <a href=\"https://www.archie.ai/\">the company</a> is managing technical resources, building, and fixing things from my home in Thailand. Last time I flew to SFO I was there for nine months before making it back.</p><p>While in California, I was always busy. Surrounded by great people, though I often felt lonely, wishing I was back home with my girlfriend, Betty. This trip brought a lot of those memories back. Of course, the prospect of seeing Arjun and Ishtiaq, my very close friends and co-founders, as well as a shot at being a part of a Silicon Valley’s elite club was exhilarating. I felt as if I was being propelled to the heights of an emotional rollercoaster as I sat in the tail section of the plane, quaking from the turbulence.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*keTy7W6yPIVHlmmTY46yAA.jpeg\" /><figcaption>An edgy stewardess sat facing me directly across the emergency exit route. She didn’t seem to stay still for one minute during the entire flight. Perhaps it was her first year at the job.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zOWO6cBm82Jckrh20_I8FQ.jpeg\" /></figure><p>Border-crossing is everyone’s least favourite part of international travel. Even with a Canadian passport, arguably one of the best travel documents in the world, you could still get hassled.</p><p>A long line of tired passengers snaked through the hall. I sent my messages out, checked my emails and waited for my turn. Shifting one foot in front of the other, as the crowd methodically inched through the three open booths.</p><p>The invitation letter I presented to the officer seemed to have immediately put him in a good mood. He waved me in while sharing a joke with his co-worker. I drowsily stumbled across the hall, amused at the amount of grease a sheet of paper has added to the grinding process of being admitted to the USA.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JdQVusc62VItFN_GR-Eqhw.jpeg\" /><figcaption>Little Hollywood.</figcaption></figure><p>I took a short Uber ride with two other passengers before arriving at the house. Ish met me with a bear hug and we spent an hour catching up until Arjun, who flew in a little earlier, woke up and we got some dinner.</p><h3>The house.</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mcF_iGN8n7_VCgKG5UVTRA.jpeg\" /><figcaption>Ish and I, captured by Arjun.</figcaption></figure><p>The house, our HQ, seemed unchanged since the last time I was there.</p><p>It resided in San Franciso’s <em>Little Hollywood</em> — a fairly unknown neighbourhood that warranted a (relatively) affordable rent, a distant view of a park and close proximity to Caltrain station.</p><p>We made the garage our office with an array of sticky notes, company posters, a whiteboard and large table space that hosted laptops, spare monitors and a few home automation speakers. A few of my photographs (mostly mountains and trees) were hanging on the walls, but the piano was gone.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4bbhbZtVZFXe2P6IW8NVkw.jpeg\" /><figcaption>Arjun.</figcaption></figure><p>Next morning I got to meet Bhargav and Chandra in-person. They were both responsible for developing new features for our product throughout the past few months, though I’ve only spoken to them on the phone until now. It was all business as we were in the rush to prepare for the interview.</p><h3>The interview.</h3><p>It took us about an hour in an old van to get to Mountain View. Our Uber driver did not seem to be in the rush; he drove at or below the speed limit the entire time. Which made me feel uneasy as I tend to speed whenever I’m on the road, though we had more than enough time.</p><p>Y Combinator building is a refurbished mini-warehouse that’s been furnished with nicely-painted walls, chairs and sofas. A small plaque, no larger than a mailbox stood in front of it, identifying it as the place we wanted to be at.</p><p>Met a few other founders in the parking lot. A horoscope app, a social tool for events, and women’s health cycle tracker. We stood in an awkward circle, wondering if we’d ever see each other again.</p><p>There were seven or eight people in the interview room. Naturally, only a few of us spoke as the decisionmakers were trying to determine whether we were the right choice for them. We were asked just a handful of typical “investor” questions. Everything went by uncomfortably quick, leaving only a hazy recollection that felt like a hallucination.</p><p>We took a train back and waited at the house. The rejection email arrived a few hours before my scheduled departure.</p><p>Effectively nothing has changed for the trajectory of our business. There were over a thousand customers in our database that we had to satisfy and convert. A long list of products to be built, bugs to be fixed, and newly scheduled meetings to attend. Still, nobody likes to lose.</p><p>I flew home looking forward to seeing Betty and all the comforts of sleeping in my own bed.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w2dAR6xB8H8J-sVRBC3i3g.jpeg\" /></figure><p>This story has originally been published on Analog.Cafe — a film photography publication and features events around Archie.AI founding team:</p><ul><li><a href=\"https://www.analog.cafe/zine/return-flight-31p7\">Read the full story at Analog.Cafe</a></li><li><a href=\"https://www.archie.ai\">Archie.AI: Google Analytics Chatbot</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=da9111784266\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/return-flight-da9111784266\">Return Flight</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<p>Entire trip lasted around four days, half of which I spent in the air. Three different planes carried me from Chiang Mai to Bangkok, then Taipei, then San Francisco. Three more did it again in reverse order.</p><p>I crossed the Pacific twice for a ten-minute meeting.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*g3osmShBgsheGn7KreX0zw.jpeg\" /><figcaption>All the photos in this essay were taken with my fourty-year-old Yashica Electro 35 camera on Ilford Pan 100 film.</figcaption></figure><p>A week prior, Ishtiaq called first thing in the morning with the news: Y Combinator invited us for an interview and all three co-founders had to be there.</p><p>Y Combinator is the most respected startup accelerator program on the planet. They helped Air BnB, Dropbox and Reddit (amongst hundreds of others) get to the position they are at today. Their unique way of deciding whether we were worth their investment is paying for everyone’s return flights and accommodations to meet us for exactly ten minutes.</p><p>Arjun flew from Dubai and I flew from Chiang Mai to meet Ish at our tiny San Francisco HQ.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w8ZUtWId7FgLWSKQWzkFNQ.jpeg\" /></figure><p>My part of the job at <a href=\"https://www.archie.ai/\">the company</a> is managing technical resources, building, and fixing things from my home in Thailand. Last time I flew to SFO I was there for nine months before making it back.</p><p>While in California, I was always busy. Surrounded by great people, though I often felt lonely, wishing I was back home with my girlfriend, Betty. This trip brought a lot of those memories back. Of course, the prospect of seeing Arjun and Ishtiaq, my very close friends and co-founders, as well as a shot at being a part of a Silicon Valley’s elite club was exhilarating. I felt as if I was being propelled to the heights of an emotional rollercoaster as I sat in the tail section of the plane, quaking from the turbulence.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*keTy7W6yPIVHlmmTY46yAA.jpeg\" /><figcaption>An edgy stewardess sat facing me directly across the emergency exit route. She didn’t seem to stay still for one minute during the entire flight. Perhaps it was her first year at the job.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zOWO6cBm82Jckrh20_I8FQ.jpeg\" /></figure><p>Border-crossing is everyone’s least favourite part of international travel. Even with a Canadian passport, arguably one of the best travel documents in the world, you could still get hassled.</p><p>A long line of tired passengers snaked through the hall. I sent my messages out, checked my emails and waited for my turn. Shifting one foot in front of the other, as the crowd methodically inched through the three open booths.</p><p>The invitation letter I presented to the officer seemed to have immediately put him in a good mood. He waved me in while sharing a joke with his co-worker. I drowsily stumbled across the hall, amused at the amount of grease a sheet of paper has added to the grinding process of being admitted to the USA.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*JdQVusc62VItFN_GR-Eqhw.jpeg\" /><figcaption>Little Hollywood.</figcaption></figure><p>I took a short Uber ride with two other passengers before arriving at the house. Ish met me with a bear hug and we spent an hour catching up until Arjun, who flew in a little earlier, woke up and we got some dinner.</p><h3>The house.</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*mcF_iGN8n7_VCgKG5UVTRA.jpeg\" /><figcaption>Ish and I, captured by Arjun.</figcaption></figure><p>The house, our HQ, seemed unchanged since the last time I was there.</p><p>It resided in San Franciso’s <em>Little Hollywood</em> — a fairly unknown neighbourhood that warranted a (relatively) affordable rent, a distant view of a park and close proximity to Caltrain station.</p><p>We made the garage our office with an array of sticky notes, company posters, a whiteboard and large table space that hosted laptops, spare monitors and a few home automation speakers. A few of my photographs (mostly mountains and trees) were hanging on the walls, but the piano was gone.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4bbhbZtVZFXe2P6IW8NVkw.jpeg\" /><figcaption>Arjun.</figcaption></figure><p>Next morning I got to meet Bhargav and Chandra in-person. They were both responsible for developing new features for our product throughout the past few months, though I’ve only spoken to them on the phone until now. It was all business as we were in the rush to prepare for the interview.</p><h3>The interview.</h3><p>It took us about an hour in an old van to get to Mountain View. Our Uber driver did not seem to be in the rush; he drove at or below the speed limit the entire time. Which made me feel uneasy as I tend to speed whenever I’m on the road, though we had more than enough time.</p><p>Y Combinator building is a refurbished mini-warehouse that’s been furnished with nicely-painted walls, chairs and sofas. A small plaque, no larger than a mailbox stood in front of it, identifying it as the place we wanted to be at.</p><p>Met a few other founders in the parking lot. A horoscope app, a social tool for events, and women’s health cycle tracker. We stood in an awkward circle, wondering if we’d ever see each other again.</p><p>There were seven or eight people in the interview room. Naturally, only a few of us spoke as the decisionmakers were trying to determine whether we were the right choice for them. We were asked just a handful of typical “investor” questions. Everything went by uncomfortably quick, leaving only a hazy recollection that felt like a hallucination.</p><p>We took a train back and waited at the house. The rejection email arrived a few hours before my scheduled departure.</p><p>Effectively nothing has changed for the trajectory of our business. There were over a thousand customers in our database that we had to satisfy and convert. A long list of products to be built, bugs to be fixed, and newly scheduled meetings to attend. Still, nobody likes to lose.</p><p>I flew home looking forward to seeing Betty and all the comforts of sleeping in my own bed.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*w2dAR6xB8H8J-sVRBC3i3g.jpeg\" /></figure><p>This story has originally been published on Analog.Cafe — a film photography publication and features events around Archie.AI founding team:</p><ul><li><a href=\"https://www.analog.cafe/zine/return-flight-31p7\">Read the full story at Analog.Cafe</a></li><li><a href=\"https://www.archie.ai\">Archie.AI: Google Analytics Chatbot</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=da9111784266\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/return-flight-da9111784266\">Return Flight</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: artificial-intelligence\n",
      "\tTag: google-analytics\n",
      "\tTag: analytics\n",
      "\tTag: startup\n",
      "Thank you for an incredible year from team Archie.AI\n",
      "Thu, 04 Jan 2018 06:16:19 GMT\n",
      "Dmitri\n",
      "<h4>Happy Holidays!</h4><h4>This is Dmitri, CTO and co-founder of Archie.AI.</h4><p>I would like to personally thank you for being our pioneering customer. With your support and feedback, we are able to help over a thousand businesses of various sizes understand and interact with data better. Below is a quick recap of what happened during the past twelve months.</p><h3><strong>2017 was a huge! </strong>We launched six products, amongst hundreds of features, including:</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*rQJF3ZOoiXNILfBgpEROXw.jpeg\" /></figure><p><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Bot</a> — Cut through the clutter of Google Analytics with free, weekly email reports.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*coJVTsslMQDmcHw9u_aFig.jpeg\" /></figure><p><a href=\"https://www.archie.ai/google-assistant\">Google Assistant Action</a> — Talk to your Google Analytics with Google Assistant-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*CmZHGDLnyFrhLVlOxJ50CQ.jpeg\" /></figure><p><a href=\"https://www.amazon.com/Archie-AI-Archie-Voice/dp/B07525T7R9\">Alexa Skill</a> — Talk to you Google Analytics on Amazon Alexa-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*9MOLxnt3fOLY7itlwtjxwg.jpeg\" /></figure><p><a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\">Chrome Extension</a> — Talk to your Google Analytics with Google Chrome Extension.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*ottjZYv2BgPIYM2yWeo0bA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/funnels\">Funnels</a> — Effortlessly compare conversion funnels using your existing Google Analytics account.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*vCgCMpWeYM0V7cdPctVEBA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/enterprise\">Enterprise</a> — AI/ML/Analytics Solution for your SME.</p><p>Archie.AI user community has grown from five to 1,521 (as of this writing). The chart that you see below shows the speed at which Archie has attracted new converts to a better, faster and more natural way to understand data — by talking to it.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_OhZTBcHuFYRG2Vt.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/0*VjCNe3RCS8q1NcD7.jpg\" /><figcaption>Archi.AI founding team at the Google NYC headquarters. I’m in the middle, Arjun Mohan is on your left and Ishtiaq Rahman is on your right.</figcaption></figure><p>None of this would be possible without your feedback and support. Thank you.</p><p>Stay tuned for more awesome launches this coming year. <strong>Expect big things in January 2018!</strong></p><p>Best wishes,<br>Dmitri Tcherbadji<br>Founder/CTO ∙ <strong>Team Archie.AI</strong></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fafd2a7c4f4\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/thank-you-for-an-incredible-year-from-team-archie-ai-fafd2a7c4f4\">Thank you for an incredible year from team Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4>Happy Holidays!</h4><h4>This is Dmitri, CTO and co-founder of Archie.AI.</h4><p>I would like to personally thank you for being our pioneering customer. With your support and feedback, we are able to help over a thousand businesses of various sizes understand and interact with data better. Below is a quick recap of what happened during the past twelve months.</p><h3><strong>2017 was a huge! </strong>We launched six products, amongst hundreds of features, including:</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*rQJF3ZOoiXNILfBgpEROXw.jpeg\" /></figure><p><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">Email Bot</a> — Cut through the clutter of Google Analytics with free, weekly email reports.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*coJVTsslMQDmcHw9u_aFig.jpeg\" /></figure><p><a href=\"https://www.archie.ai/google-assistant\">Google Assistant Action</a> — Talk to your Google Analytics with Google Assistant-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*CmZHGDLnyFrhLVlOxJ50CQ.jpeg\" /></figure><p><a href=\"https://www.amazon.com/Archie-AI-Archie-Voice/dp/B07525T7R9\">Alexa Skill</a> — Talk to you Google Analytics on Amazon Alexa-enabled devices.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*9MOLxnt3fOLY7itlwtjxwg.jpeg\" /></figure><p><a href=\"https://chrome.google.com/webstore/detail/archieai-google-analytics/dehldelopfcidgmfdbgaljofaemkkjcg?hl=en\">Chrome Extension</a> — Talk to your Google Analytics with Google Chrome Extension.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*ottjZYv2BgPIYM2yWeo0bA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/funnels\">Funnels</a> — Effortlessly compare conversion funnels using your existing Google Analytics account.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/320/1*vCgCMpWeYM0V7cdPctVEBA.jpeg\" /></figure><p><a href=\"https://www.archie.ai/enterprise\">Enterprise</a> — AI/ML/Analytics Solution for your SME.</p><p>Archie.AI user community has grown from five to 1,521 (as of this writing). The chart that you see below shows the speed at which Archie has attracted new converts to a better, faster and more natural way to understand data — by talking to it.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*_OhZTBcHuFYRG2Vt.png\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/0*VjCNe3RCS8q1NcD7.jpg\" /><figcaption>Archi.AI founding team at the Google NYC headquarters. I’m in the middle, Arjun Mohan is on your left and Ishtiaq Rahman is on your right.</figcaption></figure><p>None of this would be possible without your feedback and support. Thank you.</p><p>Stay tuned for more awesome launches this coming year. <strong>Expect big things in January 2018!</strong></p><p>Best wishes,<br>Dmitri Tcherbadji<br>Founder/CTO ∙ <strong>Team Archie.AI</strong></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fafd2a7c4f4\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/thank-you-for-an-incredible-year-from-team-archie-ai-fafd2a7c4f4\">Thank you for an incredible year from team Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: product\n",
      "\tTag: startup\n",
      "\tTag: 2018\n",
      "\tTag: new-year\n",
      "\tTag: lessons-learned\n",
      "7 painfully obvious lessons I learned in 2017 while building a startup.\n",
      "Mon, 01 Jan 2018 06:16:27 GMT\n",
      "Ishtiaq Rahman\n",
      "<p>Happy New Year Medium! 🎉</p><p>I didn’t know I suck at so many different things before I started a company. 🚀</p><p>Building a company requires you to get good at a lot of different things besides your domain expertise. You may be good at product/engineering but you also have to do other things like fundraising, hiring, marketing and taxes etc. As a result, you become self-aware of all the things you’re bad at.</p><p>Exhibit A: I am really bad at PR. I’d send press releases to journalists with detailed product description, quotes, image resources and announcements about Archie.AI’s product releases and never hear back. We hit 500 customers, launched on Google Assistant, Alexa, Chrome Webstore, won startup contests, got huge computation grants from IBM and NVIDIA, raised a funding round — press didn’t even accidentally write about us.</p><p>I just sucked at telling a compelling story to write about. But the PR failure pushed us to build our own audience the hard way.</p><p>We started getting our message across directly to whoever would listen.</p><p>We built our own audience through sharing real insights we learned and people started to listen.</p><p>Here are 7 painfully obvious lessons I learned in 2017 while building Archie.AI, in no particular order.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*CB3KH2nTYMnldnVh.gif\" /><figcaption>Gif by <a href=\"https://giphy.com/lisa-vertudaches/\">Lisa Vertudaches</a></figcaption></figure><ol><li>Do not underestimate the power of your vulnerability. Sharing it is hard, but it is instantly relatable to EVERYONE. People like real shit, it’s beautifully simple.</li><li>Empathy is the most useful skill for building any product. Second most useful skill is the ability to rely on Data to make decisions.</li><li>People will never buy something they don’t understand. No matter how intricate your product or service is, a 10-year-old should be able to verbalize it in his/her own words.</li><li>Humans have no issue paying for things that give them value. Your customers will look for a good deal, but if you can provide real value, people/market will reward you for your efforts.</li><li>If you have real insights — only acquired by experiments and experience — people will listen. Your audience may be small today but it will grow if you have a real story to tell and you’re willing to put yourself out there in front of the world.</li><li>“Done” is always, unequivocally better than “perfect”. Perfection should reside inside your head where all externalities can be ignored.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/245/0*42zkp6Xd3zgYYGCa.gif\" /></figure><p>7. Faking courage is the same as having real courage.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*Q6Fa6uGL-L76JDLu.gif\" /><figcaption>Bran thought about it. ‘Can a man still be brave if he’s afraid?’<br>‘That is the only time a man can be brave,’ his father told him.”</figcaption></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=655e1b1c99f9\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/7-painfully-obvious-lessons-i-learned-in-2017-while-building-my-startup-655e1b1c99f9\">7 painfully obvious lessons I learned in 2017 while building a startup.</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<p>Happy New Year Medium! 🎉</p><p>I didn’t know I suck at so many different things before I started a company. 🚀</p><p>Building a company requires you to get good at a lot of different things besides your domain expertise. You may be good at product/engineering but you also have to do other things like fundraising, hiring, marketing and taxes etc. As a result, you become self-aware of all the things you’re bad at.</p><p>Exhibit A: I am really bad at PR. I’d send press releases to journalists with detailed product description, quotes, image resources and announcements about Archie.AI’s product releases and never hear back. We hit 500 customers, launched on Google Assistant, Alexa, Chrome Webstore, won startup contests, got huge computation grants from IBM and NVIDIA, raised a funding round — press didn’t even accidentally write about us.</p><p>I just sucked at telling a compelling story to write about. But the PR failure pushed us to build our own audience the hard way.</p><p>We started getting our message across directly to whoever would listen.</p><p>We built our own audience through sharing real insights we learned and people started to listen.</p><p>Here are 7 painfully obvious lessons I learned in 2017 while building Archie.AI, in no particular order.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*CB3KH2nTYMnldnVh.gif\" /><figcaption>Gif by <a href=\"https://giphy.com/lisa-vertudaches/\">Lisa Vertudaches</a></figcaption></figure><ol><li>Do not underestimate the power of your vulnerability. Sharing it is hard, but it is instantly relatable to EVERYONE. People like real shit, it’s beautifully simple.</li><li>Empathy is the most useful skill for building any product. Second most useful skill is the ability to rely on Data to make decisions.</li><li>People will never buy something they don’t understand. No matter how intricate your product or service is, a 10-year-old should be able to verbalize it in his/her own words.</li><li>Humans have no issue paying for things that give them value. Your customers will look for a good deal, but if you can provide real value, people/market will reward you for your efforts.</li><li>If you have real insights — only acquired by experiments and experience — people will listen. Your audience may be small today but it will grow if you have a real story to tell and you’re willing to put yourself out there in front of the world.</li><li>“Done” is always, unequivocally better than “perfect”. Perfection should reside inside your head where all externalities can be ignored.</li></ol><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/245/0*42zkp6Xd3zgYYGCa.gif\" /></figure><p>7. Faking courage is the same as having real courage.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/0*Q6Fa6uGL-L76JDLu.gif\" /><figcaption>Bran thought about it. ‘Can a man still be brave if he’s afraid?’<br>‘That is the only time a man can be brave,’ his father told him.”</figcaption></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=655e1b1c99f9\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/7-painfully-obvious-lessons-i-learned-in-2017-while-building-my-startup-655e1b1c99f9\">7 painfully obvious lessons I learned in 2017 while building a startup.</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: conversations\n",
      "\tTag: google-analytics\n",
      "\tTag: growth-hacking\n",
      "\tTag: analytics\n",
      "\tTag: marketing\n",
      "Introducing Funnels By Archie.AI\n",
      "Thu, 14 Dec 2017 05:51:06 GMT\n",
      "Ishtiaq Rahman\n",
      "<h3>A tool to effortlessly compare Google Analytics funnels by Archie.AI</h3><p>Team Archie.AI keep dropping hits. 🚀</p><p>This time we’re back with a tool to help you use Google Analytics data to instantly create and compare conversion funnels side-by-side.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/900/1*QUiooKUO6qqYdwc9R3ZVmQ.gif\" /><figcaption>Funnels by Archie.AI. Try it here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></figcaption></figure><p>Here are some quick use-cases.</p><ul><li>Compare the performance of referrals from different sources.<br>E.g. Facebook Referrals VS Google Referrals: Who’s converting more?</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YsNN0KzhQLmx4NxjmMiP-g.gif\" /><figcaption>Compare campaign performance with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Compare the pages on your website to see what is working and what isn’t<br>E.g: Compare two of your content pages to see which one ends up converting most of your conversions.</li><li>Compare conversion performance over time.<br>E.g. Compare conversion funnels before/after website redesigns to see if performance changed.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sS6gcT441g3_Om8Ao1fvrA.gif\" /><figcaption>Compare conversion performance over time with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Run A/B testing of 2 landing pages and compare effectiveness</li><li>Compare conversion funnels across Device type, Browser type, locations and more.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-Qv0qJ9qjQ7nD2I0o7NC4w.jpeg\" /><figcaption>Compare conversion funnels across Device type, Browser type, locations and more.</figcaption></figure><p>Following are the roles we built this tool for.</p><ul><li>You’re a Product Owner/Product Manager/Founder directly responsible for the performance of your business’s digital front.</li><li>You’re part of a business that sells their product/services online through websites, web/mobile apps.</li><li>You’re an engineer trying to find a better way (automated) to sift through data and report actionable analytics, anomalies and patterns to your team.</li><li>You’re responsible for allocating how and where Digital Marketing dollars are spent.</li></ul><p>We’re offering 15 day trial period so you can play around with it 🎁 and let us know what you think.</p><p>Try it out here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a5ff206d530a\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/introducing-funnels-by-archie-ai-a5ff206d530a\">Introducing Funnels By Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h3>A tool to effortlessly compare Google Analytics funnels by Archie.AI</h3><p>Team Archie.AI keep dropping hits. 🚀</p><p>This time we’re back with a tool to help you use Google Analytics data to instantly create and compare conversion funnels side-by-side.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/900/1*QUiooKUO6qqYdwc9R3ZVmQ.gif\" /><figcaption>Funnels by Archie.AI. Try it here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></figcaption></figure><p>Here are some quick use-cases.</p><ul><li>Compare the performance of referrals from different sources.<br>E.g. Facebook Referrals VS Google Referrals: Who’s converting more?</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YsNN0KzhQLmx4NxjmMiP-g.gif\" /><figcaption>Compare campaign performance with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Compare the pages on your website to see what is working and what isn’t<br>E.g: Compare two of your content pages to see which one ends up converting most of your conversions.</li><li>Compare conversion performance over time.<br>E.g. Compare conversion funnels before/after website redesigns to see if performance changed.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*sS6gcT441g3_Om8Ao1fvrA.gif\" /><figcaption>Compare conversion performance over time with <a href=\"https://www.archie.ai/funnels\">Funnels by Archie.AI</a></figcaption></figure><ul><li>Run A/B testing of 2 landing pages and compare effectiveness</li><li>Compare conversion funnels across Device type, Browser type, locations and more.</li></ul><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*-Qv0qJ9qjQ7nD2I0o7NC4w.jpeg\" /><figcaption>Compare conversion funnels across Device type, Browser type, locations and more.</figcaption></figure><p>Following are the roles we built this tool for.</p><ul><li>You’re a Product Owner/Product Manager/Founder directly responsible for the performance of your business’s digital front.</li><li>You’re part of a business that sells their product/services online through websites, web/mobile apps.</li><li>You’re an engineer trying to find a better way (automated) to sift through data and report actionable analytics, anomalies and patterns to your team.</li><li>You’re responsible for allocating how and where Digital Marketing dollars are spent.</li></ul><p>We’re offering 15 day trial period so you can play around with it 🎁 and let us know what you think.</p><p>Try it out here: <a href=\"https://www.archie.ai/funnels\">https://www.archie.ai/funnels</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a5ff206d530a\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/introducing-funnels-by-archie-ai-a5ff206d530a\">Introducing Funnels By Archie.AI</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "\tTag: productivity\n",
      "\tTag: google-analytics\n",
      "\tTag: marketing\n",
      "\tTag: artificial-intelligence\n",
      "\tTag: analytics\n",
      "An easier way to get Google Analytics email reports\n",
      "Thu, 23 Nov 2017 06:21:36 GMT\n",
      "Dmitri\n",
      "<h4>How to set up weekly email reports from your GA account with traffic &amp; conversion summary, predictions and insights</h4><blockquote><strong>TL;DR:</strong> Here’s the <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><strong>link</strong></a> for an app that does it for you.</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ui4EJXOWGhhDvgjL4U7Axw.jpeg\" /></figure><p>I spend a lot of my time working with Google Analytics. I measure visitors of an e-commerce website that sells prints, a community blog, a Kickstarter page for when my campaign was live and multiple web properties owned by the start up I co-founded. It’s a real hassle to try and keep up with all that data, let alone making sense of it.</p><p>I thought that my problem was unique to serial webmasters, however it turns out that <strong>making sense of Google Analytics can be a challenge, even for a casual blogger</strong>. Seeing the default graph of visitors over time doesn’t provide as much value as one might think. Real-time reporting surely is exciting, but not very insightful. A proper way to get an answer to <em>“What should I do with my website next?”</em> question can only be found by digging through numerous GA views, often importing the data into a spreadsheet and processing it further. Only then you <em>may</em> have some answers.</p><h3>Email reporting — spending less time digging through data.</h3><p>A friend once brought up email reporting as a possible solution. He owns a medium-sized blog where he posts reviews of vintage camera lenses and street photography advice. It turns out that Google Analytics provides email reports that could potentially cut down on the time spent digging through data on the daily basis.</p><p>Perhaps I could do better if I concentrate on building content, code and design for my websites and let the data get to me, instead of seeking it out? At least that’s what I hoped the email reporting would do: give me the numbers every week or so. I’ve never found the constant stream of traffic reports that useful anyways.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/351/1*eYL5tFDQTLcuJJ4yk3EKGQ.jpeg\" /><figcaption>The dream: simple, usable email reporting.</figcaption></figure><h4>Google Analytics’ proprietary email reporting: not very simple, not very valuable.</h4><p>Everything sounded fantastic at the start. Google is an all-powerful tech giant that can whip out amazing software. I’ve got a decade’s worth of programming experience &amp; industry know-how. This is just an email report — should be super-easy! Right?</p><p>No. First of all, Google has been revamping its Analytics software for the past few years practically non-stop. Hence finding good instructions with correct screenshots on the web is a challenge. After some digging it became evident that I’d have to create a custom dashboard that can then be sent as a PDF attachment to my email at a frequency of my choosing. Making such dashboard is a lot of work, and if it isn’t properly designed to cater to my application, I’ll be getting <strong>misleading reports, every time</strong>. Which isn’t good.</p><p>I have to say that PDF reports look great with the graphics and all, although I’d have to wait for them to download and open in a very mobile un-friendly way: zoom, scroll, zoom, scroll…</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*T6ojhkfWCG02gRY2LokViQ.jpeg\" /></figure><p>Long story short, GA email reporting can be an incredibly powerful feature, but to set it up correctly you’d have to do a data requirements inventory on your web property and get it right. Which isn’t simple.</p><h3>An easier, better way to get Google Analytics email reports.</h3><blockquote>Disclaimer: the product I’m about to recommend was built by my startup.</blockquote><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UDjRuV8rs2VeYLM_FMzO4w.jpeg\" /></a><figcaption>The tool is called Archie.AI. It’s free and easy to set up, you can get it here: <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">https://www.archie.ai/email-reporting-for-google-analytics</a></figcaption></figure><p>One of the advantages of Google Analytics that becomes a drawback later on is the way it presents data. Always cut-dry facts, with zero opinions. Which is perfect if you have a data analyst on your payroll. That person would take those facts and let you know what she thinks it all means and what your next steps should be.</p><p>My team and I have been working on an algorithm that could perform that very task:<strong> interpret and suggest, according to available data</strong>. The code that does that runs thousands of queries every day, answering questions like “Predict my next week’s traffic.” or “How do I increase my traffic?” This tool is part of a larger suite of medium to advanced Google Analytics AI enhancements:<em> Archie.AI</em>.</p><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BeqMTlg3OVJt-oaGdUYrjA.png\" /></a></figure><p>After trying the email reporting tool that comes with Google Analytics and chatting with some of our clients we decided to use our natural language generation platform to create simple, curated email reports. The goal was to select about seven key metrics and generate insights with predictions and human-like advice. Then send it every seven days, just before the week’s start.</p><p>Besides giving human-like opinions and advice on your data we made sure our tool does not require any work on your end, besides clicking “Log in with Google” and selecting the property you’d like to track. You can also add conversion tracking with dollar (or whatever your currency is) value to get some e-commerce or KPI reports — but that’s up to you.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/680/1*8ymsMzKlAjjci1sSdq2yfg.gif\" /><figcaption>The setup process for Google Analytics email reporting with Archie.AI. Simple.</figcaption></figure><p>After tapping those three buttons you would get your first report instantly and all consequent reports every Sunday night (EST). The emails are all text, but the key points are highlighted to get your attention and the entire thing consists of <strong>algorithmic interpretations that can help you drive your decisions much better than any fancy graph could.</strong></p><p>Although it’s a part of a larger suite of tools available with full Archie.AI membership we decided to make it 100% free, leaving the choice up to you on whether you want to upgrade or not.</p><p>This is a fairly new product and we’re constantly looking for your feedback. If you’ve got some advice, criticism or ideas — please don’t hesitate to let us know. In any case, follow <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">this link</a> to try it out.</p><h3>🍻</h3><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b456bb5eec7\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/an-easier-way-to-get-google-analytics-email-reports-b456bb5eec7\">An easier way to get Google Analytics email reports</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
      "<h4>How to set up weekly email reports from your GA account with traffic &amp; conversion summary, predictions and insights</h4><blockquote><strong>TL;DR:</strong> Here’s the <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><strong>link</strong></a> for an app that does it for you.</blockquote><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Ui4EJXOWGhhDvgjL4U7Axw.jpeg\" /></figure><p>I spend a lot of my time working with Google Analytics. I measure visitors of an e-commerce website that sells prints, a community blog, a Kickstarter page for when my campaign was live and multiple web properties owned by the start up I co-founded. It’s a real hassle to try and keep up with all that data, let alone making sense of it.</p><p>I thought that my problem was unique to serial webmasters, however it turns out that <strong>making sense of Google Analytics can be a challenge, even for a casual blogger</strong>. Seeing the default graph of visitors over time doesn’t provide as much value as one might think. Real-time reporting surely is exciting, but not very insightful. A proper way to get an answer to <em>“What should I do with my website next?”</em> question can only be found by digging through numerous GA views, often importing the data into a spreadsheet and processing it further. Only then you <em>may</em> have some answers.</p><h3>Email reporting — spending less time digging through data.</h3><p>A friend once brought up email reporting as a possible solution. He owns a medium-sized blog where he posts reviews of vintage camera lenses and street photography advice. It turns out that Google Analytics provides email reports that could potentially cut down on the time spent digging through data on the daily basis.</p><p>Perhaps I could do better if I concentrate on building content, code and design for my websites and let the data get to me, instead of seeking it out? At least that’s what I hoped the email reporting would do: give me the numbers every week or so. I’ve never found the constant stream of traffic reports that useful anyways.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/351/1*eYL5tFDQTLcuJJ4yk3EKGQ.jpeg\" /><figcaption>The dream: simple, usable email reporting.</figcaption></figure><h4>Google Analytics’ proprietary email reporting: not very simple, not very valuable.</h4><p>Everything sounded fantastic at the start. Google is an all-powerful tech giant that can whip out amazing software. I’ve got a decade’s worth of programming experience &amp; industry know-how. This is just an email report — should be super-easy! Right?</p><p>No. First of all, Google has been revamping its Analytics software for the past few years practically non-stop. Hence finding good instructions with correct screenshots on the web is a challenge. After some digging it became evident that I’d have to create a custom dashboard that can then be sent as a PDF attachment to my email at a frequency of my choosing. Making such dashboard is a lot of work, and if it isn’t properly designed to cater to my application, I’ll be getting <strong>misleading reports, every time</strong>. Which isn’t good.</p><p>I have to say that PDF reports look great with the graphics and all, although I’d have to wait for them to download and open in a very mobile un-friendly way: zoom, scroll, zoom, scroll…</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*T6ojhkfWCG02gRY2LokViQ.jpeg\" /></figure><p>Long story short, GA email reporting can be an incredibly powerful feature, but to set it up correctly you’d have to do a data requirements inventory on your web property and get it right. Which isn’t simple.</p><h3>An easier, better way to get Google Analytics email reports.</h3><blockquote>Disclaimer: the product I’m about to recommend was built by my startup.</blockquote><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*UDjRuV8rs2VeYLM_FMzO4w.jpeg\" /></a><figcaption>The tool is called Archie.AI. It’s free and easy to set up, you can get it here: <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">https://www.archie.ai/email-reporting-for-google-analytics</a></figcaption></figure><p>One of the advantages of Google Analytics that becomes a drawback later on is the way it presents data. Always cut-dry facts, with zero opinions. Which is perfect if you have a data analyst on your payroll. That person would take those facts and let you know what she thinks it all means and what your next steps should be.</p><p>My team and I have been working on an algorithm that could perform that very task:<strong> interpret and suggest, according to available data</strong>. The code that does that runs thousands of queries every day, answering questions like “Predict my next week’s traffic.” or “How do I increase my traffic?” This tool is part of a larger suite of medium to advanced Google Analytics AI enhancements:<em> Archie.AI</em>.</p><figure><a href=\"https://www.archie.ai/email-reporting-for-google-analytics\"><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*BeqMTlg3OVJt-oaGdUYrjA.png\" /></a></figure><p>After trying the email reporting tool that comes with Google Analytics and chatting with some of our clients we decided to use our natural language generation platform to create simple, curated email reports. The goal was to select about seven key metrics and generate insights with predictions and human-like advice. Then send it every seven days, just before the week’s start.</p><p>Besides giving human-like opinions and advice on your data we made sure our tool does not require any work on your end, besides clicking “Log in with Google” and selecting the property you’d like to track. You can also add conversion tracking with dollar (or whatever your currency is) value to get some e-commerce or KPI reports — but that’s up to you.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/680/1*8ymsMzKlAjjci1sSdq2yfg.gif\" /><figcaption>The setup process for Google Analytics email reporting with Archie.AI. Simple.</figcaption></figure><p>After tapping those three buttons you would get your first report instantly and all consequent reports every Sunday night (EST). The emails are all text, but the key points are highlighted to get your attention and the entire thing consists of <strong>algorithmic interpretations that can help you drive your decisions much better than any fancy graph could.</strong></p><p>Although it’s a part of a larger suite of tools available with full Archie.AI membership we decided to make it 100% free, leaving the choice up to you on whether you want to upgrade or not.</p><p>This is a fairly new product and we’re constantly looking for your feedback. If you’ve got some advice, criticism or ideas — please don’t hesitate to let us know. In any case, follow <a href=\"https://www.archie.ai/email-reporting-for-google-analytics\">this link</a> to try it out.</p><h3>🍻</h3><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b456bb5eec7\" width=\"1\" height=\"1\"><hr><p><a href=\"https://medium.com/archieai/an-easier-way-to-get-google-analytics-email-reports-b456bb5eec7\">An easier way to get Google Analytics email reports</a> was originally published in <a href=\"https://medium.com/archieai\">Archie.AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n"
     ]
    }
   ],
   "source": [
    "for entry in archie_ai.entries:\n",
    "    for term in entry.tags:\n",
    "        print(f\"\\tTag: {term['term']}\")\n",
    "        \n",
    "    print(f\"{entry.title}\\r\\n{entry.published}\\r\\n{entry.author}\")\n",
    "    print(entry.summary)\n",
    "    \n",
    "    for content in entry.content:\n",
    "        print(content.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`archie_ai` worked much better than I had anticipated, but there are several articles that we're not going to be interested in. I'll work on excluding those later, but we'll need to keep an eye on the terms and figure out which ones we're really interested in. We could also have our **writing engine** determine if the content/subject matter is something we're interested in and let it sort everything out for us..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For grins and giggles, let's take a look at the *VentureBeat* feed and see what kind of articles it includes\n",
    "> There are several articles that show up in my **Google** news feed that are usually interesting and they keep up with the things we're interested in here, so that's why I included it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "venture_beat = feedparser.parse(\"data/VentureBeat.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feed': {'title': 'VentureBeat',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'VentureBeat'},\n",
       "  'links': [{'rel': 'alternate',\n",
       "    'type': 'text/html',\n",
       "    'href': 'https://venturebeat.com'},\n",
       "   {'rel': 'self',\n",
       "    'type': 'application/rss+xml',\n",
       "    'href': 'http://feeds.feedburner.com/venturebeat/SZYF'},\n",
       "   {'rel': 'hub',\n",
       "    'href': 'http://pubsubhubbub.appspot.com/',\n",
       "    'type': 'text/html'}],\n",
       "  'link': 'https://venturebeat.com',\n",
       "  'subtitle': 'Tech news that matters',\n",
       "  'subtitle_detail': {'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Tech news that matters'},\n",
       "  'updated': 'Sat, 19 Oct 2019 22:31:12 +0000',\n",
       "  'updated_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=22, tm_min=31, tm_sec=12, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "  'language': 'en-US',\n",
       "  'sy_updateperiod': 'hourly',\n",
       "  'sy_updatefrequency': '1',\n",
       "  'generator_detail': {'name': 'https://wordpress.org/?v=5.2.4'},\n",
       "  'generator': 'https://wordpress.org/?v=5.2.4',\n",
       "  'site': '126020344',\n",
       "  'rights': 'Copyright 2019, VentureBeat',\n",
       "  'rights_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Copyright 2019, VentureBeat'},\n",
       "  'image': {'title': 'VentureBeat',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'VentureBeat'},\n",
       "   'href': 'https://venturebeat.com/wp-content/themes/vb-news/brand/img/logos/VB_Extended_Logo_40H.png',\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'https://venturebeat.com'}],\n",
       "   'link': 'https://venturebeat.com',\n",
       "   'width': 144,\n",
       "   'height': 23,\n",
       "   'subtitle': 'Venturebeat.com',\n",
       "   'subtitle_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Venturebeat.com'}},\n",
       "  'feedburner_info': {'uri': 'venturebeat/szyf'}},\n",
       " 'entries': [{'title': 'Former Eidos president and frequent game startup adviser Keith Boesky passes away',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Former Eidos president and frequent game startup adviser Keith Boesky passes away'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/H2cAxcpZmfw/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/H2cAxcpZmfw/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/19/former-eidos-president-and-frequent-game-startup-adviser-keith-boesky-passes-away/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 22:33:41 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=22, tm_min=33, tm_sec=41, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Dean Takahashi'}],\n",
       "   'author': 'Dean Takahashi',\n",
       "   'author_detail': {'name': 'Dean Takahashi'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'DeanBeat News', 'scheme': None, 'label': None},\n",
       "    {'term': 'Eidos', 'scheme': None, 'label': None},\n",
       "    {'term': 'Emily Greer', 'scheme': None, 'label': None},\n",
       "    {'term': 'Keith Boesky', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540572',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Keith Boesky, former president of Tomb Raider publisher Eidos and a frequent adviser to game companies at Boesky &#038; Co., has died from cancer.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Keith Boesky, former president of Tomb Raider publisher Eidos and a frequent adviser to game companies at Boesky &#038; Co., has died from cancer.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"373\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?fit=578%2C373&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Keith Boesky was the former president of Eidos.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=877&amp;strip=all 877w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=578&amp;strip=all 578w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Keith Boesky, former president of Tomb Raider publisher Eidos and a frequent adviser to game companies at Boesky & Co., has died from cancer.\\xa0<a href=\"https://venturebeat.com/2019/10/19/former-eidos-president-and-frequent-game-startup-adviser-keith-boesky-passes-away/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/H2cAxcpZmfw\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/19/former-eidos-president-and-frequent-game-startup-adviser-keith-boesky-passes-away/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540572',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/19/former-eidos-president-and-frequent-game-startup-adviser-keith-boesky-passes-away/',\n",
       "    'title': 'Former Eidos president and frequent game startup adviser Keith Boesky passes away'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/19/former-eidos-president-and-frequent-game-startup-adviser-keith-boesky-passes-away/'},\n",
       "  {'title': 'Harold Ryan interview — Why ProbablyMonsters is making a huge bet on triple-A games',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Harold Ryan interview — Why ProbablyMonsters is making a huge bet on triple-A games'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/lMCLFQXTK-w/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/lMCLFQXTK-w/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/19/harold-ryan-interview-why-probablymonsters-is-making-a-huge-bet-on-triple-a-games/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 19:12:43 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=19, tm_min=12, tm_sec=43, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Dean Takahashi'}],\n",
       "   'author': 'Dean Takahashi',\n",
       "   'author_detail': {'name': 'Dean Takahashi'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Bungie', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games/Shooter Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'console gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'DeanBeat Reviews Previews and Interviews',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Destiny', 'scheme': None, 'label': None},\n",
       "    {'term': 'Destiny 2', 'scheme': None, 'label': None},\n",
       "    {'term': 'Harold Ryan', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Probably Monsters', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2537544',\n",
       "   'guidislink': False,\n",
       "   'summary': '<p>Former Bungie CEO\\xa0Harold Ryan showed everybody how to go big or go home earlier this month. He announced that his ProbablyMonsters is announcing it has raised $18.8 million for the company’s two triple-A game studios. Ryan is going to need a lot more money than that to pull off not one but two ambitious triple-A&#160;[&#8230;]\\n</p>',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '<p>Former Bungie CEO\\xa0Harold Ryan showed everybody how to go big or go home earlier this month. He announced that his ProbablyMonsters is announcing it has raised $18.8 million for the company’s two triple-A game studios. Ryan is going to need a lot more money than that to pull off not one but two ambitious triple-A&#160;[&#8230;]\\n</p>'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"ProbablyMonsters team\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=1400&amp;strip=all 1400w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Former Bungie CEO\\xa0Harold Ryan showed everybody how to go big or go home earlier this month. He announced that his ProbablyMonsters is announcing it has raised $18.8 million for the company’s two triple-A game studios. Ryan is going to need a lot more money than that to pull off not one but two ambitious triple-A projects in an age when there are a&hellip;<a href=\"https://venturebeat.com/2019/10/19/harold-ryan-interview-why-probablymonsters-is-making-a-huge-bet-on-triple-a-games/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/lMCLFQXTK-w\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/19/harold-ryan-interview-why-probablymonsters-is-making-a-huge-bet-on-triple-a-games/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2537544',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/19/harold-ryan-interview-why-probablymonsters-is-making-a-huge-bet-on-triple-a-games/',\n",
       "    'title': 'Harold Ryan interview — Why ProbablyMonsters is making a huge bet on triple-A games'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/19/harold-ryan-interview-why-probablymonsters-is-making-a-huge-bet-on-triple-a-games/'},\n",
       "  {'title': 'Will the rise of IoT and slowing of Moore’s Law contribute to climate change?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Will the rise of IoT and slowing of Moore’s Law contribute to climate change?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/E2f51XM2CsI/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/E2f51XM2CsI/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/19/will-rise-of-iot-and-the-slowing-of-moores-law-contribute-to-climate-change/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 15:45:19 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=15, tm_min=45, tm_sec=19, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Dean Takahashi'}],\n",
       "   'author': 'Dean Takahashi',\n",
       "   'author_detail': {'name': 'Dean Takahashi'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'Entrepreneur', 'scheme': None, 'label': None},\n",
       "    {'term': 'Amazon', 'scheme': None, 'label': None},\n",
       "    {'term': 'Arm', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Law & Government', 'scheme': None, 'label': None},\n",
       "    {'term': 'climate change', 'scheme': None, 'label': None},\n",
       "    {'term': 'Drew Henry', 'scheme': None, 'label': None},\n",
       "    {'term': 'HiSilicon', 'scheme': None, 'label': None},\n",
       "    {'term': 'NVidia', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2538320',\n",
       "   'guidislink': False,\n",
       "   'summary': \"I spoke with Drew Henry, senior vice president at Arm, about the growing IoT ecosystem's compute demands and the impact that could have on climate change.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"I spoke with Drew Henry, senior vice president at Arm, about the growing IoT ecosystem's compute demands and the impact that could have on climate change.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"The future is looking more and more bleak for the wildlife of the Arctic, especially the polar bears. These bears rely on the sea ice to hunt their favorite prey, seals, and this large male bear seen here, seems to be looking across the Arctic in disbelief as his world disappears beneath him.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=2121&amp;strip=all 2121w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=2000&amp;strip=all 2000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>I spoke with Drew Henry, senior vice president at Arm, about the growing IoT ecosystem\\'s compute demands and the impact that could have on climate change.<a href=\"https://venturebeat.com/2019/10/19/will-rise-of-iot-and-the-slowing-of-moores-law-contribute-to-climate-change/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/E2f51XM2CsI\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/19/will-rise-of-iot-and-the-slowing-of-moores-law-contribute-to-climate-change/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2538320',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/19/will-rise-of-iot-and-the-slowing-of-moores-law-contribute-to-climate-change/',\n",
       "    'title': 'Will the rise of IoT and slowing of Moore’s Law contribute to climate change?'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/19/will-rise-of-iot-and-the-slowing-of-moores-law-contribute-to-climate-change/'},\n",
       "  {'title': 'Tilt Five adds new partners for AR tabletop game project: Tabletopia and Monocle Socity',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Tilt Five adds new partners for AR tabletop game project: Tabletopia and Monocle Socity'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/aVSGIdO6irk/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/aVSGIdO6irk/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/19/tilt-five-adds-new-partners-for-ar-tabletop-game-project-tabletopia-and-monocle-socity/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 10:13:11 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=10, tm_min=13, tm_sec=11, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Harry Baker, UploadVR'}],\n",
       "   'author': 'Harry Baker, UploadVR',\n",
       "   'author_detail': {'name': 'Harry Baker, UploadVR'},\n",
       "   'tags': [{'term': 'AR/VR', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'AR tabletop', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Roleplaying Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Tilt Five', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540488',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Tilt Five\\xa0announced two new tabletop AR game partners with Tabletopia and Monocle Society.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Tilt Five\\xa0announced two new tabletop AR game partners with Tabletopia and Monocle Society.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"394\" src=\"https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?fit=578%2C394&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Tilt Five\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=1237&amp;strip=all 1237w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Tilt Five\\xa0announced two new tabletop AR game partners with Tabletopia and Monocle Society.<a href=\"https://venturebeat.com/2019/10/19/tilt-five-adds-new-partners-for-ar-tabletop-game-project-tabletopia-and-monocle-socity/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/aVSGIdO6irk\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/19/tilt-five-adds-new-partners-for-ar-tabletop-game-project-tabletopia-and-monocle-socity/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540488',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/19/tilt-five-adds-new-partners-for-ar-tabletop-game-project-tabletopia-and-monocle-socity/',\n",
       "    'title': 'Tilt Five adds new partners for AR tabletop game project: Tabletopia and Monocle Socity'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/19/tilt-five-adds-new-partners-for-ar-tabletop-game-project-tabletopia-and-monocle-socity/'},\n",
       "  {'title': 'Battletech gets Heavy Metal expansion on November 21',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Battletech gets Heavy Metal expansion on November 21'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/6SA-_r9okvI/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/6SA-_r9okvI/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/19/battletech-gets-heavy-metal-expansion-on-november-21/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 08:30:28 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=8, tm_min=30, tm_sec=28, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Dean Takahashi'}],\n",
       "   'author': 'Dean Takahashi',\n",
       "   'author_detail': {'name': 'Dean Takahashi'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'BattleTech', 'scheme': None, 'label': None},\n",
       "    {'term': 'Battletech: Heavy Metal', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Board Games/Miniatures & Wargaming',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'DeanBeat News', 'scheme': None, 'label': None},\n",
       "    {'term': 'Harebrained Schemes', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mitch Gitelman', 'scheme': None, 'label': None},\n",
       "    {'term': 'Paradox Interactive', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC gaming', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540507',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Paradox Interactive and Harebrained Schemes announced the Heavy Metal expansion for mech combat game Battletech will go live on November 21.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Paradox Interactive and Harebrained Schemes announced the Heavy Metal expansion for mech combat game Battletech will go live on November 21.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<iframe class=\\'youtube-player\\' type=\\'text/html\\' width=\\'560\\' height=\\'315\\' src=\\'https://www.youtube.com/embed/oCqrGKA-wdg?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent\\' allowfullscreen=\\'true\\' style=\\'border:0;\\'></iframe><hr/>Paradox Interactive and Harebrained Schemes announced the Heavy Metal expansion for mech combat game Battletech will go live on November 21.<a href=\"https://venturebeat.com/2019/10/19/battletech-gets-heavy-metal-expansion-on-november-21/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/6SA-_r9okvI\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/19/battletech-gets-heavy-metal-expansion-on-november-21/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540507',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/19/battletech-gets-heavy-metal-expansion-on-november-21/',\n",
       "    'title': 'Battletech gets Heavy Metal expansion on November 21'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/19/battletech-gets-heavy-metal-expansion-on-november-21/'},\n",
       "  {'title': 'Age of Wonders: Planetfall’s first expansion is Revelations, launching November 19',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Age of Wonders: Planetfall’s first expansion is Revelations, launching November 19'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/SzAB55UEp0Y/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/SzAB55UEp0Y/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/19/age-of-wonders-planetfall-gets-its-first-expansion-is-revelations-launching-november-19/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 08:25:18 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=8, tm_min=25, tm_sec=18, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jason Wilson'}],\n",
       "   'author': 'Jason Wilson',\n",
       "   'author_detail': {'name': 'Jason Wilson'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Age of Wonders', 'scheme': None, 'label': None},\n",
       "    {'term': 'Age of Wonders: Planetfall', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Board Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games/Strategy Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Games/Roleplaying Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Paradox Interactive', 'scheme': None, 'label': None},\n",
       "    {'term': 'PDXCON 2019', 'scheme': None, 'label': None},\n",
       "    {'term': 'Triumph Studios', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540427',\n",
       "   'guidislink': False,\n",
       "   'summary': \"Age of Wonders: Planetfall's first expansion is Revelations, and it launches November 19 for PC, PlayStation 4, and Xbox One.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"Age of Wonders: Planetfall's first expansion is Revelations, and it launches November 19 for PC, PlayStation 4, and Xbox One.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<iframe class=\\'youtube-player\\' type=\\'text/html\\' width=\\'560\\' height=\\'315\\' src=\\'https://www.youtube.com/embed/YofuDirQaLo?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent\\' allowfullscreen=\\'true\\' style=\\'border:0;\\'></iframe><hr/>Age of Wonders: Planetfall\\'s first expansion is Revelations, and it launches November 19 for PC, PlayStation 4, and Xbox One.<a href=\"https://venturebeat.com/2019/10/19/age-of-wonders-planetfall-gets-its-first-expansion-is-revelations-launching-november-19/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/SzAB55UEp0Y\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/19/age-of-wonders-planetfall-gets-its-first-expansion-is-revelations-launching-november-19/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540427',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/19/age-of-wonders-planetfall-gets-its-first-expansion-is-revelations-launching-november-19/',\n",
       "    'title': 'Age of Wonders: Planetfall’s first expansion is Revelations, launching November 19'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/19/age-of-wonders-planetfall-gets-its-first-expansion-is-revelations-launching-november-19/'},\n",
       "  {'title': 'Huawei is in early talks about licensing 5G tech to U.S. firms',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Huawei is in early talks about licensing 5G tech to U.S. firms'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/WdwX2Y2wqOQ/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/WdwX2Y2wqOQ/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/huawei-is-in-early-talks-about-licensing-5g-tech-to-u-s-firms/#respond',\n",
       "   'published': 'Sat, 19 Oct 2019 04:55:45 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=4, tm_min=55, tm_sec=45, tm_wday=5, tm_yday=292, tm_isdst=0),\n",
       "   'authors': [{'name': 'Reuters'}],\n",
       "   'author': 'Reuters',\n",
       "   'author_detail': {'name': 'Reuters'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'Media', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'Security', 'scheme': None, 'label': None},\n",
       "    {'term': '5G', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Internet & Telecom/Mobile & Wireless',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/News', 'scheme': None, 'label': None},\n",
       "    {'term': 'China', 'scheme': None, 'label': None},\n",
       "    {'term': 'Huawei', 'scheme': None, 'label': None},\n",
       "    {'term': 'United States', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540506',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Blacklisted Chinese telecoms equipment giant Huawei is in early-stage talks with some U.S. telecoms companies about licensing its 5G network technology.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Blacklisted Chinese telecoms equipment giant Huawei is in early-stage talks with some U.S. telecoms companies about licensing its 5G network technology.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"The logo of Huawei Technologies is pictured in front of the German headquarters of the Chinese telecommunications giant in Duesseldorf, Germany, February 18, 2019.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=1200&amp;strip=all 1200w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=700&amp;strip=all 700w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Blacklisted Chinese telecoms equipment giant Huawei is in early-stage talks with some U.S. telecoms companies about licensing its 5G network technology.<a href=\"https://venturebeat.com/2019/10/18/huawei-is-in-early-talks-about-licensing-5g-tech-to-u-s-firms/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/WdwX2Y2wqOQ\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/huawei-is-in-early-talks-about-licensing-5g-tech-to-u-s-firms/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540506',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/huawei-is-in-early-talks-about-licensing-5g-tech-to-u-s-firms/',\n",
       "    'title': 'Huawei is in early talks about licensing 5G tech to U.S. firms'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/huawei-is-in-early-talks-about-licensing-5g-tech-to-u-s-firms/'},\n",
       "  {'title': '5 predictions for AI’s impact on customer experience in 2020 (VB Live)',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '5 predictions for AI’s impact on customer experience in 2020 (VB Live)'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/7k2oeQeN-0E/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/7k2oeQeN-0E/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/5-predictions-for-ais-impact-on-customer-experience-in-2020-vb-live/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 21:46:11 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=46, tm_sec=11, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'VB Staff'}],\n",
       "   'author': 'VB Staff',\n",
       "   'author_detail': {'name': 'VB Staff'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commerce', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'Entrepreneur', 'scheme': None, 'label': None},\n",
       "    {'term': 'Marketing', 'scheme': None, 'label': None},\n",
       "    {'term': 'ai', 'scheme': None, 'label': None},\n",
       "    {'term': 'artificial intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'Bold360 by LogMeIn', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Business & Industrial', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'customer engagement', 'scheme': None, 'label': None},\n",
       "    {'term': 'customer experience', 'scheme': None, 'label': None},\n",
       "    {'term': 'customer journey', 'scheme': None, 'label': None},\n",
       "    {'term': 'digital technology', 'scheme': None, 'label': None},\n",
       "    {'term': 'machine learning', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540444',\n",
       "   'guidislink': False,\n",
       "   'summary': \"Join this VB Live event for a look at the predictions that came true, the hype that fizzled, and what's next for the AI, CX, and chatbot technology.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"Join this VB Live event for a look at the predictions that came true, the hype that fizzled, and what's next for the AI, CX, and chatbot technology.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"303\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?fit=578%2C303&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=2115&amp;strip=all 2115w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=2000&amp;strip=all 2000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Join this VB Live event for a look at the predictions that came true, the hype that fizzled, and what\\'s next for the AI, CX, and chatbot technology.<a href=\"https://venturebeat.com/2019/10/18/5-predictions-for-ais-impact-on-customer-experience-in-2020-vb-live/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/7k2oeQeN-0E\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/5-predictions-for-ais-impact-on-customer-experience-in-2020-vb-live/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540444',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/5-predictions-for-ais-impact-on-customer-experience-in-2020-vb-live/',\n",
       "    'title': '5 predictions for AI’s impact on customer experience in 2020 (VB Live)'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/5-predictions-for-ais-impact-on-customer-experience-in-2020-vb-live/'},\n",
       "  {'title': 'Fortnite is finally getting better spatial audio',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Fortnite is finally getting better spatial audio'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/C4hbkSg_FG8/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/C4hbkSg_FG8/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/fortnite-spatial-audio/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 21:40:28 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=40, tm_sec=28, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jeff Grubb'}],\n",
       "   'author': 'Jeff Grubb',\n",
       "   'author_detail': {'name': 'Jeff Grubb'},\n",
       "   'tags': [{'term': 'Esports', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Consumer Electronics/Audio Equipment',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Epic Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'Fortnite', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540364',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Fortnite is getting one of its most important upgrades ever. Epic is adding spatial audio to the battle royale shooter to give players more tactical info.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Fortnite is getting one of its most important upgrades ever. Epic is adding spatial audio to the battle royale shooter to give players more tactical info.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<iframe class=\\'youtube-player\\' type=\\'text/html\\' width=\\'560\\' height=\\'315\\' src=\\'https://www.youtube.com/embed/WDUbxKGb2nY?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent\\' allowfullscreen=\\'true\\' style=\\'border:0;\\'></iframe><hr/>Fortnite is getting one of its most important upgrades ever. Epic is adding spatial audio to the battle royale shooter to give players more tactical info.<a href=\"https://venturebeat.com/2019/10/18/fortnite-spatial-audio/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/C4hbkSg_FG8\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/fortnite-spatial-audio/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540364',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/fortnite-spatial-audio/',\n",
       "    'title': 'Fortnite is finally getting better spatial audio'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/fortnite-spatial-audio/'},\n",
       "  {'title': 'The RetroBeat: Sonic & Knuckles turned a problem into success 25 years ago',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'The RetroBeat: Sonic & Knuckles turned a problem into success 25 years ago'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/IuvebmxLyx8/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/IuvebmxLyx8/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/the-retrobeat-sonic-knuckles-turned-a-problem-into-success-25-years-ago/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 21:02:29 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=2, tm_sec=29, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Minotti'}],\n",
       "   'author': 'Mike Minotti',\n",
       "   'author_detail': {'name': 'Mike Minotti'},\n",
       "   'tags': [{'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'console gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'retro gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Sega', 'scheme': None, 'label': None},\n",
       "    {'term': 'Sonic & Knuckles', 'scheme': None, 'label': None},\n",
       "    {'term': 'The RetroBeat', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540351',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Sonic &#038; Knuckles is what happens when you make the best out of a bad situation. The classic Genesis game is now 25 years old.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Sonic &#038; Knuckles is what happens when you make the best out of a bad situation. The classic Genesis game is now 25 years old.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"361\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?fit=578%2C361&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Sonic &amp; Knuckles.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=1280&amp;strip=all 1280w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Sonic & Knuckles is what happens when you make the best out of a bad situation. The classic Genesis game is now 25 years old.<a href=\"https://venturebeat.com/2019/10/18/the-retrobeat-sonic-knuckles-turned-a-problem-into-success-25-years-ago/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/IuvebmxLyx8\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/the-retrobeat-sonic-knuckles-turned-a-problem-into-success-25-years-ago/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540351',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/the-retrobeat-sonic-knuckles-turned-a-problem-into-success-25-years-ago/',\n",
       "    'title': 'The RetroBeat: Sonic & Knuckles turned a problem into success 25 years ago'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/the-retrobeat-sonic-knuckles-turned-a-problem-into-success-25-years-ago/'},\n",
       "  {'title': 'Researchers demo AR hand tracking controls for smartphones',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Researchers demo AR hand tracking controls for smartphones'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/5yIcZzB0k1I/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/5yIcZzB0k1I/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/researchers-demo-ar-hand-tracking-controls-for-smartphones/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 21:00:04 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=21, tm_min=0, tm_sec=4, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jeremy Horwitz'}],\n",
       "   'author': 'Jeremy Horwitz',\n",
       "   'author_detail': {'name': 'Jeremy Horwitz'},\n",
       "   'tags': [{'term': 'AR/VR', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'augmented reality', 'scheme': None, 'label': None},\n",
       "    {'term': 'Brown', 'scheme': None, 'label': None},\n",
       "    {'term': 'Brown UCI', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Consumer Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Internet & Telecom/Mobile & Wireless/Mobile Phones',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Portal-ble', 'scheme': None, 'label': None},\n",
       "    {'term': 'smartphone', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540429',\n",
       "   'guidislink': False,\n",
       "   'summary': 'A group of Brown University researchers wants to bring hand tracking to smartphone augmented reality using off-the-shelf hardware and open source software.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'A group of Brown University researchers wants to bring hand tracking to smartphone augmented reality using off-the-shelf hardware and open source software.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"263\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/portalble-e1571431845492.jpg?fit=578%2C263&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/portalble-e1571431845492.jpg?zoom=2&amp;resize=578%2C263&amp;strip=all 1156w, https://venturebeat.com/wp-content/uploads/2019/10/portalble-e1571431845492.jpg?zoom=3&amp;resize=578%2C263&amp;strip=all 1734w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>A group of Brown University researchers wants to bring hand tracking to smartphone augmented reality using off-the-shelf hardware and open source software.<a href=\"https://venturebeat.com/2019/10/18/researchers-demo-ar-hand-tracking-controls-for-smartphones/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/5yIcZzB0k1I\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/researchers-demo-ar-hand-tracking-controls-for-smartphones/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540429',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/researchers-demo-ar-hand-tracking-controls-for-smartphones/',\n",
       "    'title': 'Researchers demo AR hand tracking controls for smartphones'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/researchers-demo-ar-hand-tracking-controls-for-smartphones/'},\n",
       "  {'title': 'Bipartisan group condemns Blizzard and Apple for bowing to China',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Bipartisan group condemns Blizzard and Apple for bowing to China'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/9DdbFykkNRY/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/9DdbFykkNRY/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/bipartisan-group-condemns-blizzard-and-apple-for-kowtowing-to-china/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 20:33:32 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=20, tm_min=33, tm_sec=32, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jeff Grubb'}],\n",
       "   'author': 'Jeff Grubb',\n",
       "   'author_detail': {'name': 'Jeff Grubb'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Esports', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Activision Blizzard', 'scheme': None, 'label': None},\n",
       "    {'term': 'Alexandria Ocasio-Cortez', 'scheme': None, 'label': None},\n",
       "    {'term': 'Apple', 'scheme': None, 'label': None},\n",
       "    {'term': 'Blizzard Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'Bobby Kotick', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/News', 'scheme': None, 'label': None},\n",
       "    {'term': 'China', 'scheme': None, 'label': None},\n",
       "    {'term': 'J. Allen Brack', 'scheme': None, 'label': None},\n",
       "    {'term': 'Marco Rubio', 'scheme': None, 'label': None},\n",
       "    {'term': 'Ron Wyden', 'scheme': None, 'label': None},\n",
       "    {'term': 'Tim Cook', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540422',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Biparitsan group condemns Blizzard and Apple for making moves at the behest of the Chinese government in relation to Hong Kong.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Biparitsan group condemns Blizzard and Apple for making moves at the behest of the Chinese government in relation to Hong Kong.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Congress is asking Blizzard and Apple to stop helping China.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=1600&amp;strip=all 1600w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Biparitsan group condemns Blizzard and Apple for making moves at the behest of the Chinese government in relation to Hong Kong.<a href=\"https://venturebeat.com/2019/10/18/bipartisan-group-condemns-blizzard-and-apple-for-kowtowing-to-china/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/9DdbFykkNRY\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/bipartisan-group-condemns-blizzard-and-apple-for-kowtowing-to-china/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540422',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/bipartisan-group-condemns-blizzard-and-apple-for-kowtowing-to-china/',\n",
       "    'title': 'Bipartisan group condemns Blizzard and Apple for bowing to China'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/bipartisan-group-condemns-blizzard-and-apple-for-kowtowing-to-china/'},\n",
       "  {'title': 'AI Weekly: Why Google still needs the cloud even with on-device ML',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'AI Weekly: Why Google still needs the cloud even with on-device ML'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/k38EH-HHPlA/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/k38EH-HHPlA/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/ai-weekly-why-google-still-needs-the-cloud-even-with-on-device-ml/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 19:59:04 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=59, tm_sec=4, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Khari Johnson'}],\n",
       "   'author': 'Khari Johnson',\n",
       "   'author_detail': {'name': 'Khari Johnson'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Dev', 'scheme': None, 'label': None},\n",
       "    {'term': 'Media', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'Security', 'scheme': None, 'label': None},\n",
       "    {'term': 'artificial intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Software',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Internet & Telecom', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Science', 'scheme': None, 'label': None},\n",
       "    {'term': 'edge computing', 'scheme': None, 'label': None},\n",
       "    {'term': 'Google Assistant', 'scheme': None, 'label': None},\n",
       "    {'term': 'on-device machine learning', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540401',\n",
       "   'guidislink': False,\n",
       "   'summary': \"Google is giving more hardware dedicated chips for on-device machine learning, but services like Google Assistant still rely on the cloud. Here's why.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"Google is giving more hardware dedicated chips for on-device machine learning, but services like Google Assistant still rely on the cloud. Here's why.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Google\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=1800&amp;strip=all 1800w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Google is giving more hardware dedicated chips for on-device machine learning, but services like Google Assistant still rely on the cloud. Here\\'s why.<a href=\"https://venturebeat.com/2019/10/18/ai-weekly-why-google-still-needs-the-cloud-even-with-on-device-ml/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/k38EH-HHPlA\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/ai-weekly-why-google-still-needs-the-cloud-even-with-on-device-ml/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540401',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/ai-weekly-why-google-still-needs-the-cloud-even-with-on-device-ml/',\n",
       "    'title': 'AI Weekly: Why Google still needs the cloud even with on-device ML'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/ai-weekly-why-google-still-needs-the-cloud-even-with-on-device-ml/'},\n",
       "  {'title': 'NVMe vs. SATA, Part 2: Industry insider interview',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'NVMe vs. SATA, Part 2: Industry insider interview'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/EV9lM781vvE/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/EV9lM781vvE/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-part-2-industry-insider-interview/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 19:38:55 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=38, tm_sec=55, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'William Van Winkle'}],\n",
       "   'author': 'William Van Winkle',\n",
       "   'author_detail': {'name': 'William Van Winkle'},\n",
       "   'tags': [{'term': 'Big Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Computer Hardware/Computer Drives & Storage',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'enterprise storage', 'scheme': None, 'label': None},\n",
       "    {'term': 'NVMe', 'scheme': None, 'label': None},\n",
       "    {'term': 'SATA', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540078',\n",
       "   'guidislink': False,\n",
       "   'summary': \"The NVM Express specification for solid state drives arrived eight years ago. So\\xa0where’s all the adoption? Western Digital's Eric Pike explores.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"The NVM Express specification for solid state drives arrived eight years ago. So\\xa0where’s all the adoption? Western Digital's Eric Pike explores.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"548\" height=\"307\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?fit=548%2C307&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?w=548&amp;strip=all 548w, https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?w=400&amp;strip=all 400w\" sizes=\"(max-width: 548px) 100vw, 548px\" /><hr/>The NVM Express specification for solid state drives arrived eight years ago. So\\xa0where’s all the adoption? Western Digital\\'s Eric Pike explores.<a href=\"https://venturebeat.com/2019/10/18/nvme-vs-sata-part-2-industry-insider-interview/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/EV9lM781vvE\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-part-2-industry-insider-interview/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540078',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-part-2-industry-insider-interview/',\n",
       "    'title': 'NVMe vs. SATA, Part 2: Industry insider interview'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-part-2-industry-insider-interview/'},\n",
       "  {'title': 'NVMe vs. SATA: Which NAND storage do you need?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'NVMe vs. SATA: Which NAND storage do you need?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/eAjnXyxG-xE/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/eAjnXyxG-xE/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-which-nand-storage-do-you-need/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 19:36:51 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=36, tm_sec=51, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'William Van Winkle'}],\n",
       "   'author': 'William Van Winkle',\n",
       "   'author_detail': {'name': 'William Van Winkle'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Computer Hardware/Computer Drives & Storage',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'enterprise storage', 'scheme': None, 'label': None},\n",
       "    {'term': 'M.2', 'scheme': None, 'label': None},\n",
       "    {'term': 'NAND', 'scheme': None, 'label': None},\n",
       "    {'term': 'NVMe', 'scheme': None, 'label': None},\n",
       "    {'term': 'PCI Express', 'scheme': None, 'label': None},\n",
       "    {'term': 'PCIe', 'scheme': None, 'label': None},\n",
       "    {'term': 'SATA', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540066',\n",
       "   'guidislink': False,\n",
       "   'summary': \"For workstations and servers, it's getting hard not to justify the relatively low price/premium for NVMe versus the older SATA.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"For workstations and servers, it's getting hard not to justify the relatively low price/premium for NVMe versus the older SATA.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"299\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?fit=578%2C299&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=9939&amp;strip=all 9939w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=3000&amp;strip=all 3000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>For workstations and servers, it\\'s getting hard not to justify the relatively low price/premium for NVMe versus the older SATA.<a href=\"https://venturebeat.com/2019/10/18/nvme-vs-sata-which-nand-storage-do-you-need/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/eAjnXyxG-xE\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-which-nand-storage-do-you-need/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540066',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-which-nand-storage-do-you-need/',\n",
       "    'title': 'NVMe vs. SATA: Which NAND storage do you need?'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/nvme-vs-sata-which-nand-storage-do-you-need/'},\n",
       "  {'title': 'Today’s 4G LTE puts you on the pathway to tomorrow’s 5G',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Today’s 4G LTE puts you on the pathway to tomorrow’s 5G'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/H1BKf_FsV9c/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/H1BKf_FsV9c/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/todays-4g-lte-puts-you-on-the-pathway-to-tomorrows-5g/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 19:34:43 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=34, tm_sec=43, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Chris Angelini'}],\n",
       "   'author': 'Chris Angelini',\n",
       "   'author_detail': {'name': 'Chris Angelini'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': '4G LTE', 'scheme': None, 'label': None},\n",
       "    {'term': '5G', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI. artificial intelligence', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Internet & Telecom/Mobile & Wireless',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Internet & Telecom/Service Providers',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'cloud computing', 'scheme': None, 'label': None},\n",
       "    {'term': 'edge computing', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2539869',\n",
       "   'guidislink': False,\n",
       "   'summary': 'There’s a pathway to 5G that promises much of the technology’s value on existing 4G LTE networks for those who make the right upgrades.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'There’s a pathway to 5G that promises much of the technology’s value on existing 4G LTE networks for those who make the right upgrades.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"326\" src=\"https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?fit=578%2C326&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"A 5G sign is seen during the Mobile World Congress in Barcelona, Spain February 28, 2018.\" srcset=\"https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>There’s a pathway to 5G that promises much of the technology’s value on existing 4G LTE networks for those who make the right upgrades.<a href=\"https://venturebeat.com/2019/10/18/todays-4g-lte-puts-you-on-the-pathway-to-tomorrows-5g/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/H1BKf_FsV9c\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/todays-4g-lte-puts-you-on-the-pathway-to-tomorrows-5g/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2539869',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/todays-4g-lte-puts-you-on-the-pathway-to-tomorrows-5g/',\n",
       "    'title': 'Today’s 4G LTE puts you on the pathway to tomorrow’s 5G'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/todays-4g-lte-puts-you-on-the-pathway-to-tomorrows-5g/'},\n",
       "  {'title': 'Jedi: Fallen Order — The satisfaction of creating new Star Wars canon',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Jedi: Fallen Order — The satisfaction of creating new Star Wars canon'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/Fn5epBsAsfc/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/Fn5epBsAsfc/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/jedi-fallen-order-the-satisfaction-of-creating-new-star-wars-canon/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 19:30:16 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=19, tm_min=30, tm_sec=16, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Mike Minotti'}],\n",
       "   'author': 'Mike Minotti',\n",
       "   'author_detail': {'name': 'Mike Minotti'},\n",
       "   'tags': [{'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Arts & Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'console gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Electronic Arts', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Respawn Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'Star Wars: Jedi -- Fallen Order',\n",
       "     'scheme': None,\n",
       "     'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540302',\n",
       "   'guidislink': False,\n",
       "   'summary': 'After a long demo, I got a chance to talk with Respawn about the fun and challenge of creating its own slice of Star Wars material.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'After a long demo, I got a chance to talk with Respawn about the fun and challenge of creating its own slice of Star Wars material.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"325\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?fit=578%2C325&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"A Jedi and his droid.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=3840&amp;strip=all 3840w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=3000&amp;strip=all 3000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>After a long demo, I got a chance to talk with Respawn about the fun and challenge of creating its own slice of Star Wars material.<a href=\"https://venturebeat.com/2019/10/18/jedi-fallen-order-the-satisfaction-of-creating-new-star-wars-canon/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/Fn5epBsAsfc\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/jedi-fallen-order-the-satisfaction-of-creating-new-star-wars-canon/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540302',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/jedi-fallen-order-the-satisfaction-of-creating-new-star-wars-canon/',\n",
       "    'title': 'Jedi: Fallen Order — The satisfaction of creating new Star Wars canon'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/jedi-fallen-order-the-satisfaction-of-creating-new-star-wars-canon/'},\n",
       "  {'title': 'Wing launches drone delivery in Christiansburg, Virginia',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Wing launches drone delivery in Christiansburg, Virginia'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/5AecPUZEW30/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/5AecPUZEW30/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/wing-launches-drone-delivery-in-christiansburg-virginia/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 18:47:46 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=18, tm_min=47, tm_sec=46, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Kyle Wiggers'}],\n",
       "   'author': 'Kyle Wiggers',\n",
       "   'author_detail': {'name': 'Kyle Wiggers'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'Big Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Commerce', 'scheme': None, 'label': None},\n",
       "    {'term': 'Dev', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'Entrepreneur', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'Transportation', 'scheme': None, 'label': None},\n",
       "    {'term': 'Alphabet', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Business & Industrial', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Consumer Electronics/Drones & RC Aircraft',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Hobbies & Leisure', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Travel/Air Travel', 'scheme': None, 'label': None},\n",
       "    {'term': 'commercial drone', 'scheme': None, 'label': None},\n",
       "    {'term': 'delivery', 'scheme': None, 'label': None},\n",
       "    {'term': 'drone', 'scheme': None, 'label': None},\n",
       "    {'term': 'Wing', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540346',\n",
       "   'guidislink': False,\n",
       "   'summary': \"Google parent company Alphabet's Wing today said that it's kicked off a drone delivery pilot in Virginia for select residents.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"Google parent company Alphabet's Wing today said that it's kicked off a drone delivery pilot in Virginia for select residents.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<iframe class=\\'youtube-player\\' type=\\'text/html\\' width=\\'560\\' height=\\'315\\' src=\\'https://www.youtube.com/embed/wCTKwkYzVzo?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent\\' allowfullscreen=\\'true\\' style=\\'border:0;\\'></iframe><hr/>Google parent company Alphabet\\'s Wing today said that it\\'s kicked off a drone delivery pilot in Virginia for select residents.<a href=\"https://venturebeat.com/2019/10/18/wing-launches-drone-delivery-in-christiansburg-virginia/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/5AecPUZEW30\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/wing-launches-drone-delivery-in-christiansburg-virginia/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540346',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/wing-launches-drone-delivery-in-christiansburg-virginia/',\n",
       "    'title': 'Wing launches drone delivery in Christiansburg, Virginia'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/wing-launches-drone-delivery-in-christiansburg-virginia/'},\n",
       "  {'title': 'Verizon debuts GPU-based 5G edge services for mobile VR/XR developers',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Verizon debuts GPU-based 5G edge services for mobile VR/XR developers'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/rpZ6BCGkIz0/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/rpZ6BCGkIz0/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/verizon-debuts-gpu-based-5g-edge-services-for-mobile-vr-xr-developers/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 18:40:55 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=18, tm_min=40, tm_sec=55, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jeremy Horwitz'}],\n",
       "   'author': 'Jeremy Horwitz',\n",
       "   'author_detail': {'name': 'Jeremy Horwitz'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'AR/VR', 'scheme': None, 'label': None},\n",
       "    {'term': 'Cloud', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': '5G', 'scheme': None, 'label': None},\n",
       "    {'term': '5G edge', 'scheme': None, 'label': None},\n",
       "    {'term': '5G Network', 'scheme': None, 'label': None},\n",
       "    {'term': 'AR', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Consumer Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'category-/Internet & Telecom/Mobile & Wireless',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'cloud', 'scheme': None, 'label': None},\n",
       "    {'term': 'Edge', 'scheme': None, 'label': None},\n",
       "    {'term': 'edge cloud', 'scheme': None, 'label': None},\n",
       "    {'term': 'GPU', 'scheme': None, 'label': None},\n",
       "    {'term': 'Verizon', 'scheme': None, 'label': None},\n",
       "    {'term': 'VR', 'scheme': None, 'label': None},\n",
       "    {'term': 'XR', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540333',\n",
       "   'guidislink': False,\n",
       "   'summary': '5G is about to make better use of GPUs than ever before, thanks to innovations that will enable multiple users to share cloud-based graphics hardware.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': '5G is about to make better use of GPUs than ever before, thanks to innovations that will enable multiple users to share cloud-based graphics hardware.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"325\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/verizon5gvr-e1571423723684.jpg?fit=578%2C325&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Verizon&#039;s Envrmnt develops 5G network-ready XR technologies, including interactive realtime lighting service that makes digital objects blend into their real environments.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/verizon5gvr-e1571423723684.jpg?zoom=2&amp;resize=578%2C325&amp;strip=all 1156w, https://venturebeat.com/wp-content/uploads/2019/10/verizon5gvr-e1571423723684.jpg?zoom=3&amp;resize=578%2C325&amp;strip=all 1734w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>5G is about to make better use of GPUs than ever before, thanks to innovations that will enable multiple users to share cloud-based graphics hardware.<a href=\"https://venturebeat.com/2019/10/18/verizon-debuts-gpu-based-5g-edge-services-for-mobile-vr-xr-developers/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/rpZ6BCGkIz0\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/verizon-debuts-gpu-based-5g-edge-services-for-mobile-vr-xr-developers/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540333',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/verizon-debuts-gpu-based-5g-edge-services-for-mobile-vr-xr-developers/',\n",
       "    'title': 'Verizon debuts GPU-based 5G edge services for mobile VR/XR developers'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/verizon-debuts-gpu-based-5g-edge-services-for-mobile-vr-xr-developers/'},\n",
       "  {'title': 'ProBeat: Google’s Pixel 4 ups the AI ante to offline language models',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'ProBeat: Google’s Pixel 4 ups the AI ante to offline language models'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/wgH-Ny3vjbc/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/wgH-Ny3vjbc/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/probeat-googles-pixel-4-ups-the-ai-ante-to-offline-language-models/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 17:30:40 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=17, tm_min=30, tm_sec=40, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Emil Protalinski'}],\n",
       "   'author': 'Emil Protalinski',\n",
       "   'author_detail': {'name': 'Emil Protalinski'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Dev', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'Media', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'Android', 'scheme': None, 'label': None},\n",
       "    {'term': 'Android 10', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Google', 'scheme': None, 'label': None},\n",
       "    {'term': 'Google 2019 hardware event', 'scheme': None, 'label': None},\n",
       "    {'term': 'Google Pixel 4', 'scheme': None, 'label': None},\n",
       "    {'term': 'Google Pixel 4 XL', 'scheme': None, 'label': None},\n",
       "    {'term': 'Live Caption', 'scheme': None, 'label': None},\n",
       "    {'term': 'Pixel 4', 'scheme': None, 'label': None},\n",
       "    {'term': 'Pixel 4 XL', 'scheme': None, 'label': None},\n",
       "    {'term': 'ProBeat', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2539041',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Live Caption and Recorder on the Pixel 4 and Pixel 4 XL show that Google wants to rule offline natural language processing.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Live Caption and Recorder on the Pixel 4 and Pixel 4 XL show that Google wants to rule offline natural language processing.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<iframe class=\\'youtube-player\\' type=\\'text/html\\' width=\\'560\\' height=\\'315\\' src=\\'https://www.youtube.com/embed/v8cLk2W3vY8?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent\\' allowfullscreen=\\'true\\' style=\\'border:0;\\'></iframe><hr/>Live Caption and Recorder on the Pixel 4 and Pixel 4 XL show that Google wants to rule offline natural language processing.<a href=\"https://venturebeat.com/2019/10/18/probeat-googles-pixel-4-ups-the-ai-ante-to-offline-language-models/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/wgH-Ny3vjbc\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/probeat-googles-pixel-4-ups-the-ai-ante-to-offline-language-models/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2539041',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/probeat-googles-pixel-4-ups-the-ai-ante-to-offline-language-models/',\n",
       "    'title': 'ProBeat: Google’s Pixel 4 ups the AI ante to offline language models'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/probeat-googles-pixel-4-ups-the-ai-ante-to-offline-language-models/'},\n",
       "  {'title': 'Hands-on: Roku’s Apple TV app helped me cut the cord — from Apple',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Hands-on: Roku’s Apple TV app helped me cut the cord — from Apple'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/zPJLywnvt64/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/zPJLywnvt64/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/hands-on-rokus-apple-tv-app-helped-me-cut-the-cord-from-apple/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 16:33:07 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=16, tm_min=33, tm_sec=7, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jeremy Horwitz'}],\n",
       "   'author': 'Jeremy Horwitz',\n",
       "   'author_detail': {'name': 'Jeremy Horwitz'},\n",
       "   'tags': [{'term': 'Media', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'app', 'scheme': None, 'label': None},\n",
       "    {'term': 'Apple', 'scheme': None, 'label': None},\n",
       "    {'term': 'Apple TV', 'scheme': None, 'label': None},\n",
       "    {'term': 'Apple TV App', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Computers & Electronics/Consumer Electronics',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'cord-cutting', 'scheme': None, 'label': None},\n",
       "    {'term': 'Roku', 'scheme': None, 'label': None},\n",
       "    {'term': 'Roku TV', 'scheme': None, 'label': None},\n",
       "    {'term': 'Samsung', 'scheme': None, 'label': None},\n",
       "    {'term': 'subscription service', 'scheme': None, 'label': None},\n",
       "    {'term': 'TCL', 'scheme': None, 'label': None},\n",
       "    {'term': 'TV app', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540274',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Apple TV devices were designed to help users cut the cord from cable companies. Now an Apple TV app for Roku lets users cut the cord with Apple hardware.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Apple TV devices were designed to help users cut the cord from cable companies. Now an Apple TV app for Roku lets users cut the cord with Apple hardware.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=1254&amp;strip=all 1254w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=700&amp;strip=all 700w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Apple TV devices were designed to help users cut the cord from cable companies. Now an Apple TV app for Roku lets users cut the cord with Apple hardware.<a href=\"https://venturebeat.com/2019/10/18/hands-on-rokus-apple-tv-app-helped-me-cut-the-cord-from-apple/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/zPJLywnvt64\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/hands-on-rokus-apple-tv-app-helped-me-cut-the-cord-from-apple/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540274',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/hands-on-rokus-apple-tv-app-helped-me-cut-the-cord-from-apple/',\n",
       "    'title': 'Hands-on: Roku’s Apple TV app helped me cut the cord — from Apple'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/hands-on-rokus-apple-tv-app-helped-me-cut-the-cord-from-apple/'},\n",
       "  {'title': 'Electronic Theatre brings immersive group gaming to physical rooms',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Electronic Theatre brings immersive group gaming to physical rooms'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/Ue2TTcQOSg4/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/Ue2TTcQOSg4/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/electronic-theatre-brings-immersive-group-gaming-to-physical-rooms/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 15:16:27 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=15, tm_min=16, tm_sec=27, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Paul Sawers'}],\n",
       "   'author': 'Paul Sawers',\n",
       "   'author_detail': {'name': 'Paul Sawers'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Entrepreneur', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'Media', 'scheme': None, 'label': None},\n",
       "    {'term': 'Social', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'Electronic Theater', 'scheme': None, 'label': None},\n",
       "    {'term': 'Electronic Theatre', 'scheme': None, 'label': None},\n",
       "    {'term': 'Tough Mudder', 'scheme': None, 'label': None},\n",
       "    {'term': 'Will Dean', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2539990',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Will Dean is known as the creator of Tough Mudder. Now, he has gone digital with Electronic Theatre -- immersive group gaming experiences in physical rooms.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Will Dean is known as the creator of Tough Mudder. Now, he has gone digital with Electronic Theatre -- immersive group gaming experiences in physical rooms.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"360\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?fit=578%2C360&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Electronic Theatre\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=1296&amp;strip=all 1296w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Will Dean is known as the creator of Tough Mudder. Now, he has gone digital with Electronic Theatre -- immersive group gaming experiences in physical rooms.<a href=\"https://venturebeat.com/2019/10/18/electronic-theatre-brings-immersive-group-gaming-to-physical-rooms/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/Ue2TTcQOSg4\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/electronic-theatre-brings-immersive-group-gaming-to-physical-rooms/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2539990',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/electronic-theatre-brings-immersive-group-gaming-to-physical-rooms/',\n",
       "    'title': 'Electronic Theatre brings immersive group gaming to physical rooms'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/electronic-theatre-brings-immersive-group-gaming-to-physical-rooms/'},\n",
       "  {'title': 'GamesBeat Decides 128: Star Wars Jedi: Fallen Order rules',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'GamesBeat Decides 128: Star Wars Jedi: Fallen Order rules'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/Z5L1aTFRMow/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/Z5L1aTFRMow/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/gamesbeat-decides-128-jedi-fallen-order/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 15:06:29 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=15, tm_min=6, tm_sec=29, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jeff Grubb'}],\n",
       "   'author': 'Jeff Grubb',\n",
       "   'author_detail': {'name': 'Jeff Grubb'},\n",
       "   'tags': [{'term': 'AR/VR', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Esports', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'Mobile', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Arts & Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'DeanBeat Flair and Opinion', 'scheme': None, 'label': None},\n",
       "    {'term': 'GamesBeat Decides', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'podcast', 'scheme': None, 'label': None},\n",
       "    {'term': 'Respawn Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'Star Wars: Jedi -- Fallen Order',\n",
       "     'scheme': None,\n",
       "     'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540277',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Star Wars Jedi: Fallen Order is a potentailly excellent entry in the long history of the series. We played the first 3.5 hours. Listen to our thoughts.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Star Wars Jedi: Fallen Order is a potentailly excellent entry in the long history of the series. We played the first 3.5 hours. Listen to our thoughts.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"325\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?fit=578%2C325&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"A good &#039;Star Wars&#039; game? Yes, please.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=1280&amp;strip=all 1280w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Star Wars Jedi: Fallen Order is a potentailly excellent entry in the long history of the series. We played the first 3.5 hours. Listen to our thoughts.<a href=\"https://venturebeat.com/2019/10/18/gamesbeat-decides-128-jedi-fallen-order/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/Z5L1aTFRMow\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/gamesbeat-decides-128-jedi-fallen-order/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540277',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/gamesbeat-decides-128-jedi-fallen-order/',\n",
       "    'title': 'GamesBeat Decides 128: Star Wars Jedi: Fallen Order rules'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/gamesbeat-decides-128-jedi-fallen-order/'},\n",
       "  {'title': 'The DeanBeat: Riot Games sheds its image as a single-game company',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'The DeanBeat: Riot Games sheds its image as a single-game company'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/qy36ZT4vCC4/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/qy36ZT4vCC4/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/the-deanbeat-riot-games-sheds-its-image-as-a-single-game-company/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 15:00:45 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=15, tm_min=0, tm_sec=45, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Dean Takahashi'}],\n",
       "   'author': 'Dean Takahashi',\n",
       "   'author_detail': {'name': 'Dean Takahashi'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Esports', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Arcane', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Arts & Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games/Strategy Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'League of Legends', 'scheme': None, 'label': None},\n",
       "    {'term': 'League of Legends: Wild Rift', 'scheme': None, 'label': None},\n",
       "    {'term': 'Legends of Runeterra', 'scheme': None, 'label': None},\n",
       "    {'term': 'Marc Merrill', 'scheme': None, 'label': None},\n",
       "    {'term': 'MOBA', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Riot Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'Team Fight Tactics', 'scheme': None, 'label': None},\n",
       "    {'term': 'The DeanBeat', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540210',\n",
       "   'guidislink': False,\n",
       "   'summary': \"Riot Games announced on its 10th anniversary that it created new games, films, and animated series in the hopes of overcoming The Innovator's Dilemma.\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"Riot Games announced on its 10th anniversary that it created new games, films, and animated series in the hopes of overcoming The Innovator's Dilemma.\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"321\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?fit=578%2C321&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Marc Merrill (left) and Brandon Beck started Riot Games in 2006.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=1134&amp;strip=all 1134w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Riot Games announced on its 10th anniversary that it created new games, films, and animated series in the hopes of overcoming The Innovator\\'s Dilemma.<a href=\"https://venturebeat.com/2019/10/18/the-deanbeat-riot-games-sheds-its-image-as-a-single-game-company/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/qy36ZT4vCC4\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/the-deanbeat-riot-games-sheds-its-image-as-a-single-game-company/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540210',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/the-deanbeat-riot-games-sheds-its-image-as-a-single-game-company/',\n",
       "    'title': 'The DeanBeat: Riot Games sheds its image as a single-game company'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/the-deanbeat-riot-games-sheds-its-image-as-a-single-game-company/'},\n",
       "  {'title': 'Here’s how to\\xa0blow everyone’s minds with your company’s AI product at Transform 2020',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Here’s how to\\xa0blow everyone’s minds with your company’s AI product at Transform 2020'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/R2EC0TS_jMw/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/R2EC0TS_jMw/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/heres-how-to-blow-everyones-minds-with-your-companys-ai-product-at-transform-2020/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 14:50:48 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=14, tm_min=50, tm_sec=48, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'VB Staff'}],\n",
       "   'author': 'VB Staff',\n",
       "   'author_detail': {'name': 'VB Staff'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'Big Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Dev', 'scheme': None, 'label': None},\n",
       "    {'term': 'Entrepreneur', 'scheme': None, 'label': None},\n",
       "    {'term': 'ai conferences', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI events', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Business & Industrial', 'scheme': None, 'label': None},\n",
       "    {'term': 'Transform 2020', 'scheme': None, 'label': None},\n",
       "    {'term': 'Transform technology showcase', 'scheme': None, 'label': None},\n",
       "    {'term': 'VB Transform 2020', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2540182',\n",
       "   'guidislink': False,\n",
       "   'summary': 'If you think your AI product is groundbreaking and delivers real-world results, you could be one of 14 companies on the main stage at Transform 2020.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'If you think your AI product is groundbreaking and delivers real-world results, you could be one of 14 companies on the main stage at Transform 2020.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"290\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?fit=578%2C290&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"#VBTransform @VentureBeat Brainworks, Dr. Philip Alvelda, Founder\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=6441&amp;strip=all 6441w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=700&amp;strip=all 700w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=3000&amp;strip=all 3000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>If you think your AI product is groundbreaking and delivers real-world results, you could be one of 14 companies on the main stage at Transform 2020.<a href=\"https://venturebeat.com/2019/10/18/heres-how-to-blow-everyones-minds-with-your-companys-ai-product-at-transform-2020/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/R2EC0TS_jMw\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/heres-how-to-blow-everyones-minds-with-your-companys-ai-product-at-transform-2020/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2540182',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/heres-how-to-blow-everyones-minds-with-your-companys-ai-product-at-transform-2020/',\n",
       "    'title': 'Here’s how to\\xa0blow everyone’s minds with your company’s AI product at Transform 2020'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/heres-how-to-blow-everyones-minds-with-your-companys-ai-product-at-transform-2020/'},\n",
       "  {'title': 'Saber Interactive buys Bigmoon Entertainment, announces two new projects',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Saber Interactive buys Bigmoon Entertainment, announces two new projects'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/pYR-KxvqLY0/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/pYR-KxvqLY0/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/saber-interactive-buys-bigmoon-entertainment-announces-two-new-projects/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 14:00:17 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=14, tm_min=0, tm_sec=17, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Jason Wilson'}],\n",
       "   'author': 'Jason Wilson',\n",
       "   'author_detail': {'name': 'Jason Wilson'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'Bigmoon Entertainment', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Sports/Team Sports', 'scheme': None, 'label': None},\n",
       "    {'term': 'Dakar 18', 'scheme': None, 'label': None},\n",
       "    {'term': 'DeanBeat News', 'scheme': None, 'label': None},\n",
       "    {'term': 'Saber Interactive', 'scheme': None, 'label': None},\n",
       "    {'term': 'World War Z', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2538957',\n",
       "   'guidislink': False,\n",
       "   'summary': \"Saber Interactive announces today that it's buying Bigmoon Entertainment, the makers of games such as Dakar 18, Demons Age, and Police Simulator: Patrol Duty\",\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': \"Saber Interactive announces today that it's buying Bigmoon Entertainment, the makers of games such as Dakar 18, Demons Age, and Police Simulator: Patrol Duty\"},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Saber Interactive adds Bigmoon Entertainment to its stable.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=1200&amp;strip=all 1200w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=700&amp;strip=all 700w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Saber Interactive announces today that it\\'s buying Bigmoon Entertainment, the makers of games such as Dakar 18, Demons Age, and Police Simulator: Patrol Duty<a href=\"https://venturebeat.com/2019/10/18/saber-interactive-buys-bigmoon-entertainment-announces-two-new-projects/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/pYR-KxvqLY0\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/saber-interactive-buys-bigmoon-entertainment-announces-two-new-projects/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2538957',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/saber-interactive-buys-bigmoon-entertainment-announces-two-new-projects/',\n",
       "    'title': 'Saber Interactive buys Bigmoon Entertainment, announces two new projects'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/saber-interactive-buys-bigmoon-entertainment-announces-two-new-projects/'},\n",
       "  {'title': 'Call of Duty League: How Activision reimagined its city-based esports structure',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Call of Duty League: How Activision reimagined its city-based esports structure'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/kWeSFuYlqwo/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/kWeSFuYlqwo/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/call-of-duty-league-how-activision-reimagined-its-city-based-esports-structure/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 13:00:38 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=13, tm_min=0, tm_sec=38, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Dean Takahashi'}],\n",
       "   'author': 'Dean Takahashi',\n",
       "   'author_detail': {'name': 'Dean Takahashi'},\n",
       "   'tags': [{'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Esports', 'scheme': None, 'label': None},\n",
       "    {'term': 'Games', 'scheme': None, 'label': None},\n",
       "    {'term': 'PC Gaming', 'scheme': None, 'label': None},\n",
       "    {'term': 'activision', 'scheme': None, 'label': None},\n",
       "    {'term': 'Activision Blizzard', 'scheme': None, 'label': None},\n",
       "    {'term': 'Call of Duty League', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Games/Computer & Video Games/Sports Games',\n",
       "     'scheme': None,\n",
       "     'label': None},\n",
       "    {'term': 'Johanna Faries', 'scheme': None, 'label': None},\n",
       "    {'term': 'Overwatch League', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2539797',\n",
       "   'guidislink': False,\n",
       "   'summary': 'Taking lessons from the success of the Overwatch League, Activision has revamped the structure of its esports competition in the Call of Duty League.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'Taking lessons from the success of the Overwatch League, Activision has revamped the structure of its esports competition in the Call of Duty League.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"321\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?fit=578%2C321&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Call of Duty League\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=1486&amp;strip=all 1486w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Taking lessons from the success of the Overwatch League, Activision has revamped the structure of its esports competition in the Call of Duty League.<a href=\"https://venturebeat.com/2019/10/18/call-of-duty-league-how-activision-reimagined-its-city-based-esports-structure/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/kWeSFuYlqwo\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/call-of-duty-league-how-activision-reimagined-its-city-based-esports-structure/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2539797',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/call-of-duty-league-how-activision-reimagined-its-city-based-esports-structure/',\n",
       "    'title': 'Call of Duty League: How Activision reimagined its city-based esports structure'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/call-of-duty-league-how-activision-reimagined-its-city-based-esports-structure/'},\n",
       "  {'title': 'How does society create an ethics guide for AI?',\n",
       "   'title_detail': {'type': 'text/plain',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'How does society create an ethics guide for AI?'},\n",
       "   'links': [{'rel': 'alternate',\n",
       "     'type': 'text/html',\n",
       "     'href': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/AJOcW7--1uw/'}],\n",
       "   'link': 'http://feedproxy.google.com/~r/venturebeat/SZYF/~3/AJOcW7--1uw/',\n",
       "   'comments': 'https://venturebeat.com/2019/10/18/how-does-society-create-an-ethics-guide-for-ai/#respond',\n",
       "   'published': 'Fri, 18 Oct 2019 11:10:23 +0000',\n",
       "   'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=18, tm_hour=11, tm_min=10, tm_sec=23, tm_wday=4, tm_yday=291, tm_isdst=0),\n",
       "   'authors': [{'name': 'Ramin Vatanparast, Trustpilot'}],\n",
       "   'author': 'Ramin Vatanparast, Trustpilot',\n",
       "   'author_detail': {'name': 'Ramin Vatanparast, Trustpilot'},\n",
       "   'tags': [{'term': 'AI', 'scheme': None, 'label': None},\n",
       "    {'term': 'Big Data', 'scheme': None, 'label': None},\n",
       "    {'term': 'Business', 'scheme': None, 'label': None},\n",
       "    {'term': 'Dev', 'scheme': None, 'label': None},\n",
       "    {'term': 'Enterprise', 'scheme': None, 'label': None},\n",
       "    {'term': 'Entrepreneur', 'scheme': None, 'label': None},\n",
       "    {'term': 'AI ethics', 'scheme': None, 'label': None},\n",
       "    {'term': 'category-/Business & Industrial', 'scheme': None, 'label': None},\n",
       "    {'term': 'Trustpilot', 'scheme': None, 'label': None}],\n",
       "   'id': 'https://venturebeat.com/?p=2538275',\n",
       "   'guidislink': False,\n",
       "   'summary': 'There are four aspects that dictate AI technologies be ethically designed: the dilemma, the impact, adoption, and institutionalization.',\n",
       "   'summary_detail': {'type': 'text/html',\n",
       "    'language': None,\n",
       "    'base': '',\n",
       "    'value': 'There are four aspects that dictate AI technologies be ethically designed: the dilemma, the impact, adoption, and institutionalization.'},\n",
       "   'content': [{'type': 'text/html',\n",
       "     'language': None,\n",
       "     'base': '',\n",
       "     'value': '<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=2448&amp;strip=all 2448w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=700&amp;strip=all 700w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=2000&amp;strip=all 2000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>There are four aspects that dictate AI technologies be ethically designed: the dilemma, the impact, adoption, and institutionalization.<a href=\"https://venturebeat.com/2019/10/18/how-does-society-create-an-ethics-guide-for-ai/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/AJOcW7--1uw\" height=\"1\" width=\"1\" alt=\"\"/>'}],\n",
       "   'wfw_commentrss': 'https://venturebeat.com/2019/10/18/how-does-society-create-an-ethics-guide-for-ai/feed/',\n",
       "   'slash_comments': '0',\n",
       "   'post-id': '2538275',\n",
       "   'source': {'href': 'https://venturebeat.com/2019/10/18/how-does-society-create-an-ethics-guide-for-ai/',\n",
       "    'title': 'How does society create an ethics guide for AI?'},\n",
       "   'feedburner_origlink': 'https://venturebeat.com/2019/10/18/how-does-society-create-an-ethics-guide-for-ai/'}],\n",
       " 'bozo': 0,\n",
       " 'encoding': 'utf-8',\n",
       " 'version': 'rss20',\n",
       " 'namespaces': {'content': 'http://purl.org/rss/1.0/modules/content/',\n",
       "  'wfw': 'http://wellformedweb.org/CommentAPI/',\n",
       "  'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  '': 'com-wordpress:feed-additions:1',\n",
       "  'sy': 'http://purl.org/rss/1.0/modules/syndication/',\n",
       "  'slash': 'http://purl.org/rss/1.0/modules/slash/',\n",
       "  'media': 'http://search.yahoo.com/mrss/',\n",
       "  'georss': 'http://www.georss.org/georss',\n",
       "  'geo': 'http://www.w3.org/2003/01/geo/wgs84_pos#',\n",
       "  'feedburner': 'http://rssnamespace.org/feedburner/ext/1.0'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venture_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VentureBeat\n",
      "Tech news that matters\n",
      "Sat, 19 Oct 2019 22:31:12 +0000\n"
     ]
    }
   ],
   "source": [
    "print(venture_beat['feed']['title'])\n",
    "print(venture_beat['feed']['subtitle'])\n",
    "print(venture_beat['feed']['updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTag: Business\n",
      "\tTag: Games\n",
      "\tTag: category-/Games/Computer & Video Games\n",
      "\tTag: DeanBeat News\n",
      "\tTag: Eidos\n",
      "\tTag: Emily Greer\n",
      "\tTag: Keith Boesky\n",
      "Former Eidos president and frequent game startup adviser Keith Boesky passes away\n",
      "Sat, 19 Oct 2019 22:33:41 +0000\n",
      "Dean Takahashi\n",
      "Keith Boesky, former president of Tomb Raider publisher Eidos and a frequent adviser to game companies at Boesky &#038; Co., has died from cancer.\n",
      "<img width=\"578\" height=\"373\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?fit=578%2C373&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Keith Boesky was the former president of Eidos.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=877&amp;strip=all 877w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/keith-boesky.jpg?w=578&amp;strip=all 578w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Keith Boesky, former president of Tomb Raider publisher Eidos and a frequent adviser to game companies at Boesky & Co., has died from cancer. <a href=\"https://venturebeat.com/2019/10/19/former-eidos-president-and-frequent-game-startup-adviser-keith-boesky-passes-away/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/H2cAxcpZmfw\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: Bungie\n",
      "\tTag: category-/Games/Computer & Video Games/Shooter Games\n",
      "\tTag: console gaming\n",
      "\tTag: DeanBeat Reviews Previews and Interviews\n",
      "\tTag: Destiny\n",
      "\tTag: Destiny 2\n",
      "\tTag: Harold Ryan\n",
      "\tTag: PC gaming\n",
      "\tTag: Probably Monsters\n",
      "Harold Ryan interview — Why ProbablyMonsters is making a huge bet on triple-A games\n",
      "Sat, 19 Oct 2019 19:12:43 +0000\n",
      "Dean Takahashi\n",
      "<p>Former Bungie CEO Harold Ryan showed everybody how to go big or go home earlier this month. He announced that his ProbablyMonsters is announcing it has raised $18.8 million for the company’s two triple-A game studios. Ryan is going to need a lot more money than that to pull off not one but two ambitious triple-A&#160;[&#8230;]\n",
      "</p>\n",
      "<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"ProbablyMonsters team\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=1400&amp;strip=all 1400w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/probably-monsters.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Former Bungie CEO Harold Ryan showed everybody how to go big or go home earlier this month. He announced that his ProbablyMonsters is announcing it has raised $18.8 million for the company’s two triple-A game studios. Ryan is going to need a lot more money than that to pull off not one but two ambitious triple-A projects in an age when there are a&hellip;<a href=\"https://venturebeat.com/2019/10/19/harold-ryan-interview-why-probablymonsters-is-making-a-huge-bet-on-triple-a-games/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/lMCLFQXTK-w\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Enterprise\n",
      "\tTag: Entrepreneur\n",
      "\tTag: Amazon\n",
      "\tTag: Arm\n",
      "\tTag: category-/Law & Government\n",
      "\tTag: climate change\n",
      "\tTag: Drew Henry\n",
      "\tTag: HiSilicon\n",
      "\tTag: NVidia\n",
      "Will the rise of IoT and slowing of Moore’s Law contribute to climate change?\n",
      "Sat, 19 Oct 2019 15:45:19 +0000\n",
      "Dean Takahashi\n",
      "I spoke with Drew Henry, senior vice president at Arm, about the growing IoT ecosystem's compute demands and the impact that could have on climate change.\n",
      "<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"The future is looking more and more bleak for the wildlife of the Arctic, especially the polar bears. These bears rely on the sea ice to hunt their favorite prey, seals, and this large male bear seen here, seems to be looking across the Arctic in disbelief as his world disappears beneath him.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=2121&amp;strip=all 2121w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/09/climate-change.jpg?w=2000&amp;strip=all 2000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>I spoke with Drew Henry, senior vice president at Arm, about the growing IoT ecosystem's compute demands and the impact that could have on climate change.<a href=\"https://venturebeat.com/2019/10/19/will-rise-of-iot-and-the-slowing-of-moores-law-contribute-to-climate-change/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/E2f51XM2CsI\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AR/VR\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: AR tabletop\n",
      "\tTag: category-/Games/Roleplaying Games\n",
      "\tTag: Tilt Five\n",
      "Tilt Five adds new partners for AR tabletop game project: Tabletopia and Monocle Socity\n",
      "Sat, 19 Oct 2019 10:13:11 +0000\n",
      "Harry Baker, UploadVR\n",
      "Tilt Five announced two new tabletop AR game partners with Tabletopia and Monocle Society.\n",
      "<img width=\"578\" height=\"394\" src=\"https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?fit=578%2C394&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Tilt Five\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=1237&amp;strip=all 1237w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/09/tilt-five-2.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Tilt Five announced two new tabletop AR game partners with Tabletopia and Monocle Society.<a href=\"https://venturebeat.com/2019/10/19/tilt-five-adds-new-partners-for-ar-tabletop-game-project-tabletopia-and-monocle-socity/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/aVSGIdO6irk\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: BattleTech\n",
      "\tTag: Battletech: Heavy Metal\n",
      "\tTag: category-/Games/Board Games/Miniatures & Wargaming\n",
      "\tTag: category-/Games/Computer & Video Games\n",
      "\tTag: DeanBeat News\n",
      "\tTag: Harebrained Schemes\n",
      "\tTag: Mitch Gitelman\n",
      "\tTag: Paradox Interactive\n",
      "\tTag: PC gaming\n",
      "Battletech gets Heavy Metal expansion on November 21\n",
      "Sat, 19 Oct 2019 08:30:28 +0000\n",
      "Dean Takahashi\n",
      "Paradox Interactive and Harebrained Schemes announced the Heavy Metal expansion for mech combat game Battletech will go live on November 21.\n",
      "<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/oCqrGKA-wdg?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe><hr/>Paradox Interactive and Harebrained Schemes announced the Heavy Metal expansion for mech combat game Battletech will go live on November 21.<a href=\"https://venturebeat.com/2019/10/19/battletech-gets-heavy-metal-expansion-on-november-21/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/6SA-_r9okvI\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: Age of Wonders\n",
      "\tTag: Age of Wonders: Planetfall\n",
      "\tTag: category-/Games/Board Games\n",
      "\tTag: category-/Games/Computer & Video Games/Strategy Games\n",
      "\tTag: category-/Games/Roleplaying Games\n",
      "\tTag: Paradox Interactive\n",
      "\tTag: PDXCON 2019\n",
      "\tTag: Triumph Studios\n",
      "Age of Wonders: Planetfall’s first expansion is Revelations, launching November 19\n",
      "Sat, 19 Oct 2019 08:25:18 +0000\n",
      "Jason Wilson\n",
      "Age of Wonders: Planetfall's first expansion is Revelations, and it launches November 19 for PC, PlayStation 4, and Xbox One.\n",
      "<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/YofuDirQaLo?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe><hr/>Age of Wonders: Planetfall's first expansion is Revelations, and it launches November 19 for PC, PlayStation 4, and Xbox One.<a href=\"https://venturebeat.com/2019/10/19/age-of-wonders-planetfall-gets-its-first-expansion-is-revelations-launching-november-19/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/SzAB55UEp0Y\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Enterprise\n",
      "\tTag: Media\n",
      "\tTag: Mobile\n",
      "\tTag: Security\n",
      "\tTag: 5G\n",
      "\tTag: category-/Computers & Electronics\n",
      "\tTag: category-/Internet & Telecom/Mobile & Wireless\n",
      "\tTag: category-/News\n",
      "\tTag: China\n",
      "\tTag: Huawei\n",
      "\tTag: United States\n",
      "Huawei is in early talks about licensing 5G tech to U.S. firms\n",
      "Sat, 19 Oct 2019 04:55:45 +0000\n",
      "Reuters\n",
      "Blacklisted Chinese telecoms equipment giant Huawei is in early-stage talks with some U.S. telecoms companies about licensing its 5G network technology.\n",
      "<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"The logo of Huawei Technologies is pictured in front of the German headquarters of the Chinese telecommunications giant in Duesseldorf, Germany, February 18, 2019.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=1200&amp;strip=all 1200w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/04/2019-04-24T111728Z_3_LYNXNPEF3N0ER_RTROPTP_4_HUAWEI-HSBC-e1558409923159.jpg?w=700&amp;strip=all 700w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Blacklisted Chinese telecoms equipment giant Huawei is in early-stage talks with some U.S. telecoms companies about licensing its 5G network technology.<a href=\"https://venturebeat.com/2019/10/18/huawei-is-in-early-talks-about-licensing-5g-tech-to-u-s-firms/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/WdwX2Y2wqOQ\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: Business\n",
      "\tTag: Commerce\n",
      "\tTag: Enterprise\n",
      "\tTag: Entrepreneur\n",
      "\tTag: Marketing\n",
      "\tTag: ai\n",
      "\tTag: artificial intelligence\n",
      "\tTag: Bold360 by LogMeIn\n",
      "\tTag: category-/Business & Industrial\n",
      "\tTag: category-/Computers & Electronics\n",
      "\tTag: customer engagement\n",
      "\tTag: customer experience\n",
      "\tTag: customer journey\n",
      "\tTag: digital technology\n",
      "\tTag: machine learning\n",
      "5 predictions for AI’s impact on customer experience in 2020 (VB Live)\n",
      "Fri, 18 Oct 2019 21:46:11 +0000\n",
      "VB Staff\n",
      "Join this VB Live event for a look at the predictions that came true, the hype that fizzled, and what's next for the AI, CX, and chatbot technology.\n",
      "<img width=\"578\" height=\"303\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?fit=578%2C303&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=2115&amp;strip=all 2115w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/group.texting.GettyImages-1079872594.jpg?w=2000&amp;strip=all 2000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Join this VB Live event for a look at the predictions that came true, the hype that fizzled, and what's next for the AI, CX, and chatbot technology.<a href=\"https://venturebeat.com/2019/10/18/5-predictions-for-ais-impact-on-customer-experience-in-2020-vb-live/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/7k2oeQeN-0E\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Esports\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: category-/Computers & Electronics/Consumer Electronics/Audio Equipment\n",
      "\tTag: category-/Games/Computer & Video Games\n",
      "\tTag: Epic Games\n",
      "\tTag: Fortnite\n",
      "Fortnite is finally getting better spatial audio\n",
      "Fri, 18 Oct 2019 21:40:28 +0000\n",
      "Jeff Grubb\n",
      "Fortnite is getting one of its most important upgrades ever. Epic is adding spatial audio to the battle royale shooter to give players more tactical info.\n",
      "<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/WDUbxKGb2nY?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe><hr/>Fortnite is getting one of its most important upgrades ever. Epic is adding spatial audio to the battle royale shooter to give players more tactical info.<a href=\"https://venturebeat.com/2019/10/18/fortnite-spatial-audio/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/C4hbkSg_FG8\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Games\n",
      "\tTag: category-/Games/Computer & Video Games\n",
      "\tTag: console gaming\n",
      "\tTag: retro gaming\n",
      "\tTag: Sega\n",
      "\tTag: Sonic & Knuckles\n",
      "\tTag: The RetroBeat\n",
      "The RetroBeat: Sonic & Knuckles turned a problem into success 25 years ago\n",
      "Fri, 18 Oct 2019 21:02:29 +0000\n",
      "Mike Minotti\n",
      "Sonic &#038; Knuckles is what happens when you make the best out of a bad situation. The classic Genesis game is now 25 years old.\n",
      "<img width=\"578\" height=\"361\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?fit=578%2C361&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Sonic &amp; Knuckles.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=1280&amp;strip=all 1280w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/Sonic-and-Knuckles.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Sonic & Knuckles is what happens when you make the best out of a bad situation. The classic Genesis game is now 25 years old.<a href=\"https://venturebeat.com/2019/10/18/the-retrobeat-sonic-knuckles-turned-a-problem-into-success-25-years-ago/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/IuvebmxLyx8\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AR/VR\n",
      "\tTag: Mobile\n",
      "\tTag: augmented reality\n",
      "\tTag: Brown\n",
      "\tTag: Brown UCI\n",
      "\tTag: category-/Computers & Electronics/Consumer Electronics\n",
      "\tTag: category-/Internet & Telecom/Mobile & Wireless/Mobile Phones\n",
      "\tTag: Portal-ble\n",
      "\tTag: smartphone\n",
      "Researchers demo AR hand tracking controls for smartphones\n",
      "Fri, 18 Oct 2019 21:00:04 +0000\n",
      "Jeremy Horwitz\n",
      "A group of Brown University researchers wants to bring hand tracking to smartphone augmented reality using off-the-shelf hardware and open source software.\n",
      "<img width=\"578\" height=\"263\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/portalble-e1571431845492.jpg?fit=578%2C263&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/portalble-e1571431845492.jpg?zoom=2&amp;resize=578%2C263&amp;strip=all 1156w, https://venturebeat.com/wp-content/uploads/2019/10/portalble-e1571431845492.jpg?zoom=3&amp;resize=578%2C263&amp;strip=all 1734w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>A group of Brown University researchers wants to bring hand tracking to smartphone augmented reality using off-the-shelf hardware and open source software.<a href=\"https://venturebeat.com/2019/10/18/researchers-demo-ar-hand-tracking-controls-for-smartphones/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/5yIcZzB0k1I\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Esports\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: Activision Blizzard\n",
      "\tTag: Alexandria Ocasio-Cortez\n",
      "\tTag: Apple\n",
      "\tTag: Blizzard Entertainment\n",
      "\tTag: Bobby Kotick\n",
      "\tTag: category-/News\n",
      "\tTag: China\n",
      "\tTag: J. Allen Brack\n",
      "\tTag: Marco Rubio\n",
      "\tTag: Ron Wyden\n",
      "\tTag: Tim Cook\n",
      "Bipartisan group condemns Blizzard and Apple for bowing to China\n",
      "Fri, 18 Oct 2019 20:33:32 +0000\n",
      "Jeff Grubb\n",
      "Biparitsan group condemns Blizzard and Apple for making moves at the behest of the Chinese government in relation to Hong Kong.\n",
      "<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Congress is asking Blizzard and Apple to stop helping China.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=1600&amp;strip=all 1600w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/house.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Biparitsan group condemns Blizzard and Apple for making moves at the behest of the Chinese government in relation to Hong Kong.<a href=\"https://venturebeat.com/2019/10/18/bipartisan-group-condemns-blizzard-and-apple-for-kowtowing-to-china/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/9DdbFykkNRY\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: Business\n",
      "\tTag: Dev\n",
      "\tTag: Media\n",
      "\tTag: Mobile\n",
      "\tTag: Security\n",
      "\tTag: artificial intelligence\n",
      "\tTag: category-/Computers & Electronics/Software\n",
      "\tTag: category-/Internet & Telecom\n",
      "\tTag: category-/Science\n",
      "\tTag: edge computing\n",
      "\tTag: Google Assistant\n",
      "\tTag: on-device machine learning\n",
      "AI Weekly: Why Google still needs the cloud even with on-device ML\n",
      "Fri, 18 Oct 2019 19:59:04 +0000\n",
      "Khari Johnson\n",
      "Google is giving more hardware dedicated chips for on-device machine learning, but services like Google Assistant still rely on the cloud. Here's why.\n",
      "<img width=\"578\" height=\"385\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?fit=578%2C385&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Google\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=1800&amp;strip=all 1800w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/google-1.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Google is giving more hardware dedicated chips for on-device machine learning, but services like Google Assistant still rely on the cloud. Here's why.<a href=\"https://venturebeat.com/2019/10/18/ai-weekly-why-google-still-needs-the-cloud-even-with-on-device-ml/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/k38EH-HHPlA\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Big Data\n",
      "\tTag: Business\n",
      "\tTag: Enterprise\n",
      "\tTag: category-/Computers & Electronics/Computer Hardware/Computer Drives & Storage\n",
      "\tTag: enterprise storage\n",
      "\tTag: NVMe\n",
      "\tTag: SATA\n",
      "NVMe vs. SATA, Part 2: Industry insider interview\n",
      "Fri, 18 Oct 2019 19:38:55 +0000\n",
      "William Van Winkle\n",
      "The NVM Express specification for solid state drives arrived eight years ago. So where’s all the adoption? Western Digital's Eric Pike explores.\n",
      "<img width=\"548\" height=\"307\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?fit=548%2C307&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?w=548&amp;strip=all 548w, https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/GETTYIMAGES-1022326340.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.jpeg?w=400&amp;strip=all 400w\" sizes=\"(max-width: 548px) 100vw, 548px\" /><hr/>The NVM Express specification for solid state drives arrived eight years ago. So where’s all the adoption? Western Digital's Eric Pike explores.<a href=\"https://venturebeat.com/2019/10/18/nvme-vs-sata-part-2-industry-insider-interview/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/EV9lM781vvE\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: category-/Computers & Electronics/Computer Hardware/Computer Drives & Storage\n",
      "\tTag: enterprise storage\n",
      "\tTag: M.2\n",
      "\tTag: NAND\n",
      "\tTag: NVMe\n",
      "\tTag: PCI Express\n",
      "\tTag: PCIe\n",
      "\tTag: SATA\n",
      "NVMe vs. SATA: Which NAND storage do you need?\n",
      "Fri, 18 Oct 2019 19:36:51 +0000\n",
      "William Van Winkle\n",
      "For workstations and servers, it's getting hard not to justify the relatively low price/premium for NVMe versus the older SATA.\n",
      "<img width=\"578\" height=\"299\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?fit=578%2C299&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=9939&amp;strip=all 9939w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2019/10/Intel-SD-DC-P4600-Series.jpg?w=3000&amp;strip=all 3000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>For workstations and servers, it's getting hard not to justify the relatively low price/premium for NVMe versus the older SATA.<a href=\"https://venturebeat.com/2019/10/18/nvme-vs-sata-which-nand-storage-do-you-need/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/eAjnXyxG-xE\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Mobile\n",
      "\tTag: 4G LTE\n",
      "\tTag: 5G\n",
      "\tTag: AI. artificial intelligence\n",
      "\tTag: category-/Computers & Electronics\n",
      "\tTag: category-/Internet & Telecom/Mobile & Wireless\n",
      "\tTag: category-/Internet & Telecom/Service Providers\n",
      "\tTag: cloud computing\n",
      "\tTag: edge computing\n",
      "Today’s 4G LTE puts you on the pathway to tomorrow’s 5G\n",
      "Fri, 18 Oct 2019 19:34:43 +0000\n",
      "Chris Angelini\n",
      "There’s a pathway to 5G that promises much of the technology’s value on existing 4G LTE networks for those who make the right upgrades.\n",
      "<img width=\"578\" height=\"326\" src=\"https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?fit=578%2C326&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"A 5G sign is seen during the Mobile World Congress in Barcelona, Spain February 28, 2018.\" srcset=\"https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2018/07/2018-07-30T132643Z_1_LYNXMPEE6T140_RTROPTP_4_TELECOMS-5G-NOKIA-T-MOBILE-US-e1552568956846.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>There’s a pathway to 5G that promises much of the technology’s value on existing 4G LTE networks for those who make the right upgrades.<a href=\"https://venturebeat.com/2019/10/18/todays-4g-lte-puts-you-on-the-pathway-to-tomorrows-5g/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/H1BKf_FsV9c\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: category-/Arts & Entertainment\n",
      "\tTag: category-/Games/Computer & Video Games\n",
      "\tTag: console gaming\n",
      "\tTag: Electronic Arts\n",
      "\tTag: PC gaming\n",
      "\tTag: Respawn Entertainment\n",
      "\tTag: Star Wars: Jedi -- Fallen Order\n",
      "Jedi: Fallen Order — The satisfaction of creating new Star Wars canon\n",
      "Fri, 18 Oct 2019 19:30:16 +0000\n",
      "Mike Minotti\n",
      "After a long demo, I got a chance to talk with Respawn about the fun and challenge of creating its own slice of Star Wars material.\n",
      "<img width=\"578\" height=\"325\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?fit=578%2C325&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"A Jedi and his droid.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=3840&amp;strip=all 3840w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2019/10/JFO_LaunchScreenshots_Cal_CU_v05.png?w=3000&amp;strip=all 3000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>After a long demo, I got a chance to talk with Respawn about the fun and challenge of creating its own slice of Star Wars material.<a href=\"https://venturebeat.com/2019/10/18/jedi-fallen-order-the-satisfaction-of-creating-new-star-wars-canon/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/Fn5epBsAsfc\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: Big Data\n",
      "\tTag: Business\n",
      "\tTag: Commerce\n",
      "\tTag: Dev\n",
      "\tTag: Enterprise\n",
      "\tTag: Entrepreneur\n",
      "\tTag: Mobile\n",
      "\tTag: Transportation\n",
      "\tTag: Alphabet\n",
      "\tTag: category-/Business & Industrial\n",
      "\tTag: category-/Computers & Electronics/Consumer Electronics/Drones & RC Aircraft\n",
      "\tTag: category-/Hobbies & Leisure\n",
      "\tTag: category-/Travel/Air Travel\n",
      "\tTag: commercial drone\n",
      "\tTag: delivery\n",
      "\tTag: drone\n",
      "\tTag: Wing\n",
      "Wing launches drone delivery in Christiansburg, Virginia\n",
      "Fri, 18 Oct 2019 18:47:46 +0000\n",
      "Kyle Wiggers\n",
      "Google parent company Alphabet's Wing today said that it's kicked off a drone delivery pilot in Virginia for select residents.\n",
      "<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/wCTKwkYzVzo?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe><hr/>Google parent company Alphabet's Wing today said that it's kicked off a drone delivery pilot in Virginia for select residents.<a href=\"https://venturebeat.com/2019/10/18/wing-launches-drone-delivery-in-christiansburg-virginia/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/5AecPUZEW30\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: AR/VR\n",
      "\tTag: Cloud\n",
      "\tTag: Games\n",
      "\tTag: Mobile\n",
      "\tTag: 5G\n",
      "\tTag: 5G edge\n",
      "\tTag: 5G Network\n",
      "\tTag: AR\n",
      "\tTag: category-/Computers & Electronics/Consumer Electronics\n",
      "\tTag: category-/Internet & Telecom/Mobile & Wireless\n",
      "\tTag: cloud\n",
      "\tTag: Edge\n",
      "\tTag: edge cloud\n",
      "\tTag: GPU\n",
      "\tTag: Verizon\n",
      "\tTag: VR\n",
      "\tTag: XR\n",
      "Verizon debuts GPU-based 5G edge services for mobile VR/XR developers\n",
      "Fri, 18 Oct 2019 18:40:55 +0000\n",
      "Jeremy Horwitz\n",
      "5G is about to make better use of GPUs than ever before, thanks to innovations that will enable multiple users to share cloud-based graphics hardware.\n",
      "<img width=\"578\" height=\"325\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/verizon5gvr-e1571423723684.jpg?fit=578%2C325&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Verizon&#039;s Envrmnt develops 5G network-ready XR technologies, including interactive realtime lighting service that makes digital objects blend into their real environments.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/verizon5gvr-e1571423723684.jpg?zoom=2&amp;resize=578%2C325&amp;strip=all 1156w, https://venturebeat.com/wp-content/uploads/2019/10/verizon5gvr-e1571423723684.jpg?zoom=3&amp;resize=578%2C325&amp;strip=all 1734w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>5G is about to make better use of GPUs than ever before, thanks to innovations that will enable multiple users to share cloud-based graphics hardware.<a href=\"https://venturebeat.com/2019/10/18/verizon-debuts-gpu-based-5g-edge-services-for-mobile-vr-xr-developers/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/rpZ6BCGkIz0\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: Business\n",
      "\tTag: Dev\n",
      "\tTag: Enterprise\n",
      "\tTag: Media\n",
      "\tTag: Mobile\n",
      "\tTag: Android\n",
      "\tTag: Android 10\n",
      "\tTag: category-/Computers & Electronics\n",
      "\tTag: Google\n",
      "\tTag: Google 2019 hardware event\n",
      "\tTag: Google Pixel 4\n",
      "\tTag: Google Pixel 4 XL\n",
      "\tTag: Live Caption\n",
      "\tTag: Pixel 4\n",
      "\tTag: Pixel 4 XL\n",
      "\tTag: ProBeat\n",
      "ProBeat: Google’s Pixel 4 ups the AI ante to offline language models\n",
      "Fri, 18 Oct 2019 17:30:40 +0000\n",
      "Emil Protalinski\n",
      "Live Caption and Recorder on the Pixel 4 and Pixel 4 XL show that Google wants to rule offline natural language processing.\n",
      "<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/v8cLk2W3vY8?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe><hr/>Live Caption and Recorder on the Pixel 4 and Pixel 4 XL show that Google wants to rule offline natural language processing.<a href=\"https://venturebeat.com/2019/10/18/probeat-googles-pixel-4-ups-the-ai-ante-to-offline-language-models/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/wgH-Ny3vjbc\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Media\n",
      "\tTag: Mobile\n",
      "\tTag: app\n",
      "\tTag: Apple\n",
      "\tTag: Apple TV\n",
      "\tTag: Apple TV App\n",
      "\tTag: category-/Computers & Electronics/Consumer Electronics\n",
      "\tTag: cord-cutting\n",
      "\tTag: Roku\n",
      "\tTag: Roku TV\n",
      "\tTag: Samsung\n",
      "\tTag: subscription service\n",
      "\tTag: TCL\n",
      "\tTag: TV app\n",
      "Hands-on: Roku’s Apple TV app helped me cut the cord — from Apple\n",
      "Fri, 18 Oct 2019 16:33:07 +0000\n",
      "Jeremy Horwitz\n",
      "Apple TV devices were designed to help users cut the cord from cable companies. Now an Apple TV app for Roku lets users cut the cord with Apple hardware.\n",
      "<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=1254&amp;strip=all 1254w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/hobbsappletv.jpeg?w=700&amp;strip=all 700w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Apple TV devices were designed to help users cut the cord from cable companies. Now an Apple TV app for Roku lets users cut the cord with Apple hardware.<a href=\"https://venturebeat.com/2019/10/18/hands-on-rokus-apple-tv-app-helped-me-cut-the-cord-from-apple/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/zPJLywnvt64\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Entrepreneur\n",
      "\tTag: Games\n",
      "\tTag: Media\n",
      "\tTag: Social\n",
      "\tTag: category-/Games\n",
      "\tTag: Electronic Theater\n",
      "\tTag: Electronic Theatre\n",
      "\tTag: Tough Mudder\n",
      "\tTag: Will Dean\n",
      "Electronic Theatre brings immersive group gaming to physical rooms\n",
      "Fri, 18 Oct 2019 15:16:27 +0000\n",
      "Paul Sawers\n",
      "Will Dean is known as the creator of Tough Mudder. Now, he has gone digital with Electronic Theatre -- immersive group gaming experiences in physical rooms.\n",
      "<img width=\"578\" height=\"360\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?fit=578%2C360&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Electronic Theatre\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=1296&amp;strip=all 1296w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/Electronic-Theatre-4.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Will Dean is known as the creator of Tough Mudder. Now, he has gone digital with Electronic Theatre -- immersive group gaming experiences in physical rooms.<a href=\"https://venturebeat.com/2019/10/18/electronic-theatre-brings-immersive-group-gaming-to-physical-rooms/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/Ue2TTcQOSg4\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AR/VR\n",
      "\tTag: Business\n",
      "\tTag: Esports\n",
      "\tTag: Games\n",
      "\tTag: Mobile\n",
      "\tTag: PC Gaming\n",
      "\tTag: category-/Arts & Entertainment\n",
      "\tTag: category-/Games/Computer & Video Games\n",
      "\tTag: DeanBeat Flair and Opinion\n",
      "\tTag: GamesBeat Decides\n",
      "\tTag: PC gaming\n",
      "\tTag: podcast\n",
      "\tTag: Respawn Entertainment\n",
      "\tTag: Star Wars: Jedi -- Fallen Order\n",
      "GamesBeat Decides 128: Star Wars Jedi: Fallen Order rules\n",
      "Fri, 18 Oct 2019 15:06:29 +0000\n",
      "Jeff Grubb\n",
      "Star Wars Jedi: Fallen Order is a potentailly excellent entry in the long history of the series. We played the first 3.5 hours. Listen to our thoughts.\n",
      "<img width=\"578\" height=\"325\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?fit=578%2C325&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"A good &#039;Star Wars&#039; game? Yes, please.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=1280&amp;strip=all 1280w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/GamesBeat-Decides-Podcast-Header-2-1.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Star Wars Jedi: Fallen Order is a potentailly excellent entry in the long history of the series. We played the first 3.5 hours. Listen to our thoughts.<a href=\"https://venturebeat.com/2019/10/18/gamesbeat-decides-128-jedi-fallen-order/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/Z5L1aTFRMow\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Esports\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: Arcane\n",
      "\tTag: category-/Arts & Entertainment\n",
      "\tTag: category-/Games/Computer & Video Games/Strategy Games\n",
      "\tTag: League of Legends\n",
      "\tTag: League of Legends: Wild Rift\n",
      "\tTag: Legends of Runeterra\n",
      "\tTag: Marc Merrill\n",
      "\tTag: MOBA\n",
      "\tTag: PC gaming\n",
      "\tTag: Riot Games\n",
      "\tTag: Team Fight Tactics\n",
      "\tTag: The DeanBeat\n",
      "The DeanBeat: Riot Games sheds its image as a single-game company\n",
      "Fri, 18 Oct 2019 15:00:45 +0000\n",
      "Dean Takahashi\n",
      "Riot Games announced on its 10th anniversary that it created new games, films, and animated series in the hopes of overcoming The Innovator's Dilemma.\n",
      "<img width=\"578\" height=\"321\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?fit=578%2C321&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Marc Merrill (left) and Brandon Beck started Riot Games in 2006.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=1134&amp;strip=all 1134w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/riot-2.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Riot Games announced on its 10th anniversary that it created new games, films, and animated series in the hopes of overcoming The Innovator's Dilemma.<a href=\"https://venturebeat.com/2019/10/18/the-deanbeat-riot-games-sheds-its-image-as-a-single-game-company/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/qy36ZT4vCC4\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: Big Data\n",
      "\tTag: Business\n",
      "\tTag: Dev\n",
      "\tTag: Entrepreneur\n",
      "\tTag: ai conferences\n",
      "\tTag: AI events\n",
      "\tTag: category-/Business & Industrial\n",
      "\tTag: Transform 2020\n",
      "\tTag: Transform technology showcase\n",
      "\tTag: VB Transform 2020\n",
      "Here’s how to blow everyone’s minds with your company’s AI product at Transform 2020\n",
      "Fri, 18 Oct 2019 14:50:48 +0000\n",
      "VB Staff\n",
      "If you think your AI product is groundbreaking and delivers real-world results, you could be one of 14 companies on the main stage at Transform 2020.\n",
      "<img width=\"578\" height=\"290\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?fit=578%2C290&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"#VBTransform @VentureBeat Brainworks, Dr. Philip Alvelda, Founder\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=6441&amp;strip=all 6441w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=700&amp;strip=all 700w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=2000&amp;strip=all 2000w, https://venturebeat.com/wp-content/uploads/2019/10/4TPO2197.jpg?w=3000&amp;strip=all 3000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>If you think your AI product is groundbreaking and delivers real-world results, you could be one of 14 companies on the main stage at Transform 2020.<a href=\"https://venturebeat.com/2019/10/18/heres-how-to-blow-everyones-minds-with-your-companys-ai-product-at-transform-2020/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/R2EC0TS_jMw\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: Bigmoon Entertainment\n",
      "\tTag: category-/Sports/Team Sports\n",
      "\tTag: Dakar 18\n",
      "\tTag: DeanBeat News\n",
      "\tTag: Saber Interactive\n",
      "\tTag: World War Z\n",
      "Saber Interactive buys Bigmoon Entertainment, announces two new projects\n",
      "Fri, 18 Oct 2019 14:00:17 +0000\n",
      "Jason Wilson\n",
      "Saber Interactive announces today that it's buying Bigmoon Entertainment, the makers of games such as Dakar 18, Demons Age, and Police Simulator: Patrol Duty\n",
      "<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Saber Interactive adds Bigmoon Entertainment to its stable.\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=1200&amp;strip=all 1200w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/jasoncollage.jpg?w=700&amp;strip=all 700w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Saber Interactive announces today that it's buying Bigmoon Entertainment, the makers of games such as Dakar 18, Demons Age, and Police Simulator: Patrol Duty<a href=\"https://venturebeat.com/2019/10/18/saber-interactive-buys-bigmoon-entertainment-announces-two-new-projects/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/pYR-KxvqLY0\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: Business\n",
      "\tTag: Esports\n",
      "\tTag: Games\n",
      "\tTag: PC Gaming\n",
      "\tTag: activision\n",
      "\tTag: Activision Blizzard\n",
      "\tTag: Call of Duty League\n",
      "\tTag: category-/Games/Computer & Video Games/Sports Games\n",
      "\tTag: Johanna Faries\n",
      "\tTag: Overwatch League\n",
      "Call of Duty League: How Activision reimagined its city-based esports structure\n",
      "Fri, 18 Oct 2019 13:00:38 +0000\n",
      "Dean Takahashi\n",
      "Taking lessons from the success of the Overwatch League, Activision has revamped the structure of its esports competition in the Call of Duty League.\n",
      "<img width=\"578\" height=\"321\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?fit=578%2C321&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"Call of Duty League\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=1486&amp;strip=all 1486w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/cod-league-2.jpg?w=930&amp;strip=all 930w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>Taking lessons from the success of the Overwatch League, Activision has revamped the structure of its esports competition in the Call of Duty League.<a href=\"https://venturebeat.com/2019/10/18/call-of-duty-league-how-activision-reimagined-its-city-based-esports-structure/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/kWeSFuYlqwo\" height=\"1\" width=\"1\" alt=\"\"/>\n",
      "\tTag: AI\n",
      "\tTag: Big Data\n",
      "\tTag: Business\n",
      "\tTag: Dev\n",
      "\tTag: Enterprise\n",
      "\tTag: Entrepreneur\n",
      "\tTag: AI ethics\n",
      "\tTag: category-/Business & Industrial\n",
      "\tTag: Trustpilot\n",
      "How does society create an ethics guide for AI?\n",
      "Fri, 18 Oct 2019 11:10:23 +0000\n",
      "Ramin Vatanparast, Trustpilot\n",
      "There are four aspects that dictate AI technologies be ethically designed: the dilemma, the impact, adoption, and institutionalization.\n",
      "<img width=\"578\" height=\"289\" src=\"https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?fit=578%2C289&amp;strip=all\" class=\"attachment-single-feed size-single-feed wp-post-image\" alt=\"\" srcset=\"https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=2448&amp;strip=all 2448w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=300&amp;strip=all 300w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=768&amp;strip=all 768w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=800&amp;strip=all 800w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=100&amp;strip=all 100w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=350&amp;strip=all 350w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=400&amp;strip=all 400w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=780&amp;strip=all 780w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=578&amp;strip=all 578w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=930&amp;strip=all 930w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=700&amp;strip=all 700w, https://venturebeat.com/wp-content/uploads/2019/10/AI.GettyImages-817338718.jpg?w=2000&amp;strip=all 2000w\" sizes=\"(max-width: 578px) 100vw, 578px\" /><hr/>There are four aspects that dictate AI technologies be ethically designed: the dilemma, the impact, adoption, and institutionalization.<a href=\"https://venturebeat.com/2019/10/18/how-does-society-create-an-ethics-guide-for-ai/\" target=\"_blank\">Read More</a><img src=\"http://feeds.feedburner.com/~r/venturebeat/SZYF/~4/AJOcW7--1uw\" height=\"1\" width=\"1\" alt=\"\"/>\n"
     ]
    }
   ],
   "source": [
    "for entry in venture_beat.entries:\n",
    "    for term in entry.tags:\n",
    "        print(f\"\\tTag: {term['term']}\")\n",
    "        \n",
    "    print(f\"{entry.title}\\r\\n{entry.published}\\r\\n{entry.author}\")\n",
    "    print(entry.summary)\n",
    "    \n",
    "    for content in entry.content:\n",
    "        print(content.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, *VentureBeat* was for grings and giggles, and it looks like the feed itself is only links to stories. We'll probably end up having to handle this one differently. If this is the case for one feed, it certainly could be the case for other feeds as well, so we'll have to plan for that and have the ability to crawl each of the links to grab the content we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup4 - Grabbing the Basic Conent/Text from the Feed\n",
    "\n",
    "Okay, now that we've got our feed data, we're ready to pull out the content so that we can begin to run it through our NLP modules. Let's take a look at the content using `BeautifulSoup4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By AI Trends Staff\n",
      "Your data has value, but unlocking it for your own benefit is challenging. Understanding how valuable data are collected and approved for use can help you to get there.\n",
      "Two primary means for differentiating audiences by their data collection methods are site-authenticated data collection and people-based data collection, suggested a recent piece in BulletinHealthcare written by Justin Fadgen, chief corporate development officer for the firm.\n",
      "Site-authenticated data are sourced from individual authentication events, such as when a user completes an online form, and generally agrees to a privacy policy that includes a data use agreement. User data are then be combined with other data sources that add meaning, becoming the basis of advertising targeting for instance. In marketing for healthcare, this is the National Provider Identifier (NPI), a 10-digit numeric identifier for covered healthcare providers under HIPAA.\n",
      "People-based data collection does not come from a registration, but from a variety of sources that could include data licensing, research, and manual verification. These data can be loaded onto a data management platform, which aggregates data from various sources into likely groups using data science. The goal is to provide an anonymized ID to individual users. These then can be individually targeted.\n",
      "People-based data may not be friendly to individual-level reporting, also called physician-level reporting. This is because no privacy policy has stipulated how the data are to be used.\n",
      "National Health Service of England Seeking to Monetize Data\n",
      "Efforts to monetize patient data of the National Health Service (NHS) of England further emphasizes the value of your data. Sensyne Health, a for-profit company, is working to get divisions of the NHS to put patient information into a database. The NHS has 71 years of patient data. In recent years, it has worked to collect patient DNA data for research.\n",
      "Sensyne’s initial goal, according to an account from Bloomberg, is to gather information on five million NHS patients. Ultimately, said Paul Drayson, the former UK science minister who founded Sensyne, the company hopes to get access to all 55 million members of NHS. EY consultants estimate those data might be worth $12 billion annually, money NHS could apply to patient care and health. Sensyne has so far signed up six of 150 hospital divisions in the NHS. Each division, or trust, receives Sensyne shares worth some $3 million.\n",
      "The potential value is of interest to the UK government, especially with Brexit injecting more uncertainty into the economy. “How the NHS works with the global life sciences industry is key to the health of the nation,” Drayson stated.\n",
      "Other groups are looking data as a business model. Intermountain Healthcare of Salt Lake City recently announced a partnership with Amgen to study the genomes of half a million patients. Israel is working on commercializing its patient health records in a $300 million program. Nebula Genomics is among companies who broker individual patient DNA data to buyers in the health industry.\n",
      "GDPR in European Union Enhances Individual Privacy Protection\n",
      "New privacy laws in Europe increase protections on patient information. According to polls, UK residents are willing to share data if it is invested back into healthcare, but they worry it will get into the wrong hands. Any citizen has the right to block sales of her or her data.\n",
      "The General Data Protection Regulation (GDPR) that went into effect in the European Union in May 2018 specified some rules around data permissions. Customers must now confirm that they want to be contacted, according to an account in SuperOffice. A default checkbox that automatically opts a customer in will not comply; opt-in needs to be a deliberate choice. SuperOffice has modified its web forms as a result.\n",
      "The GDPR says the customer has the “right to be forgotten,” to have outdated or inaccurate information removed. This gives individuals a way to gain more control over how their data are collected and used. This can be implemented with an unsubscribe link in email messages, and links to customer profiles that allow users to manage their email preferences.\n",
      "Fines for violation of GDPR privacy rules can be hefty, including $90,000 to a company that sent email to 3.3 million customers that had opted out of its lists.\n",
      "As companies pursuing AI and machine learning solutions race to get the data needed to make their applications work, we can see some challenging moments.\n",
      "Contribute Your Face to Google Database, Earn $5\n",
      "For instance, seeking to ensure its facial recognition image database is more diverse, Google recently began offering black homeless people in Atlanta $5 vouchers to submit their faces to the database, according to an account in TheRegister.\n",
      "With images of white men dominating its database, Google hired contractors to offer vouchers to people to record their faces. The temporary agency Randstad was told to target people with darker skin. Some were homeless living on the streets in Atlanta. Participants may not have been explicitly told what their images would be used for. When the word got out, it did not go over well in some circles. Atlanta City Attorney Nina Hickson wrote a letter to Google’s chief legal officer Kent Walker, asking the company to explain why the company was targeting “vulnerable populations” in Atlanta. The project was suspended. Google wanted to use the dataset to train a facial biometric system that can unlock its upcoming Pixel 4 smartphone.\n",
      "See the source posts in BulletinHealthcare, Bloomberg, SuperOffice and TheRegister.\n",
      "By AI Trends Staff\n",
      "The AI World Conference & Expo in Boston, Oct. 23-25, will include a Startup Pavilion of companies showing innovation, promise and creativity as they pursue business opportunities in new ventures in AI and machine learning.\n",
      "Here is a brief profile of each of the startups:\n",
      "The AI Network of Ridgeway Partners\n",
      "The AI Network was created by Ridgeway Partners, a global executive and board recruiting firm. The AI Network is a talent marketplace which uses AI to connect companies to the best  early-stage AI and data science talent. The firm has offices in New York, Boston, London and Hong Kong. Most of the recruiting work is based in the US and Europe, and the firm has completed assignments in Africa, the Middle East and Asia.\n",
      "AI.Reverie\n",
      "AI.Reverie is a simulation platform that trains AI to understand the world. Our platform offers tools to leverage the power of synthetic data to significantly improve the performance of mission critical vision algorithms. The firm recently announced a strategic partnership and investment from In-Q-Tel, the not-for-profit strategic investor that works to deliver innovative technology to US intelligence and defense agencies.The firm’s website describes its team as, “Idea generators and problem solvers with a passion for creating a better world with AI.” The company’s services include the creation of virtual worlds with animation and the ability to run simulations that produce synthetic data.\n",
      "AInfinity\n",
      "AInfinity specializes in cutting-edge technology solutions that combine Artificial Intelligence and ITOps capabilities. Drawing on the industry knowledge and expertise of its parent company, Atlas Systems, AInfinity has launched an end-to-end solution focused on predicting IT infrastructure (OS, Network, DB, Middleware) issues and resolving them using its rich knowledge library. The AInfinity Knowledge Library includes runbooks,, use cases, business rules, workflow orchestration, and proven best practices for resolving a wide range of IT issues.\n",
      "BAU Global\n",
      "The BAU Global Education Network is comprised of higher education institutions spread around the world. This international network welcomes students from across the globe to study at a number of locations. Students and graduates of BAU Global form an academic community that spans many countries on four continents: North America, Europe, Africa, and Asia. BAU Global universities offer nearly two hundred undergraduate, graduate and doctoral programs in architecture, art, business administration, communication, design, economics, education, engineering, health sciences, information technology, law, medicine, and social sciences.\n",
      "BAU Global develops global citizens who are committed to values that benefit the entire world. The institutions in this network not only meet the standards set forth by the accreditation bodies in their home countries, but are also highly ranked in the disciplines they offer.\n",
      "CampTek\n",
      "CampTek Software is an RPA SaaS Provider offering a wide array of services to assist you anywhere on your RPA Journey. Our team of certified experts focus on Bot development, Bot Support and Hosted Support.  With over 15 years of experience supporting and developing RPA applications, we are the choice. CampTek’s Software solutions include: Center of Excellence (COE), robot development, SaaS hosting and support, Windows and website automation, Citrix and remote desktop automation, support for Legacy Character-based systems, custom component creation and governance and architecture capabilities.\n",
      "CapeStart\n",
      "CapeStart is an outsourced data preparation services and software development firm that gives data-driven organizations the ability to offload tedious data tasks with confidence. Our mission is to provide you with reliable, knowledgeable and affordable solutions for resourcing your big data, machine learning, and artificial intelligence projects. The firm’s campus is Nagercoil, India helps to support the development work. CapeStart is engaged in over 50 active projects for its clients in a range of industries, according to its website. One client hired CapeStart to measure the ROI of its public relations activities, by monitoring the media and performing services including data extraction, sentiment analysis and document transcription.\n",
      "Capice\n",
      "Capice offers machine learning for everyone, suggesting no technical training or programming background is required to create business models. The Capice AI services including algorithms are available via an API interface. The client provides the training data, as audio, video or text. The Caprice tools are used to address business problems using classification and prediction.\n",
      "Daivergent\n",
      "Daivergent, a Public Benefit Corporation, hires workers with autism and developmental disabilities. The firm offers: dedicated project managers with experience in ata and technology fields; a US-based workforce, sourced from universities and agencies in the US; handling of requests of any scale; performance guarantees. The Daivergent platform has a remote user base of 850 candidates and 18 corporate clients. The firm offers employees online training in programming languages including Python and SQL, graphic design, 3-D modeling and marketing, to help bolster career growth. The company works closely with agencies including AHRC in New York City, a nonprofit providing workshops, day treatment programs and job training for people with intellectual and developmental disabilities.\n",
      "Firefly.ai\n",
      "Firefly.ai puts the power of artificial intelligence in the hands of any business that aims to predict its future. With our automated machine learning platform, analysts can easily build predictive models to enhance every business decision. Clients engage in the following steps: prepare and analyze data, train hundreds of models, design visual reports and deploy the models. Predictive models offered include demand analysis, predictive maintenance, investment optimization, risk mitigation, sales forecasting and customer segmentation. Firefly.ai targets ordinary business users by offering easy access to AI and machine learning.\n",
      "Jaxon.ai\n",
      "The best way to improve the accuracy of machine learning models is to increase the amount of labeled data ingested and/or re-label existing data, according to Jaxon.ai. Normally it takes months and massive amounts of manpower to get deep learning models trained with meaningful volumes of datasets. By the time the data is labeled, it is frequently already outdated. Jaxon aims to eliminate this bottleneck and allowing models to be updated continuously.\n",
      "With self-adjusting pipelines, Jaxon is said to adapt to each organization’s nuanced data and domain-specific terminology. Training sets are created using existing data, as well as new text streaming in from online and internal sources. Jaxon labels can train any text-based predictive model and can be used for document classification, recommenders, chatbots, customer insights and trend detection.\n",
      "Kyndi\n",
      "Kyndi offers an Explainable AI product and Intelligent Process Automation software platform for use by government, pharmaceutical, and financial services organizations. The product addresses the “black box” of Deep Learning, which restricts their use in regulated industries. The Kyndi platform scores the provenance and origin of each document it processes. Its Explainable AI software can be used with robotic process automation (RPA) tools to analyze text and automate inefficient workflows.\n",
      "Lazarus Enterprises\n",
      "Lazarus uses patient health data to improve early cancer detection. By using its clinical decision support tools, physicians are said to be able to improve their diagnostic accuracy from 76% all the way up to 93%. The company uses deep learning and accesses millions of patient records. The company’s business model is to sell test and subscriptions for physicians and hospitals, and selling anonymous datasets to insurance companies and research companies.\n",
      "Liquid Technologies\n",
      "LiquidTechnology is a nationwide provider of IT Asset Management Services. The company specializes in performing data center clean-outs, de-installations, consolidations and moves. The firm’s core competencies include: IT asset purchasing & brokerage, project management, compliant data destruction, chain of custody/ reverse logistics, as well as e-Stewards and R2 compliant e-Waste recycling.\n",
      "Ontoforce\n",
      "ONTOFORCE offers to help customers transform siloed data into smart-linked data ecosystems to empower data-driven decision making. The company’s linked data platform DISQOVER builds intelligent links between internal and external data sources, turning data into smart data. The software is installed on-premise or in the cloud. The company employs semantic search technology to help find insights into data. DISQOVER Public is a free resource with links to 145 different public data sources in biomedicine, enabling users to learn about the technology.\n",
      "Openmetrik\n",
      "Openmetrick works to automated three activities critical to business success: end-to-end digitization of analytics, enterprise data government and business process virtualization. The firm seeks to disrupt the IT industry by cutting the chaos of current fragmented IT tools, and to eliminate mundate, IT-resource intensive methods. Its software platform, dubbed GRIP, offers business intelligence, performance measurement and business process integration. The company’s Integration Metrics Platform secured a US patent in June 2018 enabling what the company calls the digitization of performance measurement, or a centralized metrics playbook.\n",
      "PerceptiMed\n",
      "PerceptiMed’s advanced pharmacy automation technologies reduce prescription errors and improve pharmacy workflow productivity ─ from fill to will call. PerceptiMed’s identRx uses artificial intelligence for pill verification, ensuring every pill placed into a prescription is correct and simultaneously serves as an ultra-accurate pill counter. IdentRx supports remote verification for telepharmacy. The products are designed to eliminate human errors in medication dispensing in pharmacies, long-term care facilities and hospitals.\n",
      "Roborus\n",
      "Roborus offers AI-based kiosks that employ facial recognition to automatically identify customers in cafes, restaurants, and retail shops. The software platform uses face recognition technology to classify customers’ data such as facial ID, gender, age, and 7 different moods. The machine learning system can provide guests with personalized services and is able to, for example, recommend specific menu items based on customer profile. The software gathers and analyzes data such as number of visits, consumption patterns and average spending, helping clients to enhance marketing efforts and increase sales.\n",
      "TalentSeer\n",
      "TalentSeer uses AI to provide integrated talent acquisition, market research, and career mentorship services. With an engaged AI community and deep domain knowledge, TalentSeer has helped over 100 high tech companies from autonomous driving, to finance, and healthcare at various growth stages to build strong teams. AI engineers are overloaded with repetitive pitch messages. The firm employs insight-based and influence-based recruiting techniques, to produce insights on industry, business and career development.\n",
      "TFiR \n",
      "TFiR is an abbreviation for The Fourth Industrial Revolution. The company publishes news, analysis, interviews, op-eds and tutorials covering emerging technologies and open source. The coverage addresses new technologies, new business models, tech culture and their impact on society. A recent newsletter issue included an update from Richard Stallman, the open source software movement activist and self-described “Chief GNUisance.” Stallman announced the GNU Project’s goals, principles and policies will make incremental and not radical changes. TFiR targets CXOs, developers/operators and enthusiasts, according to its website.\n",
      "For more information, see AI World Sponsors. \n",
      "By Lance Eliot, the AI Trends Insider\n",
      "[Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/]\n",
      "Fear is considered one of the fundamental elements of emotion.\n",
      "It seems as though humans and pretty much all animals are prone to fear.\n",
      "Fear can be based on a real situation, such as you might be standing in front of a hungry lion and so you naturally are bound to be fearful of it, or fear might be based on a perceived danger that is not necessarily directly evident, such as walking down a dark alley and being inherently suspicious that something bad might happen to you.\n",
      "Typically, there is a physical response in a human or animal when experiencing fear.\n",
      "You have likely been on a roller coaster and in anticipation of that big drop up ahead your heart rate goes up, you feel your body tensing, your mind might become laser focused and you can’t think of anything other than the circumstance that you are facing.\n",
      "Humans have an ability to detect fear on others, including via facial expression analysis (someone’s face gets tense), the person might clench their teeth and make fists with their hands, etc. Of course, animals can also detect fear, of which I’m guessing you’ve had cases whereby a dog sensed your fear, maybe smelling your perspiration, and either took advantage of your fearful state or in some instances maybe even tried to reduce it.\n",
      "Responding to fear can be as simple as the classic fight-or-flight kind of response.\n",
      "If you fear something, you might decide to stand your ground and fight it. Alternatively, you might instead decide to run from whatever is causing the fear. Regrettably, sometimes while in the grip of fear we make bad choices. It could be that you should have chosen to run away from an angry bear rather than trying to confront it. Maybe trying to run away from an approaching ball of fire would have been better handled by trying to shelter in place.\n",
      "There are other options beyond just fight-or-flight, including one that can be the worst of them all, freezing up.\n",
      "Sometimes the fear is so overwhelming that trying to ascertain what to do is beyond our mental capacity at the moment, and thus we become frozen in fear. Though it might be possible that being frozen will work out okay in the given situation, generally some response is more likely to be successful than no response at all.\n",
      "Fear Plausibility\n",
      "Another twist to fear is that it can be considered plausible or implausible (some would say valid or invalid).\n",
      "Last year, there was a Chinese space station that was going to fall to earth and supposedly no one could predict where it would ultimately land.\n",
      "I had a colleague that told me he was fearful it could land on him.\n",
      "I tried to point out that the vast majority of the globe is water and so the odds were high that it would fall into the water and not strike anyone in particular.\n",
      "Even if it fell over land, I pointed out that by being inside a structure such as a building, it would seem unlikely he’d get hit and killed.\n",
      "The odds that he would be outside and be struck by it were likely much less odds than say winning the multi-state lotto (I realize he’d rather win the lotto than get hit by the space station). I suggested he buy the multi-state lotto ticket, the payout was around $500 million, and that maybe he’d win the lotto and get hit by the space station at the same time (those are some amazing odds!).\n",
      "Anyway, sometimes fear is in our minds, but not due to an actual fearful situation per se.\n",
      "We can convince ourselves to be fearful.\n",
      "In that sense, fear is definitely a dual-edged sword.\n",
      "Fear provides us with a vital survival technique. When utilized poorly, it can cause us to damage ourselves as based on a false believe that something dangerous is going to happen, when let’s say there’s really no chance of it happening at all.\n",
      "Some would refer to this as an unfounded fear.\n",
      "A fascinating recent study examined fear and described an angle that most would not have thought of.\n",
      "We all know that you are bound to be fearful of a predator.\n",
      "The field mouse is fearful of the swooping hawk. The prey is fearful of the predator, and rightfully so.\n",
      "This particular study pointed out that animals tend to avoid eating feces or munching on a carcass that has gone bad.\n",
      "Those aren’t predators, so why fear them?\n",
      "It’s because we are fearful of getting infections or disease, and seem to realize that we need to avoid circumstances that might involve getting infected by some untoward bacteria.\n",
      "Nature Versus Nurture\n",
      "How do animals know about this?\n",
      "In the nature-versus-nurture debate, are we programmed in our DNA to avoid things that might infect us, or do we only learn over time by either watching others, or by being taught, or by getting an infection and surviving it such that we realize not to do that again?\n",
      "If you see a hawk diving at you, it’s a pretty obvious aspect that maybe you should avoid letting it get you. But, seeing a juicy carcass, when you are starving, and opting to avoid eating it, because you somehow know that hours or maybe days later you might get sick, and might die, now that’s an interesting aspect of fear.\n",
      "You need to connect a later-on consequence to something that at the moment seems benign.\n",
      "The researchers described a landscape of fear.\n",
      "Animals will avoid drinking contaminated water.\n",
      "Animals will avoid eating a carcass when it seems too far gone.\n",
      "Animals will even graze away from an area that had a carcass, as though realizing that whatever is bad about the carcass could be spread locally beyond just the carcass. Animals tend to flee from biting ticks or try to get the ticks off their bodies.\n",
      "Within the landscape of fear, animals are able to detect infection threats. Either instinctively or in a learned manner, animals weigh the risks associated with the threats and try to achieve various levels of safety.\n",
      "For any of you interested in population dynamics and ecological aspects, you’d likely find this view of predator avoidance and infection avoidance of keen fascination.\n",
      "Fear Landscape And Autonomous Cars\n",
      "What does this have to do with AI self-driving driverless autonomous cars?\n",
      "At the Cybernetic AI Self-Driving Car Institute, we are developing an aspect of AI systems for self-driving cars that involves leveraging a landscape of fear regarding driving cars.\n",
      "Allow me a moment to elaborate on this somewhat surprising approach.\n",
      "As a human driver, you presumably already have a fear of hitting another car.\n",
      "You likely are fearful that you might hit a pedestrian.\n",
      "You probably also have a fear that other drivers are going to hit your car.\n",
      "You might have a fear that your car will fail on you, such as being on the freeway and all of a sudden it conks out and you are stranded in the middle of the busy freeway in a stalled car. It is possible you have a fear that the roadway will be unusable or impassable.\n",
      "The other day I drove up to the local mountains and reached a point that the paved road turned to packed dirt, which then became loose dirt, which then became muddy due to recent rains. My car almost got stuck in the middle-of-nowhere in an impassable road (I was driving just a conventional car and not an off-the-road vehicle).\n",
      "All of the above fears as a human driver are plausible.\n",
      "They are founded on a reasonable belief that those things could happen.\n",
      "We daily harness those fears while driving our cars. Some drivers though make driving mistakes as based on a fear that is either unfounded or at least that doesn’t actually materialize.\n",
      "I was in a car one day with a young driver that notably never made a left turn. He seemed to avoid to the extreme making a left turn.\n",
      "Now, we all know that left turns can be dangerous, and even some of the shipping companies such as UPS are using GPS systems that try to minimize the number of left turns. But, this was left turn paranoia.\n",
      "In talking with the driver, he shared with me a sad story of his family having gotten into a car crash while making a left turn, so he vowed that it would never happen again, which he figured by not making left turns would pretty much guarantee it. I did not have the heart to point out that his now heightened frequency of right turns, being done to make-up for not making left turns, might well have balanced out the risks of making a lesser number of left turns.\n",
      "His fear of left turns would not have been apparent or visible unless you were observing him, as I had, while a passenger in the car.\n",
      "If you had asked him about his driving approach, I doubt he would have volunteered that he won’t make left turns. An outside observer might not have noticed it either, unless you were following him like a secret agent.\n",
      "Our fears then can be hidden from view.\n",
      "Likewise, when I mentioned that you are fearful of getting into a car crash and fearful of your car faltering, it’s not something that you probably would have voiced if I had asked you about it.\n",
      "The word “fear” in our society has various connotations, generally being less flattering to the person that embodies the fear. What, you were fearful of riding that roller coaster, you’re a chicken! Society seems to pressure us to hide our fears and tend to not admit to them.\n",
      "For AI purposes, some believe that if we are to achieve true AI, and be able to make computer systems that can do what humans do, we need to replicate as much as possible whatever humans do.\n",
      "If humans rely on emotions, we must then incorporate emotions into computer systems to achieve true AI.\n",
      "There is a counter-argument that maybe we don’t need emotions to have intelligence, and so we can strip away some aspects of humans and yet still arrive at fully intelligent systems.\n",
      "Others say that our intelligence is intertwined with our emotions and you cannot separate them out and yet still have intelligence. Having a no emotions AI system would not end-up being fully intelligent as it has lost an essential component that is wrapped inextricably into intelligence, they would assert.\n",
      "Whether you stand on one side or the other of the debate about emotion and intelligence, I think we could say that fear is something that does make sense for an intelligent being to possess. If you are willing to consider fear as a form of mathematical calculation about the perceived dangers and risks, we certainly should have that same kind of capability built into our AI systems.\n",
      "As such, an AI self-driving car should make use of fear.\n",
      "That being said, I am not talking about the kind of “the sky is falling” kind of fear. I am referring to the notion of fear as a methodical means to try and determine risks and dangers, and seek actions to reduce those risks and try to achieve greater chances of safety.\n",
      "Example Of No Fear Producing Dangers\n",
      "I was in a car with a colleague that likes expensive cars and loves to drive fast (I would say recklessly, while he would say just fast).\n",
      "We were on the freeway in the leftmost lane, the fast lane.\n",
      "Our exit to get off the freeway was fast approaching. He gunned his engine and at the last moment darted across all of the lanes of traffic, having lined up small gaps in each lane, including darting in front of a very large truck hauling a tanker of gasoline.\n",
      "Did we make it to the exit ramp? Yes.\n",
      "Did we hit any cars or trucks? No.\n",
      "In my mind, I was quite fearful when I realized what he was going to try and do. He said that he had no fear because he had done this action many times and he “knew” that he could pull this one off.\n",
      "For an AI self-driving car, suppose it found itself in a similar situation.\n",
      "You might argue with me that the self-driving car would have been better prepared and would have gradually made its way over to the exit and not needed to leap toward it. But, suppose I told you that the occupant in the self-driving car had suddenly told the self-driving car that they wanted it to make that next exit.\n",
      "Thus, the self-driving car had little time to take the more gradual path to get to the exit.\n",
      "You could say that the AI should have refused to make the exit.\n",
      "The AI should have said that the occupant had been late in asking and so it was tough luck, and that instead the AI would route the self-driving car to the next exit and then via side streets make its way back to where that earlier exit had been.\n",
      "This brings up an important aspect about AI self-driving cars, namely, what is the nature of the driving approach that we want our self-driving cars to have?\n",
      "You might want the AI to do exactly what the “reckless” human driver had done, and have gone for it in terms of making a last gasp dive to the freeway exit. Why is the gradual approach better than the dive for it approach? You might assert that the gradual approach is certainly safer. By what proof do you claim this?\n",
      "In fact, those that believe we will have a Utopian world of all self-driving cars, which I’ve pointed out is unlikely and that at least for many decades we will have a mix of both human driven cars and self-driving cars, but if we do have all self-driving cars then presumably the dive to the exit would be as safe as any other maneuver.\n",
      "The self-driving car that wanted to dive to the exit could alert all the other self-driving cars nearby, via V2V (vehicle-to-vehicle communications), and the pathway that otherwise randomly had formed for the human driver might now become a designed path instead (based on the cooperation of the other self-driving cars).\n",
      "We could end-up with extremely aggressive AI self-driving cars.\n",
      "It all depends on how we program the AI and also what the AI is learning.\n",
      "Machine Learning Subtly Captures Fear\n",
      "Let’s consider the Machine Learning aspects of fear.\n",
      "Suppose you have an AI self-driving car that is learning about driving by observing traffic situations and trying to find patterns to the driving behavior, of which then the AI will adopt those same driving behaviors.\n",
      "In a traffic environment of reasonable human drivers that give proper way to other drivers and abide by legal speeds, the machine learning would find those patterns and presumably be a monkey-see monkey-do and perform driving in the same manner. We have artificial neural networks that indeed do this.\n",
      "Imagine driving in the chaotic streets of New York City at rush hour. Cars cut each other off. Cars drive within inches of other cars. Cars won’t let other cars into their lanes. It’s a dog eat dog world there. Without knowing the drivers, themselves, and by only looking at the outcomes of their driving, we have a different picture of what driving is all about.\n",
      "Deriving a pattern to driving behavior would be quite a contrast to a traffic environment of a more safety conscious wider-margins-for-error kinds of drivers.\n",
      "Thus, a neural network or other kind of machine learning will indirectly embody “fear” as it is embodied in the driving behavior of those that the system is learning from. We are not in this case of a machine learning approach explicitly calling out fear and making it part of the AI system as a separate component, and instead it is being captured via the behavior of the driving going on that is being used to pattern after.\n",
      "In one case, the fear of the drivers has led to more collegian driving outcomes, while in the other case the lesser sense of fear leads to cars that nearly hit or actually do include fender benders.\n",
      "We could though be more explicit about the fear aspects.\n",
      "The AI self-driving car has sensors that collect data for purposes of sensing the world around the self-driving car, and that data is then fed into the sensor fusion. The sensor fusion tries to figure out from the sensor data what is usable and what might not be, such as having a camera lens that is obscured by dirt and needing to rely instead on a radar that is able to detect that same area that the camera would. The sensor fusion then feeds into a virtual world model that depicts the existing and ongoing state of the surroundings and the self-driving car too.\n",
      "Based on the virtual world model, the AI needs to derive an action plan of what to do next with the self-driving car. If the situation involves accelerating to get between cars that are to the right of the self-driving car, this is then issued as commands to the controls of the self-driving car. As is the steering command to direct the self-driving car over into the next lane. And so on.\n",
      "It is within these AI action plans that we are immersing a healthy dose of fear.\n",
      "You want the self-driving car to be “fearful” of hitting other cars.\n",
      "You want it to be “fearful” of having other drivers hit the self-driving car.\n",
      "These are part of the algorithms of deriving the action plans.\n",
      "If the AI isn’t instructed or hasn’t learned to not hit other cars, it would likely come up with action plans that inevitably would be intentionally hitting other cars. Indeed, if you have ever watched a simulation that is used to train self-driving cars, you’ll see that the self-driving car action plans at first involve hitting other cars, but there is a points mechanism that helps the AI to realize that hitting other cars is not a good thing to do.\n",
      "By the use of Machine Learning, we are putting an “instinctive” landscape of fear into the AI of the self-driving car, and this is augmented by an explicitly taught landscape of fear by programming the AI code accordingly.\n",
      "Since we are on the topic of fear and AI self-driving cars, I should take a moment to also discuss a whole different aspect about fears and AI self-driving cars.\n",
      "There are humans that are fearful of being occupants in AI self-driving cars.\n",
      "I’ve discussed this at length in various forums and pointed out that though the media at times makes it seem that these are unfounded fears, I assert that people are right to have a healthy dose of fear about riding in today’s AI self-driving cars. Notice that I use the word “today’s” because I don’t want to suggest that we will always be fearful of riding in self-driving cars and instead differentiating that the existing crop of self-driving cars have yet to earn the right to have a low level of fear for occupants.\n",
      "On a similar vein, some humans are fearful about having AI self-driving cars on our roadways.\n",
      "This is due to a concern that the self-driving cars might hit other cars and strike pedestrians. Once again, I say these people are well justified in such a fear today. AI self-driving cars have yet to provide ample evidence to warrant our being fearless about how these self-driving cars might behave. I don’t believe this will be forever and just want to emphasize that it’s a condition of the state-of-the-art of what exists today.\n",
      "Returning back to my mainstay points about including fear into AI self-driving cars, I would want any self-driving car to have a reasonable fear of human drivers.\n",
      "Yes, that’s right, be fearful of human drivers. In the same manner that you or I are watching out for other human drivers, and we are leveraging our “fear” to gauge how we drive, it stands to reason that we want the AI self-driving cars to do the same. It needs to be a reasoned fear, and not an unfounded fear.\n",
      "As they say, once the AI has mastered the landscape of fear, the only fear it should have, will be fear itself.\n",
      "Copyright 2019 Dr. Lance Eliot \n",
      "This content is originally posted on AI Trends.\n",
      "\n",
      "AI is being applied to the biggest challenge facing the planet – climate change. Early results are encouraging.\n",
      "Machine learning can be deployed in energy production, CO2 removal, education, solar geoengineering and finance, among 13 relevant answers according to a paper titled “Tackling Climate Change with Machine Learning, present at a workshop in June as a way to focus research, according to David Rolnick, a postdoctoral fellow at the University of Pennsylvania and one of the authors.\n",
      "“It’s surprising how many problems in machine learning can meaningfully contribute to,” said Rolnick, quoted in an account in National Geographic. Possible outcomes include more energy-efficient buildings, new low-carbon materials, better monitoring of deforestation and greener transportation.\n",
      "Three specific areas where AI research could focus were suggested: better climate predictions, showing the effects of extreme weather and measuring where the carbon is coming from.\n",
      "Climate predictions can be enhanced by climate informatics, a discipline at the intersection of data science and climate science. It covers a range of topics including extreme events, reconstructing of past climate conditions, and large-scale models to be used for predictions. Climate modeling is progressing, with complex climate simulations having potential to unlock new insights.\n",
      "One project is using machine learning algorithms to combine the predictions of some 30 climate models used by the Intergovernmental Panel on Climate Change.\n",
      "Researchers at the Montreal Institute for Learning Algorithms (MILA), Microsoft and ConscientAI Labs are using General Adversarial Networks (GANs) to simulate what homes will look like after being damaged by rising sea levels and more intense storms. Plans include release of an app to show individuals what their neighborhoods and homes might look like with different climate change scenarios.\n",
      "Banking Industry Also Studying Climate Change\n",
      "A London-based not-for-profit consultancy called Caron Tracker is researching the impact of climate change on financial markets. It generates data by monitoring coal plant emissions with satellite imagery. Carbon Tracker is working to fulfill a UN goal of preventing new coal plants from being built by 2020. A grant from Google is expanding the effort to include emissions from natural gas plants, to help identify where pollution is coming from.\n",
      "“This can be used worldwide in places that aren’t monitoring,” said Durand D’souza, a data scientist at Carbon Tracker. “And we don’t have to ask permission.”\n",
      "Climate Change AI is an organization of volunteers from academia and industry discussing how computational science can mitigate climate change. Participants include Andrew Ng, co-founder of Google Brain, Deis Hassabis, a founder of DeepMind and Jennifer Chayes, managing director at Microsoft Research, according to an account in BBVA, serving the banking sector.\n",
      "AI is seen as helping improve the energy sector, where automated distribution networks can perform real-time smart assessments to fine tune supply and demand of electricity. Smart homes and intelligent operations and logistics in the construction industry, have the potential to lower the carbon footprint. Algorithms and machine learning make it possible to anticipate electricity demand of a city or a manufacturing plan months in advance. Power can potentially be distributed to small local populations more efficiently as a result.\n",
      "Google operates a fleet of wind farms in the US. Algorithms developed by Alphabet’s Deepmind researchers are able to predict wind farm energy 36 hours in advance, using advanced weather forecast technologies, now available.\n",
      "In transportation and logistics, data from the Intergovernmental Panel on Climate Change (IPCC) shows that between 1970 and 2004, the sector increased its greenhouse emissions by 120 percent. The potential is there for transportation companies to more accurately predict demand and avoid risks. DHL, the global logistics services provider, has developed software that can juggle up to 58 parameters to define optimal schedules for cargo airplanes days in advance. This should result in few flights.\n",
      "UK Government Backing New Doctoral Research on Climate Change\n",
      "The UK government is backing more research into climate change at Cambridge University, with a new doctoral training program on the Application of AI to the Study of Environmental Risks, to be led by Prof. Simon Redfern, head of the Department of Earth Sciences.\n",
      "The scientific community has access to larger datasets than ever before to help conduct this research. “These datasets represent a transformation in the way we can study and understand the Earth and environment, as we assess and find solutions to environmental risk,” said Redfern in an account in liwaiwai.com, a site aimed at programmers. “Such huge datasets pose their own challenges, however, and new methods need to be developed to tap their potential and to use this information to guide our path away from environmental catastrophe.”\n",
      "Projects underway include the use of satellite observations to chart the distribution and pathways of whales through oceans, large datasets to understand biodiversity changes in woodland habitats, machine learning to understand earthquake risk,and the use of drones to monitor hazards at active volcanoes.\n",
      "See the source posts at National Geographic,  BBVA and liwaiwai.com.\n",
      "Focus is on AI as a tool that guides in the detection of diseases; lighthouse projects showing results; public-private partnerships helping with access to needed data\n",
      "Dr. Angeli Moeller has two roles at Bayer Pharmaceuticals, she co-leads the artificial intelligence work stream and is responsible for the research digital investment strategy. Before joining Bayer she worked as a data scientist for translational medicine at Thomson Reuters and researcher at Cancer Research UK and the Max Delbrück Center for Molecular Medicine.\n",
      "As a keen proponent of pre-competitive collaboration, she also sits on the executive committee of the Alliance for Artificial Intelligence in Healthcare (AAIH) and on the investment committee of the Pistoia Alliance.\n",
      "Moeller is driving work at Bayer to employ AI to help get the right treatment to the right patient at the right time. Bayer Pharmaceuticals invests in lighthouse initiatives that use AI to drive top-line and bottom-line growth, while accelerating digital transformation. She recently spent a few minutes talking to AI Trends Editor John P. Desmond.\n",
      "Could you describe your responsibilities at Bayer?\n",
      "The IT business partnering team I lead is in the pharmaceutical research area, and it is responsible for the digital investments in both the pre-clinical area and investments that cover cross-R&D projects. I took on that role in May last year, at which time I was also appointed co-lead of our artificial intelligence work stream for the entire pharmaceuticals division, a role I share with a colleague from the strategy team, Michael Heinke. The scope of the AI workstream encompasses R&D, medical affairs and pharmacovigilance, commercial and product supply. The projects are run by several empowered teams working across our value chain, strongly supported by external partnerships, and enabled by our parallel data architecture workstream.\n",
      "Dr. Angeli Moeller, AI Program Lead, Bayer Pharmaceuticals\n",
      "You have concentrations in your career in molecular biology, protein chemistry, and cell biology for example. What impact is new AI technologies having on those areas of research?\n",
      "When I started my PhD at Edinburgh University, I was doing lab work coupled with informatics. We were getting so much data from our phage-display methods we were only able to make predictions leveraging bioinformatics. Subsequently in my post-doc, the value of predictions made possible through machine learning became increasingly critical. You can call it artificial intelligence or you can call it machine learning. At the time, it became clear to everyone working in molecular biology that you couldn’t just study molecular biology. You had to also be working in data science or informatics.\n",
      "The rise of AI in research has been triggered by two big trends. Firstly, that lab automation now creates datasets so large that we can make increasingly accurate predictions with methodologies like machine learning, because we now have the compute power needed. The other trend, which is driving things forward is translational research. For molecular biology, protein biochemistry and cell biology, it can be limiting to treat research as a sequential process, for instance to start in vitro then go into animal studies or human studies. During my time in academia we increasingly began building predictions from in vivo experiments and clinical studies, using meta-analysis across investigations conducted in the past. Although the need to validate predictions is still the critical next step.\n",
      "The rise of translational medicine and machine learning has completely changed the way that we can look at molecular biology and protein biochemistry. For example, in the first year of my PhD I looked at interactions between two or three proteins in detail whereas in my postdoc we worked on modeling the human chemical synapse and predicting protein-protein interactions. The parameters modelled came from mouse knock-out studies, genome-wide association studies, high-throughput cell line screening and only through integration of these varied data sets were we able to model the thousands of complex interactions at a single synapse. Now add to that a model of all synapses across the brain, at various timepoints in different states of activation and we can really start to tackle some interesting medical questions.\n",
      "Could you describe one or more of the initiatives using AI to drive growth at Bayer?\n",
      "Within Bayer, we have a series of AI projects with the shared objective of getting new medicines to patients more quickly and efficiently. To achieve this goal, our projects tackle various aspect of the value chain from drug development, to clinical development, to market access, to product supply, to commercial, to providing information to health care professionals and enabling reimbursement.\n",
      "One example is our CTEPH app, which got a breakthrough device designation from the FDA. It is based on an artificial neural network.\n",
      "[Ed. Note: Chronic Thromboembolic Pulmonary Hypertension (CTEPH) Pattern Recognition was given a Breakthrough Device Designation in December 2018 by the FDA.]\n",
      "CTEPH is an indication where patients have blood clots forming in their lungs. It manifests in symptoms where you have high blood pressure, shortness of breath or you feel very fatigued. These are also symptoms of other diseases so it can be very difficult to diagnose. But using our algorithm, which runs on the CT images of patients, we aim to detect very early whether or not patients are suffering from CTEPH. And then if they are suffering from CTEPH to make sure they get on the right treatment very quickly. For us it’s all about getting the right medicine to the right patient as quickly and as efficiently as possible.\n",
      "The second example is in the heart failure and stroke area. We have a collaboration with Sensyne, a startup operating in the UK, and the goal is to use data from several National Health Service Trusts to identify new biomarkers in heart failure and stroke. The team is exploring a range of machine learning approaches across those data sets.\n",
      "What are some of the challenges you face in applying AI to healthcare in your research areas?\n",
      "One key challenge is education. Many people fear that artificial intelligence will take away choice from patients and doctors. It’s important to us that AI is used as a tool that guides us in the detection of diseases and makes treatment recommendations. But in the end, the control over which treatments are given to which patients is still something that patients and their doctor decide together, using more accurate information to make that decision.\n",
      "We want to provide the most accurate information for the researchers who are developing the drugs, the doctors who are testing the drugs and prescribing the drugs, and for the patients who are being treated by the medicines. We don’t want to take away control of making decisions from anyone. And I think there it’s really important when we put the applications into clinical practice or into hospitals that we’re very careful to make sure that it’s used in the right way. So that in the end, the control of the decision-making processes is still with the doctor and their patient.\n",
      "Are there any other challenges?\n",
      "Getting access to the data we need is a very big challenge. For machine learning to be meaningful, you need very large data sets. However, we’re using a number of approaches that mean we don’t have to clean and curate the data sets to the extent we did in the past. Additionally, federated learning means that we can now train our models on data that is stored in different locations without moving the data. We train an algorithm behind the firewall of different data owners who ensure the security and integrity of the data, this allows the model to improve its predictive power using the data without having to put all the datasets together. Which is very important because for most patient data, it has to stay in a very secure local environment.\n",
      "But just trying to find enough data can be a daunting challenge. What’s going to be very important is establishing public-private partnerships, B2B partnerships, and academic partnerships, which will make safe access to data possible. This will drive forward innovative disease research using artificial intelligence.\n",
      "What is the role of the Alliance for AI in healthcare that you helped to found?\n",
      "The Alliance is dealing with exactly the challenge I mentioned earlier around education. Our core focus is to do that together with policy makers and academic thought leaders.\n",
      "We founded the Alliance because we wanted to stop this from being a competitive approach, and make it a pre-competitive approach where different companies work together to do what is in the best interest of the patients who can benefit from this new technology. That’s why within the AAIH you have large pharma and tech companies working together with university partners and biotech to try and tackle these issues.\n",
      "Our education committee works with member companies to create internships for students who want to move into AI in healthcare and to provide educational material useful for doctors who are starting to think about how they can use AI-based applications.\n",
      "How has the role of IT changed, if at all, since the growth of AI technology at Bayer?\n",
      "I work in IT. At some companies people would have asked “why is this person working in the IT department?” The answer is that at Bayer, IT teams must understand how emerging technologies can best be applied to meet the needs of the business, in my case the pharmaceutical division, therefore an increasing number of our hires have a data-science background often coupled with experience in an area of pharma, e.g. commercial, product supply or R&D. Our pharma IT organization works in cross-disciplinary teams that include cloud-engineers, data scientists, biosample experts, bioinformaticians, clinical data managers, just to name a few.\n",
      "How far along is it the digitization of pharma, would you say?\n",
      "As an industry… it’s an interesting question. When I was at Thomson Reuters, which was only three years ago, I had clients which made up five of the largest pharmaceutical companies in the world. Now I sit in the Pistoia Alliance, in which 19 of the top pharma companies work together on pre-competitive projects. So based on those observation points, I’d say it’s very uneven. Some pharma companies are further ahead than others. Many have focused in certain areas and certain parts of the pharmaceutical process and not in others. I would say that, compared to other industries, we’re still just entering our digital journey, but I think some of us have understood that we must move at a highly accelerated rate to enact our digital transformation.\n",
      "Are you able to find the people you need to get the AI work done at Bayer? What do you look for in new hires?\n",
      "We are making really good hires, I have had the opportunity to work with new employees with extraordinary talent in the last year. But the market for data scientists is very competitive. There are not enough highly skilled machine learning experts in the world right now. This is why we’re working on the pipeline of talent coming out of universities, e. g. with internships we are creating with the Alliance for AI in Healthcare.\n",
      "We are also able to offer very good packages, which makes us an attractive employer. On a personal note, I’m the mother of a young child and I like to keep a healthy work-life balance. This is what Bayer has to offer and that helps us to attract talent.\n",
      "Another important point is that if you’re working on AI in healthcare, you always have a strong motivation for what you’re doing. Here we are implementing AI to help keep people healthy or to fight diseases like cancer. This makes a difference in comparison to pure tech companies.\n",
      "Most of our lighthouse case work on artificial intelligence is in cardiovascular disease and oncology right now. Many people have a loved one affected by diseases in these areas. For instance, my own family has a very high incidence of serious cardiac events. A lot of our work in artificial intelligence is still in early research stages, but knowing we’re working to have a positive impact on diagnosis and treatment is very rewarding.\n",
      "Do you have any advice for young people interested in a career in AI for what they should study if they’re students, or if they’re early career where they should concentrate?\n",
      "For young people entering their career, it’s critical to invest in your hard skills, e.g. statistics and programming. For people who have done that and are now looking to expand in their career in industry, it’s necessary to also demonstrate business understanding. If I look at my job today, it also involves discussions on financial impact, population health economics and a broader understanding of how a strategy for artificial intelligence can be developed. So I think then having more business insight is critical for that further career development. Lucky for me we have a lot of coaches and mentors at Bayer in senior positions who are always ready to support fellow employees developing new skills.\n",
      "Bayer is invested in helping young people start data science careers in healthcare. If any of your readers are interested, we have our job portal, we’re very active on LinkedIn, and we also host a lot of networking events.\n",
      "Is there anything you would like to add?\n",
      "I like to emphasize that we keep the patient at the center because I think it’s very easy to get swept up in the technology. If we keep the needs of the patient at the center of our strategy, then we’ll stay on the right track.\n",
      "Follow Angeli Moeller on LinkedIn.\n",
      "By Lance Eliot, the AI Trends Insider\n",
      "[Ed. Note: For reader’s interested in Dr. Eliot’s ongoing business analyses about the advent of self-driving cars, see his online Forbes column: https://forbes.com/sites/lanceeliot/]\n",
      "You’ve likely had to enter a series of numbers and letters when accessing a web site that wanted “proof” that you are a human being and that you were not some kind of Internet bot. The typical approach involves your visual inspection of a grainy image that contains letters and numbers, and then having to try and figure out what those letters and numbers are.\n",
      "It is intentionally made difficult due to the aspect that the letters and numbers are usually smashed together, and they are often twisted and distorted so as to be hard to discern.\n",
      "These challenge-response tests are known as CAPTCHA, which is an acronym for “Completely Automated Public Turing test to tell Computers and Humans Apart.”\n",
      "The idea is that if a website wants to keep automated bots from accessing their site, there needs to be some means to differentiate between whether a human is trying to access the web site or whether it is some kind of automation.\n",
      "Humans are quite good at visually being able to discern letters and numbers, and so the CAPTCHA aids in distinguishing whether the response is va a human or a bot. Automated systems have a difficult time trying to ferret out amongst a twisted and distorted mix of letters and numbers the intended indication of what those distinct letters and numbers are.\n",
      "Some people don’t know why the CAPTCHA is being used and are pretty much just irritated by the whole thing.\n",
      "Why do I have to look at this stupid and obviously messed-up list of random letters and numbers, asks those that are not in-the-know.\n",
      "Makers of web sites are at times hesitant to use the CAPTCHA because it could dissuade people from using the web site and decrease the number of potential visitors to their site. But, those pesky automated bots that might otherwise become “false” visitors, meaning that the site might believe them to be actual humans, and also there are potential adverse aspects a bot might do at a web site, and so in the end it often is worthwhile to consider making use of CAPTCHA.\n",
      "Now, you might be puzzled that the CAPTCHA is not readily able to be hacked by automation.\n",
      "One might assume that with the tremendous advances in Artificial Intelligence (AI) in recent times, certainly there must be a means to figure out those grainy images via automation.\n",
      "Well, it depends partially on how strong the CAPTCHA is. If the CAPTCHA makes use of a varied combination of letters and numbers that are really swerved and mushed together, along with varying the height and width of the characters, and if the number of such characters is sizable enough, the ability for an AI system to figure it out is quite limited today.\n",
      "Of course, the worse it is for the AI also means that it is likely harder for humans to figure out too. And, if it gets too hard for humans, you’ll have neither bots nor humans being able to pass the test. That’s not very helpful in that it will simply prevent anyone or anything from succeeding – you might as well close down your web site since it won’t be accessible at all.\n",
      "To properly recognize the CAPTCHA, you need to perform at least three key visual and mental tasks:\n",
      "* Recognition\n",
      "You need to visually examine the image and recognize that there are letters and numbers in it.\n",
      "Any of the characters can be enlarged or shrunk in size, and can be at various angles. They can be stretched or squeezed together. The parts of one character might be merged with the parts of another character. The number of variations is seemingly endless of how the CAPTCHA can obscure conventional letters and numbers.\n",
      "Humans seem to be able to relatively easily handle these invariant recognition aspects, namely that we can very quickly realize the essence of a letter or number shape, in spite of the distortions made to it.\n",
      "* Segmentation\n",
      "If I show you a letter or number and it is displayed on a standalone basis, such as the letter “h” and the letter “e,” you have a much easier time generally of figuring it out.\n",
      "On the other hand, if I merge them with other letters and numbers, such as pushing together the “he” and making each flow into the other directly, it typically becomes harder to discern. The true shape of the letter or number becomes masked by its being merged with other letters and numbers.\n",
      "You need to be able to mentally disentangle the crammed together numbers and letters into a series of distinctive chunks, and within each chunk try to reconstruct what the individual letter or number might be.\n",
      "* Contextual\n",
      "By having multiple letters and numbers, you can often improve your odds of guessing any individual letter or number by considering the context of the characters within the overall image. That being said, many CAPTCHAs don’t use regular words, since it would make things perhaps too easy to guess the individual characters. If the letters were “d” “o” “g” and you were able to guess the first two letters, it might be overly easy to guess the third letter. If instead the letters were “d” “g” “o” then you might not so readily be able to guess the entire set of letters because it does not make into a word that you would normally recognize.\n",
      "There are numerous variations nowadays of CAPTCHA algorithms.\n",
      "Some use just letters and numbers, while some also add into the mix a variety of special characters such as an ampersand and a percentage symbol.\n",
      "You’ve likely also encountered CAPTCHA that ask you to pick images that have something in common. For example, you are presented with six images of a grassy outdoor field, and are asked to mark the images that have a horse shown in the image. These aren’t so easy because the horse will often be obscured or only a small portion of a horse appears in any given image.\n",
      "The reason why the acronym of CAPTCHA mentions a Turing test is that there is a famous test in the field of AI that was proposed by the mathematician Alan Turing about how to determine whether an automated system could exhibit intelligence.\n",
      "The test consists of having a human ask questions or essentially interview another human and a separate AI system, for which the interviewer is not privy beforehand as to which is which, and if the interviewer is unable to tell the difference between the two interviewees, we presumably could declare that the automation has exhibited intelligent behavior.\n",
      "There are some that are critical of this test and don’t believe it to be sufficient per se, but nonetheless it is quite famous and regarded by many as a key test for ascertaining AI.\n",
      "In the case of CAPTCHA, the Turing test approach is being used to see if humans can outwit a bot that might be trying to also pass the same test.\n",
      "Whomever is able to figure out the letters and numbers is considered or assumed to be a human. Thus, if the bot can indeed figure out the CAPTCHA, it momentarily has won this kind of Turing test. I think we would all agree that even if some kind of automation can succeed in winning in a CAPTCHA contest, we would be hard pressed to say that it has exhibited human intelligence. In that sense, this is a small and extremely narrow version of a Turing test and not really what we all truly intend a Turing test to be able to achieve.\n",
      "In fact, because the human is having to essentially prove they are a human by passing a CAPTCHA, some refer to this test as a Reverse Turing test.\n",
      "Here’s why.\n",
      "The limelight of a conventional Turing test is for the automation to prove it has human-like capabilities. In this reverse Turing test, it is up to the human to prove that they are a human and able to perform better than the automation.\n",
      "There is a popular CAPTCHA algorithm used as a plug-in for many WordPress developed websites that is known as “Really Simple CAPTCHA.”\n",
      "In a recent article about it, a developer showed how easy it can be to develop a simple AI system to be able to succeed at cracking the CAPTCHA challenges.\n",
      "The CAPTCHA in this case consisted of a string of 4 characters that used a mixture of four fonts, and it avoided using the letters “o” and “i” to reduce any confusion by the humans that have to try and figure out the CAPTCHA generated images. Notice that by these limitations it becomes a much smaller problem to be solved, in the sense that rather than say using a string of 10 characters and using 25 fonts, and by eliminating some of the letters, the solution space is a lot smaller than otherwise.\n",
      "The developer wanting to crack it used the popular Python programming language, along with the OpenCV set of programs that are freely available for doing image processing, and Keras which is a deep learning program written in Python. He also used TensorFlow, which is Google’s machine learning library of programs (Keras uses TensorFlow). I mention the tools herein to be able to emphasize that the developer used off-the-shelf programming tools. He didn’t need to resort to some “dark web” secretive code to be able to proceed to crack this CAPTCHA.\n",
      "The CAPTCHA program was readily available as open source and therefore the developer could inspect the code at will.\n",
      "He then used the CAPTCHA to generate numerous samples of CAPTCHA images, doing so to create a set of training data. The training data consisted of each generated image and its right answer. This could then allow a pattern-matching system such as an artificial neural network to compare each image to the right answer, and then try to statistically figure out a pattern for being able to go from the seemingly inscrutable image to the desired answer.\n",
      "After doing some transformations on the images, the developer fed the images into a neural network that he setup with two convolutional layers and with two hidden connected layers. According to his article, by just having ten passes through the training data set, the neural network was able to achieve full accuracy. He then tried it with actual new CAPTCHA generated by the “Really Simple CAPTCHA” code, and his efforts paid-off as it was able to figure out the letters and numbers. This particular article caught my eye due to the claim that from the start of this project to the finish it took just 15 minutes of time.\n",
      "Now please keep in mind that this was a very simple kind of CAPTCHA.\n",
      "I don’t want you to get a misleading impression that all CAPTCHA is as easy to crack as this.\n",
      "I assure you that there are CAPTCHAs today that nobody has any kind of AI or any software that can crack it with any kind of assurance or consistency. CAPTCHA is still a relatively good means to try and distinguish between a human and a bot. The CAPTCHA just has to be tough enough to weed out the commonly used methods of cracking the CAPTCHA.  By convention, CAPTCHA is normally made available as open source code.\n",
      "Thus, some would say that it increases the chances of being able to crack it.\n",
      "What does this have to do with AI self-driving driverless autonomous cars?\n",
      "At the Cybernetic AI Self-Driving Car Institute, we are using open source software to develop AI self-driving systems, and so are most of the self-driving car makers and tech firms, and this is both a boon and a danger.\n",
      "As discussed about the CAPTCHA algorithm, it was available as open source, meaning that the source code for it was publicly available. Anyone that wanted to look at the source code can do so.\n",
      "By looking at the source code, you can figure out how it works. By figuring out how it works, you are a leg-up on being able to find ways to crack it.\n",
      "If you don’t use open source code, and instead develop your own proprietary code, you can try to keep the source code secret and therefore it is much harder for someone else to figure out how it works.\n",
      "If an attacker does not know how the code works, it becomes much harder to try and crack it. This does not mean it is impossible to crack it, but merely that it is likely going to be harder to crack it.\n",
      "Some refer to the open source approach as a white box method, while the proprietary code approach as a black box method. With a black box method, though you know what comes into and out of it, you don’t know what is going on inside the box to do so. Meanwhile, with a white box method, you know what goes into it and comes out, along with how it is doing its magic too.\n",
      "Today, open source code is prevalent and found in an estimated 95% of all computer servers, along with being used in high profile systems such as the systems that run stock exchanges and the systems that run the International Space Station. Some estimates say that there is at least 30 billion lines of open source code available, but even that number might be understated.\n",
      "Notably, open source is extensively used for AI software and many of the most popular AI packages today are available as open source.\n",
      "Generally, there is an ongoing debate about the use of open source as to whether it is unsafe because of the potential for nefarious hackers to be able to readily inspect the code and find ways to hack it, or whether it is maybe safer than even proprietary software because you can have so many eyes inspecting it.\n",
      "Presumably, something that is open to anyone to inspect can be seen by hundreds, thousands, maybe millions of developers, and that such a large number of reviewers will ensure that the open source code is safe and sound to use.\n",
      "One caveat about using open source is the classic use-it-and-forget-it aspect that arises for many developers that decide to use open source code in their own systems.\n",
      "Developers will go ahead and wrap the open source into a system they are building, and pretty much move on to other things. Meanwhile, if a hole is spotted in the publicly posted open source, and if there is a fix applied to the hole, the developer that grabbed the open source at an earlier time might not be aware of the need to apply the fix in their instance. This can happen readily by the aspect that the developer forgets they used that particular open source, or maybe they don’t become aware of the fix, or they no longer have anything to do with the developed proprietary code and others that are maintaining it don’t know that it includes the open source portions.\n",
      "One of the most infamous cases of open source being exploited consists of the Heartbleed computer security hole that was discovered in the OpenSSL cryptographic source code.\n",
      "In OpenSSL, there is a part of the code that sends a so-called heartbeat request from one system to another system. This is an important program that is used by most web sites to ensure a secure connection, such as for doing your online banking.\n",
      "When making the request, the requesting system would normally send a message of one size, let’s say 10 characters in size, and expect to get back the same message also of 10 characters in size. Turns out that if the requesting system sent a message that asked to get back 300 characters but only sent 10 characters, the system providing the response would be misled into sending back 300 characters — of which, 290 of those characters might contain something sensitive from that system inadvertently. In programming parlance, this is often referred to as a buffer over-read problem.\n",
      "In 2014, this hole immediately became headline news once it was pointed out.\n",
      "The significance of the hole was that it made zillions of interacting systems that were thought to be secure to potentially not be so secure.\n",
      "The clever name of “heart bleed” was given to this security hole, since it is related to the heartbeat portion of the systems and was now essentially bleeding out secure info. The hole was quickly plugged, and the matter was logged into the global registry of Common Vulnerabilities and Exposures (CVE) database for everyone to know about. Nonetheless, many did not right away apply the fix to their systems, even though they should have done so.\n",
      "Currently, most of the automakers and tech firms are feverishly incorporating all sorts of open source into their AI of their self-driving cars systems.\n",
      "It makes sense to do so, since otherwise you would need to reinvent the wheel on all sorts of software aspects that are needed for a self-driving car.\n",
      "The cost to develop that same open source from scratch would be enormous. And, it would take time, lots of time, in order to create that same code. That’s time that nobody has. Indeed, there is a madcap rush today to achieve a true self-driving car, and no one developing self-driving cars wants to be left behind due to writing code that they could otherwise easily and freely get.\n",
      "We do need to ask some serious questions about this.\n",
      "Does the use of open source in the AI and the other software of the self-driving cars mean that we are laying ourselves bare for a substantial and really ugly security problem down-the-road, so to speak?\n",
      "Some would say, yes.\n",
      "Are there nefarious hackers that are right now inspecting the self-driving car open source code and looking for exploits?\n",
      "Some would say, yes.\n",
      "If they are looking for exploits, there’s not much reason right now for them to reveal those holes, and so they presumably would wait until the day comes that there are enough self-driving cars on the roads to make it worthwhile to use such an exploit. Plus, once self-driving cars do become popular, it is likely to attract hackers at that time to begin inspecting the open source code, hopeful of finding some adverse “golden nugget” of a hole.\n",
      "This open source conundrum exists for all aspects of self-driving cars, including:\n",
      "\n",
      "Sensors – open source software for sensor device control and use\n",
      "Sensor Fusion – open source software for sensor fusion\n",
      "Virtual World Model – open source software for virtual world modeling\n",
      "Action Planning – open source software for creating AI action plans\n",
      "Controls Activation – open source software to activate the car controls\n",
      "Tactical AI – open source software for self-driving car tactical AI\n",
      "Strategic AI – open source software for self-driving car strategic AI\n",
      "Self-Aware AI – open source software for self-driving car self-aware AI\n",
      "\n",
      "Depending upon how a particular car maker or tech firm is building their self-driving car, each element is likely to either have open source in it, or be based upon some open source.\n",
      "It is incumbent upon the self-driving car industry to realize the potential for exposures and risks due to the use of open source.\n",
      "Self-driving car developers need to be make sure they are closely inspecting their open source code and not just blindly making use of it.\n",
      "Any patches or fixes need to be kept on top of. We need more audits of the open source code that is being used in self-driving cars. And, overall, we need more eyeballs on reviewing the open source code that underlies self-driving cars. As mentioned earlier, it is hoped that the more “good” eyeballs involved will mean that any holes or issues will be caught and fixed before the “bad” eyeballs find them and exploit those holes.\n",
      "If the bad eyeballs have their way, it will be not so much a CAPTCHA as a GOTCHA.\n",
      "Copyright 2019 Dr. Lance Eliot \n",
      "This content is originally posted on AI Trends.\n",
      "\n",
      "By John P. Desmond, AI Trends Editor\n",
      "AI has changed the game for service providers. Client companies now expect the service provider will deliver on the promise of AI for them, or help them get moving in the right direction. We spoke about trends in AI and services to executives of two service providers recently: Asheesh Mehra, co-founder and CEO of AntWorks; and Prabhdeep (PD) Singh, VP of AI at UiPath.\n",
      "AntWorks, founded in 2015, is an AI and intelligent automation company, with a platform that understands every data type. The company digitizes every bit of information from a wide range of industries. Mehra is co-founder and group CEO; his background includes seven years at Infosys working in business process outsourcing in Asia Pacific, Japan, and the Middle East. The company offers the ANTstein intelligent automation. It supports robotic process automation support, intuitive machine learning, and natural language modeling capabilities.\n",
      "UiPath of New York City is an AI enterprise software company known for AI, machine learning, and Robotic Process Automation. The company was recently positioned in the upper right Leaders quadrant in Gartner Magic Quadrant for Robotic Process Automation Software.  Prabhdeep (PD) Singh, VP of AI at UiPath, was at Microsoft for nearly 10 years before coming to UiPath a year ago. He led the product and business teams for the Microsoft Sales Intelligence AI solution.\n",
      "Mehra and Singh were interviewed separately by AI Trends Editor John P. Desmond.\n",
      "How has AI changed the game for service providers?\n",
      "Asheesh Mehra, co-founder and CEO of AntWorks: Some customers expect AI to be a magic wand that can start delivering results overnight. However, an AI engine is not magic. It needs training at the back end before it can start performing an action. It can start learning from the representative data set that is received over a few months. Then it can start its machine learning capability to help make intelligent decisions, or start predicting or inferring dependent of the representative data set it has seen over the months it has been deployed at an enterprise.\n",
      "So, is it changing expectations of customers? The answer is absolutely, yes. Some expectations are realistic, and some expectations are unrealistic. Is it impacting the end customer of enterprises? It is. In some ways it’s impacting them by making their lives, their day-to-day jobs a lot easier because it is now a helping hand, or a joint force with the human. When you put both together, you get a far superior outcome.\n",
      "Asheesh Mehra, co-founder and CEO, AntWorks\n",
      "Prabhdeep (PD) Singh, VP of AI at UiPath: The way the older service providers would typically solve business problems would be to have a human sitting in some back room doing this stuff for you manually. But now the automation has reached a stage—and the set of technologies that are available to us have reached a stage—where you can optimize pretty much every and any business process. If you remember, the name of the game for these BPO [Business Process Outsourcing] providers was to get down the cost. That’s why you couldn’t run call centers here in the US, because the cost of employing humans was just too high.\n",
      "That’s when people started going to places like India, Vietnam, and all these other places where you had English-speaking populations, but it was much cheaper to hire people. It was more of this cost optimization, cost-cutting exercise. With AI and automation coming in, there is a paradigm shift happening in the sense that you can actually increase the productivity of those humans and drive down the costs even more. We talk about this in almost every conference that I’ve gone to. If you look at the workforce productivity for the US over the last decade, it has pretty much plateaued. After we had a saturation of PCs, pretty much for all and every knowledge worker. And now in order to increase the productivity of those information workers in the workforce, you need more of AI and automation. We are seeing that, and many of our customers are getting monetary and productivity gains by automating and deploying AI in their business processes.\n",
      "Is AI delivering?\n",
      "Mehra of AntWorks: That’s a very loaded and very difficult question to answer. Yes, it’s delivering in certain spaces and in certain areas. I think AI is over-hyped and not delivering in certain other cases. If I had to use an example from the insurance world, I think AI is delivering on its promise for processing claims, being for your health, or your house, or your car. It is delivering there. There is room for AI to be improved and enhanced to deliver the outcome it is promising in some other industries, such as financial services.\n",
      "If I was to summarize that, I’d put the bar right in the center and say depending on the use case and depending on the industry segment, AI is delivering; and for where AI is not delivering, it has not been exposed and trained enough in those spaces.\n",
      "Singh of UiPath: When AI works, it’s magical. I’ve seen it work in both large companies and small startups. I’ve seen it save lives. I worked on systems that can do things like readmission prediction. It can predict if a patient is going to come back within 30 days, and the doctors can look at it and say, “Okay, let’s not discharge this patient right now.” If you have a system like that, you’re actually saving lives, because you’re not sending really sick patients home where adverse things can happen to them. You’re also saving money, because if you look at the Medicare/Medicaid guidelines, if the patient comes back within 30 days, the government is not going to reimburse you for the readmission.\n",
      "Prabhdeep (PD) Singh, VP of AI at UiPath\n",
      "The problem right now in the AI industry is what we call the last mile problem. If you look at the AI deployments, only 4% of CIOs have put something in production. Almost 90% to 95% of CIOs want to do something with AI. They know kind of where AI can be useful. Actually putting a system into production is a completely different beast. So once you have a machine learning model that works, you need to put it into production, have it interact with humans, with the existing applications. That’s where RPA [Robotic Process Automation] is useful, because RPA is the last mile vehicle for all things AI.\n",
      "Are there problems for which AI is not a fit?\n",
      "Mehra of AntWorks: If you take a step back and ask what is AI, the definition varies. In my view, AI is all about learning and then a machine taking intelligent decisions or providing accurate predictions on the data that it has received. Do we say, “No” to customers when we think we or the AI is not equipped? The answer is absolutely, yes. We do say, “No” to customers when we think we cannot deliver a particular piece using our machine learning or other algorithms. Because as I said, the expectation might be that AI is a magic wand.\n",
      "The fundamental philosophy at AntWorks is, “Say no where you have to say it. When you say ‘yes’, get it right the first time.”\n",
      "Can AI be deployed in every single use case in an enterprise? The answer is no. I don’t think AI is mature enough to go out there and solve every kind of challenge today that an enterprise experiences. We see a lot of room for the AI engines to be trained to become smarter and more intelligent to deliver to customer expectations.\n",
      "Singh of UiPath: I will say, the things that are non-digitized are problems that you cannot optimize with AI. You see many AI use cases in sales and marketing, because sales and marketing is highly digital. If an industry has gone through digital transformation, that’s where AI can be very useful. But if you have antiquated processes, and you actually never digitized, then it’s a little difficult. For example, if there was a company doing everything paper-based and old school very well, the first process is to get that paper scanned and put it in digital format before you can apply anything intelligent on top of that information.\n",
      "Do AI engagements take more time than the former non-AI way of solving problems?\n",
      "Mehra of AntWorks: No, absolutely not. One of the whole drivers to make a business case positive is to cut the time it takes to do projects. The whole objective is to speed up the business process and to ensure that accuracy is a lot higher. So does it take more time? The answer is no. If it does take more time, it’s probably taking a lot more time because not enough training has been done for the engine and it has been deployed prematurely.\n",
      "No different to when you bring a human being into an enterprise, the first four weeks of them coming in or the first three weeks or the first six weeks, is to train that individual on how to perform their job, or how to deliver that outcome. An AI engine is no different. If you expect an AI engine to start delivering the results that you’re expecting without spending enough time on training the engine, it will not deliver for you.\n",
      "So the marketplace needs to understand how to make your AI or machine learning engine deliver results for you. There are no shortcuts. You need to invest the right amount of time and expose the AI engine to the right amount of representative data for it to deliver results for you.\n",
      "Singh of UiPath:  I would say no. If you planned your system correctly, it’s much easier to solve problems and much more effective to solve problems with AI versus the older way. For example, if you remember the old school real estate agents, there were good agents and there were bad agents. The really good sales people didn’t need any of these electronic nannies and electronic aids like CRM systems. They were just going in, doing it the old school way, pounding the pavement, being really good at selling stuff.\n",
      "My point is if you have a problem which is highly dependent on human expertise, it will take time to have AI go in and improve it. But if there is a process where you are not realizing the human efficiencies to the maximum, that is where AI can make a big difference.\n",
      "What are your challenges?\n",
      "Mehra of AntWorks: I have a few challenges today. One of my first challenges is market share. I’m a four year old company. I’m against all the names from a competition perspective. They’ve all been around for longer, have captured a large market share and I’m playing catch up. So we took time to build the technology and the whole platform out while they were out there selling single technology tool sets. So now it’s my turn to capture market share.\n",
      "My second challenge is that the understanding level of the buyer varies to a large extent. On a scale of one to 10, a very large percentage of buyers are at three and below. There is a very small percentage of buyers that are in the seven, eight, nine, and 10, from a rating perspective. That starts becoming a challenge because the expectations that they have, and what reality is are a vast distance apart. So we need to deploy larger resources to help educate the marketplace.\n",
      "The third challenge is around the expectation of what AI is. There is just so much hype and white noise in this whole AI space right now. This puts pressure on you as a product company because people dream up things and it becomes a challenge. The minute you start pushing back, and say, “That’s not really what we can deliver, or a machine can deploy”, you start creating a sense of dissatisfaction in the buyer community. But you are being realistic. So, that truly is another challenge for me. Those are the three challenges for me today.\n",
      "Singh of UiPath: Once you start deploying these systems in an enterprise at a very large scale, a couple of things happen. Enterprise software is a very well-understood area. The people who deploy software and applications in their enterprise, with traditional software applications, have a very well-understood product. With AI applications, it’s not just a matter of deploying software. AI models work off of data. The data must be clean, the data pipelines need to run properly, and the AI models need to work well. That whole vision is our principle. If, for example, the data shuts off at the input, the model starts behaving completely differently. For example, I had this vision readmission model, and it uses a patient feed which was giving it the economic data of the patient. And so we know that people who are low income patients, they have a higher risk of readmissions, and also if you’re not getting that feed, the model won’t be confident enough in making these predictions. It might go completely haywire. So scaling AI is a big challenge.\n",
      "We have a discipline called DevOps to address the way traditional software is handled in the enterprise. What we need is a DevOps equivalent for AI. We in the industry call it MLOps, or machine learning ops. It’s basically the discipline around practices to manage, deploy, and create these models in a structured way. One of the offerings in our product, AI Fabric, is an MLOps system for the data scientists, who might not really understand enterprise software deployment cycles. We simplify it for them. We say, “You just create a model, the rest of the stuff on the deployment, DevOps, MLOps side, we will take care of.” So deploying AI applications in the real world we have seen as a challenge.\n",
      "The third challenge, I would say, is the ROI quantification. The business owner needs to know the impact of putting the machine learning model into production. Is it hurting or improving the overall business? You need a system which can quantify the return on investment when you’re deploying AI. Typically, you would use BI tools for this. We are working on having an embedded analytics or BI offering, to give customers this ROI visibility. You need that quantification system in place.\n",
      "What does the future hold for your company and for AI in business? Where is it going?\n",
      "Mehra of AntWorks: John, we’re super excited. I’m speaking to you today from a delivery center in Bengal. I’ve just spent the whole day sitting next to my developers, talking to my product leads and the head of my product, and it’s just super exciting. It scares me when I look at possibilities that are in store for us over the next six, 12, and 24 months, and just what machines can do if trained correctly or if deployed correctly. I’m super excited about the next two years also. We’ve grown more than 350% in the last quarter and a half.\n",
      "I did a Town Hall [in India] this afternoon and the last time I was here a quarter ago, I had, I think, 40 people. Today I addressed 165 people. I’m hiring people to support customer demand.  So, there is a huge amount of potential and growth. Over the next 12-24 months, we are looking at dramatic growth. Automation and AI are in the top three agenda items of every Fortune 500 board today. We are addressing that challenge for those organizations.\n",
      "While there is a huge opportunity, all the organizations in this space need to be responsible to not over commit and under deliver, because that will start taking away the belief in what AI machine learning and automation can do.\n",
      "Singh of UiPath: I’ll be honest with you, where we stand right now as a company, as an industry, I see a whole tsunami coming our way. It’s not a bad tsunami; it’s a good one. Right now, most of these enterprises, they’ve just gone through digital transformation. They’re putting all these new-fangled systems in place. You have Salesforce for your sales system. You have Microsoft office. You have different cloud applications that you put in production. I can name you many companies, for example oil companies, they have completely digitized processes now, for even things like drilling reports. CPG [consumer packaged goods] companies who have digital processes for designing the labels that go on to their products. They also have inventory management systems and logistics management systems.\n",
      "They’ve just put these systems in place. The next thing, or the next ROI that they want to get out of the digital transformation, is to try machine learning and some automation. They want to try putting AI in some of these processes, to inject some automation and AI, to see if they can make them more efficient. I would say in the post-digital transformation era, the future for RPA and AI looks really great. These will be the technologies that are at the cutting edge of this post-digital transformation age.\n",
      "Learn more at AntWorks and at UiPath.\n",
      "By AI Trends Staff\n",
      "Advanced safety systems using AI are being delivered in cars today, whether the customer asks for them or not. This is big business, with the value of AI in automotive manufacturing and cloud services projected to exceed $10.7 billion by 2024.\n",
      "Reaction to the new systems from the auto consumer public is mostly positive based on reactions seen so far.\n",
      "When a deer jumped in front of a 2017 Subaru Outback being driven in Skokie, Ill, recently, the vehicle came to a complete stop on its own, before the driver could react, according to an account in Consumer Reports, based on a survey of Advanced Driver Assistance Systems (ADAS). “Without the car’s automatic emergency braking system, I’d have hit the deer, no question about it,” the driver said.\n",
      "Consumer Reports readers were asked about their experiences with ADAS in their vehicles, including forward collision warning (FCW), automatic emergency braking (AEB) and blind spot warning (BSW). Some 57% of respondents reported at least one ADAS feature had prevented them from getting into a crash. The respondents provided data on some 72,000 vehicles.\n",
      "ADAS systems have increased substantially in the last 10 years in cars sold in the US, starting with FCW and AEB, then extending to BSW, lane departure warning (LDW), lane keeping assist (LKA) and more recently, pedestrian detection systems (PDS).\n",
      "Jake Fisher, senior director of auto testing for Consumer Reports, was quoted as saying, “Our survey results show that in the real world, these systems are creating positive outcomes in situations that only a few short years ago would have ended in costly and tragic results.”\n",
      "Manufacturers vary on the ADAS features included in new cars, whether they charge extra for them or supply them as standard equipment.\n",
      "Survey respondents had the highest satisfaction with AEB, adaptive cruise control (ACC), and BSW. Respondents were least satisfied with lane-keeping features, owing to “annoying” alert chimes, vibrations, or aggressive steering corrections. The dissatisfaction led owners to disable those features more frequently than others.\n",
      "BSW was the feature that drivers credited with most often keeping them out of a crash; 60% said BSW had prevented a collision.\n",
      "General Motors Research with U of Michigan\n",
      "General Motors conducted research on ADAS features with the University of Michigan Transportation Research Institute, that showed several of the features are helping to reduce car crashes in a statistically significant way, according to an account in Green Car Congress.\n",
      "The study included 3.7 million GM vehicles across 20 different models from 2013 to 2017. Some 15 different ADAS systems were evaluated using police report crash databases from 10 states.\n",
      "Among the findings:\n",
      "\n",
      "Automatic Emergency Braking (or Forward Automatic Braking) with Forward Collision Alert reduced rear-end striking crashes by 46%.\n",
      "Lane Keep Assist with Lane Departure Warning reduced lane departure-related crashes by 20%.\n",
      "Lane Change Alert with Side Blind Zone Alert reduced lane change crashes by 26%.\n",
      "Rear Vision Camera alone, Rear Park Assist functionality, Rear Cross Traffic Alert (which nearly always includes the two previous backing features) and Reverse Automatic Braking (which includes all the previous backing features) produced, respectively, an estimated 21%, 38%, 52%, and an 81% reduction in backing crashes.\n",
      "IntelliBeam and High-Intensity Discharge headlight features provided 35% and 21% reductions, respectively, in nighttime pedestrian/bicyclist/animal crashes, with a 49% reduction when offered together.\n",
      "\n",
      "“The results show that the GM active safety systems evaluated are addressing a wide range of common crashes that cause a staggering amount of injuries, property damage and cost to our customers and society, putting GM well on its way toward a vision of zero crashes,” said Raymond Kiefer, GM Safety Technical Fellow.\n",
      "Predictive Maintenance, Driver Recognition Coming\n",
      "Related benefits to drivers from AI plugging into the auto world include better ability to do predictive maintenance. Volkswagen and Microsoft announced in October 2018 a partnership to tap the power of Azure IoT, PowerBI and Skype to gather data that could indicate a pending component failure, long before the failure actually happens, according to an account on a blog from Ignite, an automotive and AI service provider. Plans are for all vehicles to receive Over the Air (OTA) software updates as well.\n",
      "Driver recognition systems are also making headway. An Israeli automotive computer vision startup, eyeSight, uses AI and deep learning in cameras and sensors that monitor driver behavior. This includes observations of eye gaze, eye openness, and head position. The system can alert the driver to keep eyes on the road, and attempt to wake up the driver if necessary. Contextual controls allow eyeSight to tailor the content of a Heads-Up-Display according to where the driver’s eyes are focused. Upper body detection reflects the driver’s posture.\n",
      "Read the source accounts in Consumer Reports, Green Car Congress and at  Ignite.\n",
      "By Benjamin Ross, Editor, AI Trends\n",
      "The US National Institutes of Health (NIH)’s Office of Portfolio Analysis (OPA) has developed a machine learning model that predicts whether a scientific advance is likely to translate to the clinic. The model, described in a recent study published in PLOS Biology (DOI:https://doi.org/10.1371/journal.pbio.3000416), determines the likelihood that a research article will be cited by a future clinical trial or guideline, which OPA labels as early indicators of translational progress.\n",
      "Developed by OPA Director George Santangelo and colleagues, the model qualifies predictions using a novel metric called “Approximate Potential to Translate” (APT). “We found that distinct knowledge flow trajectories are linked to papers that either succeed or fail to influence clinical research,” the study’s authors write. “Translational progress in biomedicine can therefore be assessed and predicted… based on information conveyed by the scientific community’s early reaction to a paper.”\n",
      "The development of APT values comes as the NIH launches the second version of its iCite tool, a web application that provides a panel of bibliometric information for journal publications within a defined analysis group. The APT values will be freely and publicly available as new components of iCite.\n",
      "Clinical research is a long, arduous process, the authors say, possibly taking decades for a discovery to translate into improvements in human health. This presents challenges when assessing and guiding the translation of the bench-to-bedside process.\n",
      "Santangelo tells AI Trends that machine learning presented an opportunity to get a better read on the likelihood that papers would move into the clinic.\n",
      "“The work started to develop in terms of seeing if we could find a method that would give us an earlier read on what to expect from different parts of the biomedical research landscape in terms of citation by clinical trials or guidelines as evidence that things were moving into the clinic.”\n",
      "As the team began to apply their APT values to existing data, Santangelo says nuanced patterns began to emerge as key predictors for translational progress.\n",
      "“I think the most important one that we focus on is the diversity of interest from across the fundamental to clinical research axis,” he says. “When people across that axis — from fundamental scientists often in the same field as the work that’s being published, all the way to people in the clinic — show an interest in the form of citations in those papers, then the likelihood of eventual citation by a clinical trial or guideline is quite high.”\n",
      "These indicators have proven to be effective, Santangelo and his colleagues argue, writing that “as little as 2 years [post publication] data yield accurate predictions about a paper’s eventual citation by a clinical article.”\n",
      "“We can now get a sense of what’s happening in the literature without as dramatic a censoring effect [a condition in which the value of a measurement is only partially known], which allows us to be more forward looking in understanding what areas of research are more likely to draw interest from clinically-focused scientists,” Santangelo says.\n",
      "Breaking Down The Paywall\n",
      "In addition to APT values, the iCite webtool will offer the NIH’s Open Citation Collection (NIH-OCC), a free public access database for biomedical research. The database currently comprises over 420 million citation links, with additional citations accumulating monthly.\n",
      "Santangelo says the database offers a solution to proprietary, restrictive, and often costly licensing agreements that have been a barrier to collaborative research.\n",
      "“These days there really isn’t a good justification for keeping [this data] behind a paywall, especially with the issues of data quality,” says Santangelo. “We recognized early on that, if we were publishing something, we were using a proprietary source for the raw data, and that others would not be able to calculate the values without working with us on a subset of the data. That never sat easy with us.”\n",
      "The NIH-OCC offers researchers the chance to access the raw data. “There’s no better check on data quality than that,” Santangelo says.\n",
      "In a Community Page article in PLOS Biology (DOI:https://doi.org/10.1371/journal.pbio.3000385), Santangelo and his co-authors say the NIH-OCC dataset has been generated from unrestricted data sources such as MedLine, PubMed Central, and CrossRef, as well as “data from a machine learning pipeline that identifies, extracts, resolves, and disambiguates authors in references from full-text articles available on the internet.”\n",
      "Santangelo says there’s a standing invitation for data sharing. “We’re data sponges,” he says. “We’ll take data from wherever we can find it.”\n",
      "Learn more at Office of Portfolio Analysis.\n",
      "By Lance Eliot, the AI Trends Insider\n",
      "Is he a man or a machine?\n",
      "That was asked about Francesco Molinari when he won the 2018 Open Golf Championship and earned himself nearly $2 million in prize money.\n",
      "It was his first major golf victory and it was the first time that the now 147th annual golf tournament was won by an Italian (there was a lot of celebrating in Italy!).\n",
      "How did he achieve the win?\n",
      "You could say that it was years upon years of other golf competitions and smaller wins that led to this big win.\n",
      "Or, you could say it was maybe the weather conditions and the mood and skills of the other golfers at the tournament that converged to let him be the best on that particular occasion.\n",
      "Presumably, you could say it was random chance, or maybe that he had a lucky charm.\n",
      "Would you be willing to say it was due to practice?\n",
      "As they famous joke goes, how do you get to Carnegie Hall – via practice, practice, practice.\n",
      "Francesco is known for being a slave to practicing.\n",
      "Of course, the odds are that many of the other golfers there had put in as many hours practicing as he has. It stands to reason that golfers at that level of play are practicing all of the time, day and night. They likely dream about golf. They likely are mentally playing golf when they eat lunch or dinner. It’s an all-consuming passion for most of them.\n",
      "If they are all practicing about the same amount of the time, perhaps the nature of how they practice might account for some of the differences in their playing levels. Just because I say that I practice, it doesn’t indicate in what manner I practice. For almost any kind of practices, you can take a varied approach to how you practice.\n",
      "I used to play tennis when I was in college. My practices often involved hitting tennis balls against a wall for hours on end. When I could find someone to play against, I’d certainly do a practice game, but at other times it was solo practicing that took place. Is the potential outcome of the solo practicing as good as doing actual practice games? You can debate the matter. The practice games are certainly more akin to what will occur when playing a match game, and so it seems logical that the practice game is a better form of practice. On the other hand, the repetition of hitting hundreds of times back-and-forth against a wall does build-up your arm and body in a manner that a practice game cannot.\n",
      "Francesco realized about two years ago that he needed to do something to boost his golf game.\n",
      "He had been a professional golfer for more than a dozen years and had been an amateur champion before turning pro. But, he had not yet reached the top echelon of the winner’s circle of professional players. Would it take some kind of voodoo magic to push him to the top? Did he have to make changes to how he perceived golf and played golf.\n",
      "He opted to radically change his practice routines.\n",
      "He entered into the ugly zone.\n",
      "Introducing The Notion Of An Ugly Zone\n",
      "For those of you familiar with the Twilight Zone (the old TV series), I suppose the ugly zone sounds somewhat like it.\n",
      "There’s nothing especially odd about the ugly zone though. The concept is relatively straightforward.\n",
      "When practicing any kind of skill, you are to do so with a maximum amount of pressure, perhaps even more so than what you’ll experience during live competition play.\n",
      "The goal is to make practices as rough and tough as a real match.\n",
      "Maybe even more so.\n",
      "When I used to help coach my son’s Little League baseball team, we often had rather acrimonious debates among the coaches and assistant coaches about whether the practices should be easy or hard.\n",
      "There were some coaches that said we should be easy on the kids and provide a supportive environment for them to learn baseball and hone their skills. It was about fun. It was about falling in love with the sport. We knew in contrast that the actual games would be pressure cookers, so the practices would hopefully serve as a means to inspire them towards becoming proficient baseball players.\n",
      "If you’ve not been to a Little League baseball game, allow me to open your eyes. You’ve got the doting parents that want their kids to win no matter what it takes. Many hope that their child will someday become a big league player, getting the fat paychecks and the out sized fame.\n",
      "Some of the eager parents had a different but similarly high pressure perspective, namely they thought that winning was the key to life, and they didn’t care that it was a baseball game per se. Instead, it was that their child needed to discover that winning is good and losing is bad.\n",
      "It wasn’t so important that the child was able to swing a bat — what was really paramount was that you must win however you can achieve it – this includes maybe swinging a bat, or catching a fly ball, or tricking the opposing team, screaming at the other team, spitting on the other team, you name it (all’s fair in love and war, and baseball).\n",
      "Should the practices be like the games?\n",
      "Would it be better to have the boys experience the crazed high pressures of a real game during their practices, or would that distract them from the needed step-at-a-time of learning their craft?\n",
      "Maybe doing high pressure practices would make them emotionally upset and they would become disgruntled about playing the sport entirely. They’d also have no opportunity to try out new techniques. They’d be constantly under the gun, so to speak.\n",
      "You’ll find this next anecdote amusing (or, maybe serious!).\n",
      "One of the coaches suggested that we setup loudspeakers at practice that would blare out the sounds of a typical game audience, including a recorded cacophony of loudmouthed spectators yelling and screaming, doing so during the practices (side note, we opted to not do that). This would help re-create the setting of actual games, apparently.\n",
      "Anyway, there are some that philosophically believe that practices need to be conducted in a high pressure manner that aligns with the pressures encountered during competitive matches.\n",
      "Of course, maybe doing this with Little League kids is not the right audience. Perhaps we might say that this approach is more suitable to adults. Furthermore, adults that are already versed in their craft, rather than someone just starting out to gain a new skill.\n",
      "Well, I realize that some of you that believe in the ugly zone approach will maybe disagree with me and my list of carve out exceptions, and you’ll insist that the ugly zone is always applicable, regardless of age, skill level, etc.\n",
      "Fine, have it your way.\n",
      "Let’s agree to disagree, and continue on, thanks.\n",
      "Desirable Difficulty Is King\n",
      "Francesco shifted his practices two years prior to his incredible win into becoming near torture tests.\n",
      "His new coach embodied the ugly zone philosophy and emphasized that the frustration level had to be equal to a real game or possibly higher than a real game.\n",
      "The more annoyed that Francesco became with his coach, the more the coach knew he was doing something right in terms of making practices hard. Every practice golf shot was considered vital. No more of the traditional hitting golf balls with your clubs for mindless hours on end. Instead, all sorts of complicated shots and series of shots were devised for practices.\n",
      "There you are on the putting green, practicing. You are 8 feet away from the hole. You try to make the putt, but miss the hole. It’s practice, so you just shrug your shoulders, you try to figure out what went wrong, and you then casually setup to do the same shot again. Not so with the ugly zone. That 8-foot putt is for the golden trophy, every time. If you miss the hole, you are done for. You are a failure. You must take each and every putt with somber seriousness. If you happen to make the putt the first time, that’s not good enough. Do it again. Indeed, do it five times in a row, flawlessly.\n",
      "Some psychologists suggest that adding challenges to practices tends to boost the long-term impacts of the practices.\n",
      "It is often referred to as desirable difficulty.\n",
      "As mentioned earlier, you might perceive that this challenges factor should be for all of the practices and all of the time of the practices, or you might believe that it should be done in a more measured fashion, just for some of the practices and maybe for just some of the time of those practices.\n",
      "Let’s take a slightly different angle on this ugly zone notion.\n",
      "Suppose you had practices that never were in the ugly zone.\n",
      "So far, I’ve mentioned the belief by some that the practices should always and exclusively be in the ugly zone. The opposite tack perhaps would be to never use the ugly zone approach at all. I’ve seen this happen in some contexts.\n",
      "For example, I was helping a group of middle school students learn about robotics as they were getting ready for a robotics competition.\n",
      "A fellow mentor was purposely having them avoid encountering any problems while practicing writing code to program the robots for doing various tasks. I took him aside and gently pointed out that we ought to have the kids experience some issues or errors, so that they’d be ready during the live competition. He insisted that any kind of difficulty would mar their learning and rebuffed my suggestion. Sadly, things didn’t go very well for them during the live competition and they were baffled as to what to do when their robots faltered.\n",
      "So, I’d generally argue that you need some amount of ugly zone involved in practicing.\n",
      "I suppose that I’m the Goldilocks kind of practices person. It should be not too much ugly zone, and nor too little ugly zone. Just the right amount of ugly zone is the aim. And, crucially, having no ugly zone at all is likely an unfortunate and perhaps misguided omission that undermines the overall utility of the practices.\n",
      "The ugly zone proponents contend that you need to learn how to think and act under pressure.\n",
      "They say that if you are the type of person that gets butterflies in your stomach during live competitions, you need to hone your skills so that instead of expunging the butterflies that you instead learn to shape them so they fly in a formation. Use the pressure to overcome your fears. Use the pressure as a kind of high octane juice. That’s what the ugly zone is supposed to achieve.\n",
      "AI Autonomous Cars And Ugly Zones\n",
      "What does this have to do with AI self-driving driverless autonomous cars?\n",
      "At the Cybernetic AI Self-Driving Car Institute, we are developing AI software for self-driving cars. In addition, we make use of a wide variety of techniques and one of those that we advocate is the use of the ugly zone.\n",
      "Allow me to explain.\n",
      "Many of the auto makers and tech firms that are making AI self-driving cars are doing testing in these ways:\n",
      "\n",
      "Use of simulations\n",
      "Use of proving grounds\n",
      "Use on public roads\n",
      "\n",
      "For my article about the use of simulations for AI self-driving cars, see: https://aitrends.com/selfdrivingcars/simulations-self-driving-cars-machine-learning-without-fear/\n",
      "For my article about providing grounds for AI self-driving cars, see: https://aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/\n",
      "When an AI self-driving car is being “tested” on public roads, this means it is being done in a relatively uncontrolled environment and that presumably just about anything can happen.\n",
      "On the one hand, this is good because there might be that “unexpected” aspect that arises and for which it is then handy to see how well the AI can respond to the matter. On the other hand, you might go hundreds, thousands, or millions of miles using the AI self-driving car and not encounter these plausible rare occasions at all, thus, in that sense, the AI self-driving car will not be tested readily on such facets.\n",
      "There’s also the rather obvious but worth stating point that doing “testing” of AI self-driving cars while on public roads is something of a dicey proposition. If the AI is unable to appropriately respond to something that occurs, the public at large could be endangered. Suppose a man on a pogo stick suddenly appears in front of the AI self-driving car and the AI does not know what to do, and perhaps hits and injures the man – that’s not good.\n",
      "See my article about the Uber crash incident that killed a pedestrian: https://aitrends.com/selfdrivingcars/initial-forensic-analysis/\n",
      "And, my follow-up article about the Uber crash: https://aitrends.com/selfdrivingcars/ntsb-releases-initial-report-on-fatal-uber-pedestrian-crash-dr-lance-eliot-seen-as-prescient/\n",
      "As I’ve mentioned many times, there are some AI developers that have an “egocentric” perspective about AI self-driving cars and seem to think that if someone does something “stupid” like pogoing in front of a self-driving car that they get what they deserve (this will doom the emergence AI self-driving cars, I assure you).\n",
      "There is also some sense of false security by many of the auto makers and tech firms that having a human back-up driver during public roadway testing is a sure way of avoiding any adverse incidents. This is quite a myth or misunderstanding, and there is still a bona fide chance that even with a human back-up driver that things can go awry for an AI self-driving car.\n",
      "See my article about egocentric designers for AI self-driving cars: https://aitrends.com/selfdrivingcars/egocentric-design-and-ai-self-driving-cars/\n",
      "For my article about the dangers even with a human back-up driver, please see: https://aitrends.com/selfdrivingcars/human-back-up-drivers-for-ai-self-driving-cars/\n",
      "Another aspect of doing testing on public roadways is that it might be difficult to reproduce the instance of what happened. I mention this because trying to do Machine Learning (ML) via only one example of something is quite difficult to do. It would be handy to be able to undertake the situation a multitude of times in order to try and arrive at a “best” or at least better way to respond. I’ve stated in my industry speeches that we’re suffering from a kind of irreproducibility in the AI self-driving car realm and for which inhibits or staggers potential progress.\n",
      "For more about irreproducibility, see my article: https://aitrends.com/selfdrivingcars/irreproducibility-and-ai-self-driving-cars/\n",
      "For my overall framework about AI self-driving cars, see: https://aitrends.com/selfdrivingcars/framework-ai-self-driving-driverless-cars-big-picture/\n",
      "As perhaps is evident, doing testing on public roadways has some disadvantages.\n",
      "That’s why it is vital to also do testing via the other means possible, including using simulations and using proving grounds.\n",
      "For simulations, you can presumably run the AI through zillions of scenarios. There’s almost no limit to what you could try to test. The main constraint would be the computational cycles needed. Some auto makers and tech firms are even using supercomputers for their simulations, similar to how such high-powered computing is being used to gauge the impacts of climate change or other large-scale problems.\n",
      "Not everyone though necessarily believes that the simulations are true to the real-world and thus the question is posed whether the AI reacting in a simulated environment is actually the same as it will react while on the roadways. If you are simulating climate change and your simulation is a bit off-base by estimates being made, this is likely Okay. But, if you are dealing with AI self-driving cars, which are multi-ton beasts that can produce instantaneous life-or-death consequences, a simulation that isn’t true to the real-world does not give one a full sense of confidence in the results.\n",
      "In essence, if I told you that I had an AI self-driving car that has successfully passed a simulation of over one-hundred million miles of car driving, albeit only in a computer-based simulation, and never been on an actual road, would you be happy to see it now placed into public use, or unhappy, or disturbed, or what?\n",
      "I think it’s fair to say that you’d be concerned.\n",
      "There’s also the potential use of proving grounds.\n",
      "See my article about proving grounds and self-driving cars: https://www.aitrends.com/selfdrivingcars/proving-grounds-ai-self-driving-cars/\n",
      "This is usually private land or sometimes government land that is set aside for the purposes of testing AI self-driving cars.\n",
      "You could say that in some ways it is better than simulations because it has a real-world aspect to it.\n",
      "You could also say that this is safer than being on the public roadways since it is in an area that avoids potential harm to the general public.\n",
      "I recently had a chance to closely explore a well-known proving ground, namely the American Center for Mobility (ACM) in Michigan, and spoke with the CEO and President, Michael Noblett, along with getting a specially guided tour of the facility by Angela Flood, Executive Director.\n",
      "The ACM consists of over 500-acres, offering multiple test environments adjacent to the Willow Run Airport. There is about 2.5 miles of an extensive driving loop that contains high-speed usable highway roads and two tri-level overpasses. It is an impressive facility and available for commercial purposes, governmental purposes, and usable too by standards bodies and colleges.\n",
      "For more info about the ACM, see: https://www.acmwillowrun.org/learn-about-the-facility/\n",
      "Creating Ugly Zones In All Modes\n",
      "Generally, it seems apparent that you’d want to use a combination of simulations, proving grounds, and public roadways for developing and testing of your AI self-driving car.\n",
      "Each approach has its own merits, and each approach has its own drawbacks.\n",
      "In combination, you can aim to get more kinds of testing that will hopefully lead to sounder AI self-driving cars.\n",
      "Let’s now revisit the ugly zone.\n",
      "For real-world driving of an AI self-driving car, as mentioned earlier, the AI might go for many miles without ever encountering some really difficult driving situations. Any such instances would presumably occur by happenstance, if at all. With a providing ground, you can possibly setup the AI for having to cope with quite ugly situations. Same goes for the use of simulations.\n",
      "Regrettably, there are some auto makers and tech firms that are not pushing their AI to the limits via the use of the proving grounds and nor the simulations. They seem to believe that the focus should be the “normal” conditions of driving.\n",
      "For example, at a proving ground, the AI self-driving car is driving on a road and all of a sudden a woman pushing a baby stroller carriage starts to walk across the street (this might be a stunt woman hired for this purpose, and the baby stroller is empty other than a fake doll). The AI self-driving car detects the motions and objects involved, i.e., the adult female and the stroller, and deftly swerves to avoid them. AI saves the day! Case closed, the AI is prepared for such a scenario.\n",
      "This seems convincing as a test.\n",
      "You might mark-off on your checklist and claim that the AI can detect a person with a baby stroller and take the right kind of action to avoid a calamity.\n",
      "There are though additional considerations.\n",
      "How many other cars were on the road with the AI self-driving car?\n",
      "In this case, none.\n",
      "Was there a car directly next to the AI self-driving car that would have been potentially in the way of the swerving action?\n",
      "Not in this case.\n",
      "Were there other pedestrians also trying to cross the street at the same time as the woman and the stroller?\n",
      "No, just the woman and the stroller.\n",
      "Were there any road signs warning about an upcoming hazard or perhaps any orange cones in the road due to roadway repairs being made? No.\n",
      "And so on.\n",
      "I think we would all feel a bit more confident in the testing of avoiding the woman with the baby stroller if we believed it was done in a more high-pressure situation.\n",
      "Imagine if the AI self-driving car had other cars all around it, boxing it in, and meanwhile there were lots of other pedestrians near to or approaching the self-driving car, and the road itself was a mess, and a lot of things were happening all at once. That’s more telling about what the AI can cope with.\n",
      "Having a simplified, stripped down situation with an otherwise barren road, and just the woman and the stroller, does not seem like much of a test per se.\n",
      "It’s not anything close to being an ugly zone.\n",
      "Don’t misunderstand my point. I’m fine with the stripped down test as one such test.\n",
      "But, if that’s going to be the nature of the testing that’s taking place, it would seem like there’s no provision for the ugly zone.\n",
      "Recall that I earlier mentioned that having a practice without any kind of ugly zone would seem to be a practice that has a substantial omission and we ought to question the validity of the practice overall.\n",
      "For AI self-driving cars, we should definitely have ugly zone testing (or, if you prefer, we can say “practices” rather than “testing”).\n",
      "Should you use only and always ugly zones?\n",
      "Well, as I mentioned previously, I’m an advocate for a measured amount of practice time for sometimes having ugly zones and sometimes not.\n",
      "My Goldilocks viewpoint is to have a combination of times with and without the ugly zones. But, however you allocate the time, there must be some amount of ugly zone practice.\n",
      "Avoidance of using an ugly zone approach in undertaking practices for AI self-driving cars is a scary and understated form of practice and will pretty much “guarantee” the failure of AI self-driving cars in the real-world.\n",
      "Per my framework, these are the key AI self-driving car driving tasks:\n",
      "\n",
      "Sensor data collection and interpretation\n",
      "Sensor fusion\n",
      "Virtual world model updating\n",
      "AI action planning\n",
      "Cars control commands issuance\n",
      "\n",
      "The ugly zone is a means to see how well each of those AI elements are able to perform. Furthermore, you want to see how well they each individually work as a semi-independent component, along with how they work in concert together to drive the self-driving car. Therefore, the ugly zone needs to have a varied and myriad of aspects that will put “pressure” on each of the components.\n",
      "You might wonder how you can “pressure” an AI system, since it’s not like a human wherein you can pressure a human to get into a tizzy by throwing all sorts of things at them at once. Actually, in some ways, you can indeed pressure the AI system by doing likewise of what you’d do to a human, namely, pile-on as many things as you can, and see what the AI does. The internal timing of the AI system needs to be taxed to see that it can handle a multitude of simultaneous things happening on the roadway at the same time and in the same place.\n",
      "For my article about the cognition timing of real-time AI systems, please see: https://aitrends.com/selfdrivingcars/cognitive-timing-for-ai-self-driving-cars/\n",
      "Conclusion \n",
      "We believe in the ugly zone approach for AI self-driving cars.\n",
      "Let’s create as tough an environment as feasible so that once the AI self-driving car is on the public roadways, it’s a piece of cake.\n",
      "True stress testing should be done in all means feasible and not wait until the AI self-driving car is in a public place and for which public harm can occur.\n",
      "Whether you want to put your own children into an ugly zone for their piano practices or for their art lessons, that’s up to you.\n",
      "I think we can all agree that we’d believe more so in the potential of AI self-driving cars to be trustworthy on our streets if we knew that they had survived, learned from, and were adept at dealing with ugly zones.\n",
      "Go, ugly zones, go.\n",
      "Copyright 2019 Dr. Lance Eliot \n",
      "This content is originally posted on AI Trends.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for entry2 in ai_trends.entries:\n",
    "    for content in entry2.content:\n",
    "        soup = BeautifulSoup(content.value, 'html.parser')\n",
    "        print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whale Science 🐋I did a quick estimation to figure out what kind of investment you’d need to be able to move the Bitcoin market in the short term, in a particular direction.I looked at Gdax trading data which handled about 2.98% of all BTC trading volume on February 26th, 2018.Source: Coinmarkercap.comOn February 26, between 11: 54 PM PST and 11:55 PM PST, the total volume traded on Gdax was 65 Bitcoins which was worth around $686,440 USD at the time. This resulted in a .557% increase in the price of Bitcoin.I picked this particular minute for my example because it had visibly higher trading volume compared to the minutes before it.(See image below).We can now estimate that the total volume of Bitcoins traded in ALL markets during that 1-minute was about 2181 Bitcoins (~23 million USD worth) from the fact 65 Bitcoins traded on Gdax represented 2.98% of all Bitcoin trade volume in the world.The actual total volume should be lower since it is unlikely that all markets are completely efficient and received the same magnitude of above average volume like Gdax did during that 1-minute in question — But we will continue with this estimation for simplicity.Data Source: Gdax.comThis means that during that 1-minute, $23 million USD worth of bullish trades increased total market value of Bitcoin by over $1 billion USD (.557% of $180.77 billion total value of all Bitcoins)Crudely put — It is possible for someone with access to $23 million USD to pump the price up by .557% in one minute.What About Ethereum?I did the same calculation for Ethereum for that exact same minute — between 11: 54 PM PST and 11:55 PM PST on February 26th, 2018.Total volume traded on Gdax during that one minute was 120 ETH and resulted in a .41% increase in the price of Ethereum.Gdax represented 2.97% of all ETH trades which puts the total estimated trade volume during that minute at 4040 ETH which was worth around $3.57 million USD at the time.Data Source: Gdax.comTherefore, we can estimate that a $3.57 million USD worth of bullish trades in Ethereum resulted in an increase of $363 million to the total market value of all ETH(.42% of $86.44 billion USD, total market value of Ethereum)WHAT DOES IT ALL MEAN?A lot more extensive analysis is required before any conclusion can be drawn from this. In future, I’d like to look at different time cycles besides one minute and include a lot more data than just the one minute I picked on a random day to do my calculations. However, this simplified calculation does give us some idea about the sensitivity of the market.It would also be interesting to look at how this “whale-effect” has changed over time.I assume it was much cheaper to move the market when Bitcoin had a substantially smaller number of hodlers. I also do not doubt that it will get progressively more and more expensive to be able to move price.This may sound counter-intuitive but Bitcoin needs a lot more whales and deep pockets. It is relatively easier and cheaper for a whale to influence the market if there are not enough other big players. But with a lot of whales in the market, a single whale no longer has the same influence. For reference: There are 2,043 billionaires worldwide (Forbes) and 35 million millionaires worldwide (Credit Suisse)This is not meant to be a financial advice. Please invest responsibly.Note:Glad you stopped by. When I’m not staring at crypto prices, I am usually working on my AI/ML startup Archie.AI — The Artificially Intelligent Data Scientist. Do check it out if you’re interested in that sort of thing.How Much Money Do You Need to Move the Bitcoin Market? was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "It’s about connecting with the fans, not creeping them outTo me, small, personal projects are always opportunities. Opportunities to learn, to be creative, and to be heard.During the past five years, I’ve run and managed nearly a dozen web projects, with traffic ranging from tens to tens of thousands visitors each day. Naturally, larger websites have more at stake. They demand round-the-clock monitoring and weekly analysis. But analytics play a huge role in small, personal projects, too.With less-frequently visited properties it’s a lot harder to derive statistically-significant conclusions. Data is noisy and takes a long time to collect. Acting on that data is also difficult. But this knowledge is valuable for understanding the people who take the time to watch, read, and react to your creative expressions.A few years ago I was very much into making music. I performed live and distributed records online. Being an introvert I eventually gravitated towards hiding with my guitar in the bedroom and creating sounds in private. Still, I loved being on the stage, as there is no better way to be with people who happen to like you and/or your work.Never the less, my public appearances have receded over time. Most of my creative work is now online (as a film photography publication and a community blogging platform). The people who happen to like it and consume regularly only manifest themselves as tiny spikes on the traffic curve reported by Google Analytics. Knowing this little about the audience creates a significant interaction void.As there wasn’t much that I could do with my analytics I switched to Archie Email Reporting product for casual weekly digests. Interestingly, a few months in I began to understand my audience a little better, or, at least, it felt like I did. I knew whether my work is getting more or less popular, where the visitors came from, whether the people are interacting with my content, and what pages, according to the bot, deserve my attention. All without having to obsess about the data via analytics dashboard.My resulting understanding of the audience isn’t very scientific. But a rough overview of the crowd does draw a decent picture on seasonal and hourly popularity (like the busy months, or, what time of the day do people visit my site most often). Going beyond this kind of knowledge requires more traffic to come up with statistically significant answers. But the real advantage of being small is to be able to talk to people on a personal level and spend less time data mining (while still keeping track).Large businesses are spending a lot of money on advanced intelligence, which today is backfiring with harsher compliance requirements (like GDPR) and overall public mistrust. At the same time, small ventures have an advantage in the ability to use analytics reports as a rough gauge of performance and to focus on interacting with fans and customers, something we can do without having to scale.On Twitter, I regularly engage in conversations, many of which are taken as invaluable feedback or messages of support. I spend my time at the places of gathering for the likeminded individuals, like film development labs and exhibition galleries. All of which have a much greater impact on the success of my small venture, defined by the size of the audience and their ability to appreciate my efforts.To get to this balance between guestimation and science, automation and personal approach I had to try a lot of different techniques. In the end, for any website that receives less than 5K unique visitors per month this method is perhaps the best. No excessive tracking or obsessive analysis. Instead, a healthy presence online (outside of the publishing platform) and a strong reliance on physical/real-world connections.With the casual data approach, I get to have meaningful, guided interactions with the community without having to spend time serving and dissecting non-existent crowds.Originally published at www.archie.ai.Why Data is Important for Small, Personal Web Projects​ was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "A Better Naming and File Organization SystemThe curse and the gift of React.js is the fact that it is not opinionated in terms of how you structure your components and files. Do what you want and it’ll work. But with every new project it’s a “blank slate” problem.This article is written from a perspective of a person building (and finally refactoring) the front-end of a blogging platform designed for film photography enthusiasts. Besides listing and displaying articles, the app provides admin controls and a full rich text editorial suite, comprised of 280 files and folders. The app in question is Analog.Cafe.Preface 1: “dumb” and “smart” components: not a good way to sort your files.- app/  - components/  - containers/When I began working on my application, coming from an intensive year with Ruby on Rails builds for Archie.AI (a fairly opinionated framework) I’ve hit the wall trying to figure out how to structure and name the numerous files with React. The most common advice at the time was to segregate the components into pure functions and stateful components.The expectation with this method is that your components will inevitably get reused elsewhere. Although this may be true for many projects, I can’t see how it could be the case for all applications. Furthermore, ripping the functionality apart and placing the pieces of a component that performs the same function into separate corners of your filesystem is counter-productive and counter-intuitive.With some experementation I’ve come up with a better system (below).Preface 2: styled-components, they aren’t CSS; they are components.​styled-components is my library of choice when it comes to baking CSS into React projects. It’s very good.A common pattern of usage with it is to separate styles into styles.js, a reminiscent of the file structure we used to have with simpler hand-written HTML files not too long ago.Turns out this is not a practically good idea. Namely, because this method creates a third type of component (in addition to above-mentioned smart and dumb). What’s worse, this type of component has a completely separate organizational method, which attempts to mimic conflicting paradigms.I recommend treating styled-components just as what they are — React components.The Interface Pattern.The Interface Pattern is a reminder that we are building a front-end application, which is easier to understand and structure when it’s thought of as a compilation of visual interface elements. This pattern consists of suggestions on file and folder structure, preferred export types, commenting practices, and file size recommendations.File and folder structure shape.- app/  - core/  - admin/  - user/  - constants.js  - index.js  - store.js  - utils.jsNote: you can browse the entire application structure for Analog.Cafe in this repo.My application is divided into three major sections: core/ admin/ and user/. In your case, you may not have any sections if the app isn’t big enough. Then you can structure your app/ folder just like the contents of the above sections (see below).The four JavaScript files above should be self-explanatory, but with a few caveats. In this example they serve as index files, where they store only the most basic and commonly-used exports: index.js contains the main wrapper React component for the app, store.js combines the reducers found inside the above three application sections and exports a Redux store, while utils.js and constants.js contain the most common JavaScripit function snippets and reusable constants.- core/  - components/  - constants/  - store/  - utils/Inside each of the application sections are four folders which resemble the shape of the app/ directory. The only difference is that this shape forces you to create more files in your utils/and constants/folders which is better for the organization and should make tree-shaking work better too.If you are not splitting your app into sections the above folders could be placed inside your app/ folder, instead of core/.- constants/  - messages-.js  - messages-article.js  - routes-article.js  - rules-submission.js- utils/  - actions-session.js  - messages-profile.jsBoth constants/and utils/ folders have similar file-naming patterns. The first keyword is either messages, routes, rules, or actions. Followed by a dash and a keyword describing a specific part of your application view. I understand that this is not the most foolproof naming convention, however, you may be able to understand it much better in practice. The main objectives should be consistency and clarity.Note the file named messages-.js which contains strings and objects designated as user-facing messages, not assigned to any specific part of the application view.- store/  - actions-article.js  - actions-submission.js  - reducers-article.js  - reducers-submission.jsThe store/ folder is for Redux. It contains pairs of files (actions- and reducers-) for each part of your application view. Simple; all in one place.- components/  - controls/  - icons/  - pages/  - routes/  - forms/  - vignettes/components/ folder: I found the above six types of components to be fairly inclusive way to organize an application. It’s required to have such sub-folders to quickly find what you are looking for and understand application structure. Otherwise you may be stuck with hundreds of folders in this part of your app. This is how I distinguish them:controls/ — Buttons & button arrays, modal boxes, links, nav bars, menus, etc.icons/ — Graphic elements made with React and meant to stay as part of an app, such as integral SVGs or CSSs.pages/ — Components that are meant to take over a whole or a meaningful part of a screen space.routes/ — This folder is specifically for React Router route components.forms/ — Input elements.vignettes/ — Smaller components that do not belong anywhere else.- controls/  - Card/    - index.js    - components/      - CardFigure.js      - CardHeader.jsEach of the component folders would have names written in CamelCase, with an optional index.js at their root, which would tie everything together. If necessary, components/ folder could be placed inside, which can contain styled-components or React.js components which would directly help compose the main component (in this case, Card/ component).Note 1: There is no distinction or rule here between “smart” and “dumb” components, but the “smart” components naturally tend to end up at the root of the main component in index.js — which you could use to your advantage.Note 2: There is nothing preventing you importing from files located in other application sections; a lot of the time it’s required and there’s nothing wrong with that. Feel free to require admin/ utils in your core/ components.Note 3: You may have noticed that sub-components do not have their own folders. That makes for easier readability and better folder structure. They could, of course, be placed in their own folders if they in-turn have their own sub-components, but that would be messy. Try to keep your file tree as flat as possible.Preferred export types.A simple rule is to prefer named exports like export const function Name ()=>{} in constants/ utils/ and store/ — this will encourage you to balance the number of files in those folders nicely.However, all components should strive to export only default exports with some exceptions where they could contain both default and named exports in very small files. This simple rule will force you to create more components (which are by the way a lot easier to name than more rigidly-structured constants and utils files), which in turn will create a number of benefits in terms of the final bundle size and app readability (fewer lines of code per file).File size recommendations.No more than 300 lines per file. Anything bigger than that warrants splitting it.Commenting practices.I used to think that more comments in the code is better. Until I learned otherwise. Plentiful comments could be useful when creating a tutorial, however, they tend to pollute application files and encourage bad variable naming practices. So if the code feels difficult to understand, it should be reviewed and corrected for a more comprehensible namings and style. Use tools like Prettier to your advantage.Write readable code instead of something that you needs a manual.It may seem like there’s a lot to deal with, but in practice, it could be easily achieved and understood by the whole team. Have a look at the repo that already uses this method to get yourself acquainted. Refer back to this text to get the details and the reasoning behind each choice.As you may have noticed I haven’t mentioned anything about where to place tests. This method also hasn’t been tried in a great diversity of production systems so there may be some things I missed or got wrong. In those cases, you may have to adapt, and if you got time please let me know so that I could make this guide better.🍻Originally published at www.archie.ai.Structuring React.js Web Applications​ was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "Please, feed your data to the machines.Artificial intelligence is taking the demand for data to a new level. 📈Let’s say you have access to 5,000 X-ray images of patients who were correctly diagnosed with a particular type of cancer — Type A.Today, it is surprisingly easy to use this data to train a bot to detect this cancer in new patients.To build this bot, you’d build an image classifier powered by a neural net and the 5,000 X-ray images would be your training data set.You’d add another 5,000 X-rays of patients without cancer so the classifier has examples of both healthy and affected X-rays.In essence, this image classifier bot would look for common patterns at pixel level using image gradients and correlate that pattern to Type-A cancer using a widely used machine learning algorithm called back-propagation.Note that YOU don’t have to specify the patterns at the pixel level to the bot for it to detect the cancer. That would be a highly inefficient process and possibly inaccurate as well.Instead, in our deep learning model, the bot looks for the patterns itself. It painstakingly evaluates small grids of pixels of an image with the cancer and compares it to the corresponding grid in ALL the other images to find the patterns that exist. For further reading, you can check out concepts like kernel convolutions or how bots are detecting various object in Kaggle competitions.If you want to dive deeper into the tech, you can read my essay “Learning at Scale & The End of ‘If-Then’ Logic”.The point is, using currently available open-source/SaaS deep learning platforms, a bit of motivation and access to the right data set, one could set this bot up in no time.Once trained, if you input a new patient’s X-ray, the classifier would be able to say things like “There’s a 98% chance that this is a Type A Cancer”.If you’ve been through a cancer diagnosis process of a loved one, you know how important it is to be certain. That’s why people get the second, the third and the fourth opinion from different doctors.Using this bot, every patient can be more confident about a diagnosis, a lot faster.The best part is that if you continue to add more X-ray images of correctly diagnosed Type A cancer, the bot will continue to get better at detecting it.As machine learning techniques become more mainstream, a lot more value will be placed on data because machines can learn from it to do our jobs better than us.Identifying cats or malignant cancer, it’s all the same for the bot as long as you have training data. Photo: Deep Learning visualized by mapr.comThis above use-case isn’t science fiction.At John Radcliffe Hospital, a team of researchers from Oxford University are using electrocardiogram images (Eco test) of the heart to detect heart diseases. The system is called Ultromics and it consistently performs better than human cardiologists. The team has access to Oxford University’s heart imaging database and they are training their machine learning algorithms with these images to detect various heart diseases.Google’s DeepMind is using a similar system to train an AI to detect eye disease by looking at thousands of retina scans at London’s Moorfields Eye Hospital.In a double blind study, IBM Watson for Oncology’s breast cancer treatment recommendations was 90% concordance with the recommendation of a tumor board consisting of multi-disciplinary doctors and practitioners. Here, the training data comes from medical records of past patients, medical journal and books.Needless to say, AI/ML use-cases are not limited to healthcare but they show us how valuable data is to solve real problems.Most organizations/businesses/governments are sitting on top of literal goldmines of data that could be made into powerful AI products.Unfortunately, not enough is being done. Not fast enough.Data is a source of great power. And with great power comes great responsibility.*So if you’ve got access to valuable data, you better be building something useful with it.Note:🤖If you’re interested in learning more about my work with AI/ML, check out my startup Archie.AI- The Artificially Intelligent Data Scientist.🤖If you’re interested in building machine learning models, check out our workshops on YouTube.🤖Want me to help you build your AI/ML project? Email me: i@eurekaking.comAdditional recommended essays on machine learning/artificial intelligence from team Archie.AI👉A Dozen Times Artificial Intelligence Startled The World.👉The Power of Natural Language Processing.👉Artificially Intelligent Engineers — How AI Will Kill All Engineering Jobs. And Why It Is a Good Thing.*Spiderman, David LaphamStop Sitting On All That Data & Do Something With It ⚙️ was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "Enhancing JavaScript bot UI with localStorageBot interfaces are fun for the users and advantageous for those who build them (if done right). The concept isn’t new, though today it’s especially powerful.An implementation of a JavaScript bot library with localStorage in-place to memorize previous interactions. Notice the greyed-out text. This screenshot is of a production release of Archie.AI Google Chrome app.For developers, bots mean less time spent designing and building custom interfaces. It’s just text bubbles; plus many existing platforms offer to completely avoid this process with their already-successful apps’ APIs (i.e. Google Assistant).For users, bots mean a possibility of hands-free interaction (via voice) and a more natural and/or seamless way to converse with machines.A simple solution.When I build things I tend to look for simple solutions, sans bloat, which could be easily understood and customized. Unfortunately, when I was looking for one last year there were none for my use case…My team and I have implemented and trained a natural language classification engine, Archie.AI, and gave it the power to understand and generate answers from Google Analytics. The bot can give daily briefings about users’ state of business, predict the number of future visitors and answer over 430 related questions. It’s an excellent way to save time when looking for a particular metric or an instant business advice.It works wonderfully with Google Assistant and Alexa, however, when the time came to get a fast, clean interface for the web, there were no good-enough options. So I built one and kept it open-source. chat-bubble is the one-kilobyte JavaScript file with no dependencies that’s really easy to implement and understand:var chatWindow = new Bubbles(  document.getElementById(\"chat\"),  \"chatWindow\");chatWindow.talk({  \"ice\": { \"says\" : [ \"Hello!\" ] }});// https://github.com/dmitrizzle/chat-bubble#demos--more-usage-examplesBatteries included: a complete set of CSS styles and percision-timed animations, an ability to safely run functions in response to user actions, and a pluggable processing engine.By “pluggable processing engine” I mean that the script is not going to tell you how to understand your user’s queries. It’s up to you to implement your own NLC. It’s up to you to either dynamically generate or write response scripts. However, it doesn’t leave you hanging. There are currently three ways to have it respond to your users:Give your users options, which appear as buttons (see gif below). Nothing needs to be done here, this is built-in.Use the provided sample code that utilizes a simple fuzzy-matching logic to map your users’ input to the options you prescribe (see gif below).Plug-in your own NLC engine (see gif above).Those options are for recognizing user input. The output (what the bot says) is just as customizable. It could be as simple as a structured JavaScript object variable. Or it could be dynamically imported JSON data. Of course, it doesn’t have to be just one huge JSON file — that would be inefficient! In our case (again, see gif above), we broke it up into individual answers for the responses that require a trip to the server (on-demand) and some calculations on our end.Bot library example with built-in button controls and input keyboard with fuzzy-match logic implemented. The JSON script that prescribes this conversation structure is below:// a simple conversation script written with JSONvar conversationScript = {  ice: {    says: [\"Hi\", \"Would you like banana or ice cream?\"],    reply: [      {        question: \"Banana\",        answer: \"banana\"      },      {        question: \"Ice Cream\",        answer: \"ice-cream\"      }    ]  },  banana: {    says: [\"🍌\"],    reply: [      {        question: \"Start Over\",        answer: \"ice\"      }    ]  },  \"ice-cream\": {    says: [\"🍦\"],    reply: [      {        question: \"Start Over\",        answer: \"ice\"      }    ]  }}Local memory.Over the next few months, we tested the script in production with about a thousand users, while adding a few tweaks and improving performance on older browsers. It has also been downloaded over 700 times as of today.The library works equally well on desktop and mobile. However, when it came time to publish it as a part of our Google Chrome browser extension user experience suffered. Because chat-bubble had no inherit persistence, the conversation history would evaporate every time the plugin window is closed. And that happened quite often as Chrome tends to kill the DOM of the plugins entirely each time the user shifts focus.That has to be fixed.There is no one way to keep the conversation history in on disk. I considered using Redux to manage the state, however, that’s a dependency and the philosophy so far is not to have one. That would also over-complicate things.Instead, I decided to store a modified JSON object that would share the same structure as the conversation script in localStorage. It would be recalled every time the bot is brought up, however, it would also need to:Have the potential to be used with a database or any other data storage method.Have different UI interactivity and style than the rest of the bot (a visual cue for the user).Be a progressive enhancement that doesn’t break the rest of the app.chat-bubble-interactions is the LS key for keeping in-touch with the chat history.Future-proofing.Keeping an option open for implementing a server-side storage solution is pretty straight-forward. The entire library is less than 340 lines of non-compressed, commented JavaScript. Shall anyone attempt to implement that, all that would need to be changed is JSON.parse(localStorage.getItem(interactionsLS)) method for accessing the history and localStorage.setItem(interactionsLS, JSON.stringify(interactionsHistory)) method for saving the history.The only roadblock I can see here is having to add a Promise -type checks to make sure that everything needed to display history is downloaded before proceeding. Something like this might take some work as there would need to be a few decisions made regarding when the download should start and what functions should it block. I’m leaving that for tomorrow.Custom UI for recalled conversations.Note the “greyed-out” style for this recollected conversation up top.To keep things simple, previous conversations would appear in the chat as soon as the user opens it.However, as a side-effect of that decision, those conversations would have to be styled differently to avoid confusing the user. Additionally, the user responses would need special attention when stored and recalled, since user responses can not have any interactivity associated with them.What I mean is that while highlighting chat bubbles in black and floating them right for user responses isn’t that hard there are implications when the chat uses buttons instead of keyboard input messages. Read on.Consider the example (below) when the user is presented with options to select one of the two or more buttons as a way of answering to the bot. Obviously storing answer options in history isn’t helpful — they have nothing to do with conversation structure after they’ve been interacted with. Only the user’s response (their selected answer bubble) is relevant. The trick is not storing anything in history until the user has created their final interaction.Note how the answer options no longer appear in the conversation history.For this purpose, I’ve created two functions for saving history: interactionsSave() and interactionsSaveCommit() — where the former would be called to mutate the proposed save object in RAM and the latter would commit that object to localStorage.interactionSave() would be called every time the bot produces a response, but only after the user has committed their answer. Because when the user clicks a bubble our script has already “forgotten” what that button looked like in terms of DOM structure, a new one would be made, specifically for committing to conversation history:// add re-generated user picks to the history stackif (_convo[key] !== undefined && content !== undefined) {  interactionsSave(    '<span class=\"bubble-button reply-pick\">' + content + \"</span>\",    \"reply reply-pick\"  )}interactionsSaveCommit() would be called every time a new speech bubble is created in DOM by the means of addBubble() function.Progressively enhancing.This is a relatively new feature that not everyone would want to use, of course. It is also experimental and could easily be overdone (should someone try to remember a 1,000 interactions the performance and user experience would drop every time the boat would load). So by default I left it off:recallInteractions = options.recallInteractions || 0Getting it to function is super simple though:var chatWindow = new Bubbles(  document.getElementById(\"chat\"),  \"chatWindow\",  { recallInteractions: 10 });…All that does is tells this interactionsSave() to toss unnecessary stuff away:if (interactionsHistory.length > recallInteractions)      interactionsHistory.shift()For simplicity’s sake, all work on chat-bubble is done without any kind of build steps. All JavaScript is written and ran immediately in-browser (even though developers who implement it are given an option to use ES6 Import method). Because the browsers read JavaScript from the hard-drive in develop mode, any attempt to use localStorage breaks the entire code base as it’s not allowed (due to security restrictions). Which made me think: this could happen quite often in other environments. So I’ve implemented a fallback with a warning:// local storage for recalling conversations upon restart  var localStorageCheck = function() {    var test = \"chat-bubble-storage-test\"    try {      localStorage.setItem(test, test)      localStorage.removeItem(test)      return true    } catch (error) {      console.error(        \"Your server does not allow storing data locally. Most likely it's because you've opened this page from your hard-drive. For testing, you can disable your browser's security or start a localhost environment.\"      )      return false    }  }  var localStorageAvailable = localStorageCheck() && recallInteractions > 0Now everything should still work even if the browser can not access disk memory.As of today, the updated script is available through NPM as chat-bubble@next. It is already performing on our Google Chrome extension and so far is able to save a lot of headache for the users, as well as dramatically reduce perceived loading time.All of the code described here is available on this GitHub repo.Storing & recalling bot interactions☝️🤖 was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "Entire trip lasted around four days, half of which I spent in the air. Three different planes carried me from Chiang Mai to Bangkok, then Taipei, then San Francisco. Three more did it again in reverse order.I crossed the Pacific twice for a ten-minute meeting.All the photos in this essay were taken with my fourty-year-old Yashica Electro 35 camera on Ilford Pan 100 film.A week prior, Ishtiaq called first thing in the morning with the news: Y Combinator invited us for an interview and all three co-founders had to be there.Y Combinator is the most respected startup accelerator program on the planet. They helped Air BnB, Dropbox and Reddit (amongst hundreds of others) get to the position they are at today. Their unique way of deciding whether we were worth their investment is paying for everyone’s return flights and accommodations to meet us for exactly ten minutes.Arjun flew from Dubai and I flew from Chiang Mai to meet Ish at our tiny San Francisco HQ.My part of the job at the company is managing technical resources, building, and fixing things from my home in Thailand. Last time I flew to SFO I was there for nine months before making it back.While in California, I was always busy. Surrounded by great people, though I often felt lonely, wishing I was back home with my girlfriend, Betty. This trip brought a lot of those memories back. Of course, the prospect of seeing Arjun and Ishtiaq, my very close friends and co-founders, as well as a shot at being a part of a Silicon Valley’s elite club was exhilarating. I felt as if I was being propelled to the heights of an emotional rollercoaster as I sat in the tail section of the plane, quaking from the turbulence.An edgy stewardess sat facing me directly across the emergency exit route. She didn’t seem to stay still for one minute during the entire flight. Perhaps it was her first year at the job.Border-crossing is everyone’s least favourite part of international travel. Even with a Canadian passport, arguably one of the best travel documents in the world, you could still get hassled.A long line of tired passengers snaked through the hall. I sent my messages out, checked my emails and waited for my turn. Shifting one foot in front of the other, as the crowd methodically inched through the three open booths.The invitation letter I presented to the officer seemed to have immediately put him in a good mood. He waved me in while sharing a joke with his co-worker. I drowsily stumbled across the hall, amused at the amount of grease a sheet of paper has added to the grinding process of being admitted to the USA.Little Hollywood.I took a short Uber ride with two other passengers before arriving at the house. Ish met me with a bear hug and we spent an hour catching up until Arjun, who flew in a little earlier, woke up and we got some dinner.The house.Ish and I, captured by Arjun.The house, our HQ, seemed unchanged since the last time I was there.It resided in San Franciso’s Little Hollywood — a fairly unknown neighbourhood that warranted a (relatively) affordable rent, a distant view of a park and close proximity to Caltrain station.We made the garage our office with an array of sticky notes, company posters, a whiteboard and large table space that hosted laptops, spare monitors and a few home automation speakers. A few of my photographs (mostly mountains and trees) were hanging on the walls, but the piano was gone.Arjun.Next morning I got to meet Bhargav and Chandra in-person. They were both responsible for developing new features for our product throughout the past few months, though I’ve only spoken to them on the phone until now. It was all business as we were in the rush to prepare for the interview.The interview.It took us about an hour in an old van to get to Mountain View. Our Uber driver did not seem to be in the rush; he drove at or below the speed limit the entire time. Which made me feel uneasy as I tend to speed whenever I’m on the road, though we had more than enough time.Y Combinator building is a refurbished mini-warehouse that’s been furnished with nicely-painted walls, chairs and sofas. A small plaque, no larger than a mailbox stood in front of it, identifying it as the place we wanted to be at.Met a few other founders in the parking lot. A horoscope app, a social tool for events, and women’s health cycle tracker. We stood in an awkward circle, wondering if we’d ever see each other again.There were seven or eight people in the interview room. Naturally, only a few of us spoke as the decisionmakers were trying to determine whether we were the right choice for them. We were asked just a handful of typical “investor” questions. Everything went by uncomfortably quick, leaving only a hazy recollection that felt like a hallucination.We took a train back and waited at the house. The rejection email arrived a few hours before my scheduled departure.Effectively nothing has changed for the trajectory of our business. There were over a thousand customers in our database that we had to satisfy and convert. A long list of products to be built, bugs to be fixed, and newly scheduled meetings to attend. Still, nobody likes to lose.I flew home looking forward to seeing Betty and all the comforts of sleeping in my own bed.This story has originally been published on Analog.Cafe — a film photography publication and features events around Archie.AI founding team:Read the full story at Analog.CafeArchie.AI: Google Analytics ChatbotReturn Flight was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "Happy Holidays!This is Dmitri, CTO and co-founder of Archie.AI.I would like to personally thank you for being our pioneering customer. With your support and feedback, we are able to help over a thousand businesses of various sizes understand and interact with data better. Below is a quick recap of what happened during the past twelve months.2017 was a huge! We launched six products, amongst hundreds of features, including:Email Bot — Cut through the clutter of Google Analytics with free, weekly email reports.Google Assistant Action — Talk to your Google Analytics with Google Assistant-enabled devices.Alexa Skill — Talk to you Google Analytics on Amazon Alexa-enabled devices.Chrome Extension — Talk to your Google Analytics with Google Chrome Extension.Funnels — Effortlessly compare conversion funnels using your existing Google Analytics account.Enterprise — AI/ML/Analytics Solution for your SME.Archie.AI user community has grown from five to 1,521 (as of this writing). The chart that you see below shows the speed at which Archie has attracted new converts to a better, faster and more natural way to understand data — by talking to it.Archi.AI founding team at the Google NYC headquarters. I’m in the middle, Arjun Mohan is on your left and Ishtiaq Rahman is on your right.None of this would be possible without your feedback and support. Thank you.Stay tuned for more awesome launches this coming year. Expect big things in January 2018!Best wishes,Dmitri TcherbadjiFounder/CTO ∙ Team Archie.AIThank you for an incredible year from team Archie.AI was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "Happy New Year Medium! 🎉I didn’t know I suck at so many different things before I started a company. 🚀Building a company requires you to get good at a lot of different things besides your domain expertise. You may be good at product/engineering but you also have to do other things like fundraising, hiring, marketing and taxes etc. As a result, you become self-aware of all the things you’re bad at.Exhibit A: I am really bad at PR. I’d send press releases to journalists with detailed product description, quotes, image resources and announcements about Archie.AI’s product releases and never hear back. We hit 500 customers, launched on Google Assistant, Alexa, Chrome Webstore, won startup contests, got huge computation grants from IBM and NVIDIA, raised a funding round — press didn’t even accidentally write about us.I just sucked at telling a compelling story to write about. But the PR failure pushed us to build our own audience the hard way.We started getting our message across directly to whoever would listen.We built our own audience through sharing real insights we learned and people started to listen.Here are 7 painfully obvious lessons I learned in 2017 while building Archie.AI, in no particular order.Gif by Lisa VertudachesDo not underestimate the power of your vulnerability. Sharing it is hard, but it is instantly relatable to EVERYONE. People like real shit, it’s beautifully simple.Empathy is the most useful skill for building any product. Second most useful skill is the ability to rely on Data to make decisions.People will never buy something they don’t understand. No matter how intricate your product or service is, a 10-year-old should be able to verbalize it in his/her own words.Humans have no issue paying for things that give them value. Your customers will look for a good deal, but if you can provide real value, people/market will reward you for your efforts.If you have real insights — only acquired by experiments and experience — people will listen. Your audience may be small today but it will grow if you have a real story to tell and you’re willing to put yourself out there in front of the world.“Done” is always, unequivocally better than “perfect”. Perfection should reside inside your head where all externalities can be ignored.7. Faking courage is the same as having real courage.Bran thought about it. ‘Can a man still be brave if he’s afraid?’‘That is the only time a man can be brave,’ his father told him.”7 painfully obvious lessons I learned in 2017 while building a startup. was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "A tool to effortlessly compare Google Analytics funnels by Archie.AITeam Archie.AI keep dropping hits. 🚀This time we’re back with a tool to help you use Google Analytics data to instantly create and compare conversion funnels side-by-side.Funnels by Archie.AI. Try it here: https://www.archie.ai/funnelsHere are some quick use-cases.Compare the performance of referrals from different sources.E.g. Facebook Referrals VS Google Referrals: Who’s converting more?Compare campaign performance with Funnels by Archie.AICompare the pages on your website to see what is working and what isn’tE.g: Compare two of your content pages to see which one ends up converting most of your conversions.Compare conversion performance over time.E.g. Compare conversion funnels before/after website redesigns to see if performance changed.Compare conversion performance over time with Funnels by Archie.AIRun A/B testing of 2 landing pages and compare effectivenessCompare conversion funnels across Device type, Browser type, locations and more.Compare conversion funnels across Device type, Browser type, locations and more.Following are the roles we built this tool for.You’re a Product Owner/Product Manager/Founder directly responsible for the performance of your business’s digital front.You’re part of a business that sells their product/services online through websites, web/mobile apps.You’re an engineer trying to find a better way (automated) to sift through data and report actionable analytics, anomalies and patterns to your team.You’re responsible for allocating how and where Digital Marketing dollars are spent.We’re offering 15 day trial period so you can play around with it 🎁 and let us know what you think.Try it out here: https://www.archie.ai/funnelsIntroducing Funnels By Archie.AI was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n",
      "How to set up weekly email reports from your GA account with traffic & conversion summary, predictions and insightsTL;DR: Here’s the link for an app that does it for you.I spend a lot of my time working with Google Analytics. I measure visitors of an e-commerce website that sells prints, a community blog, a Kickstarter page for when my campaign was live and multiple web properties owned by the start up I co-founded. It’s a real hassle to try and keep up with all that data, let alone making sense of it.I thought that my problem was unique to serial webmasters, however it turns out that making sense of Google Analytics can be a challenge, even for a casual blogger. Seeing the default graph of visitors over time doesn’t provide as much value as one might think. Real-time reporting surely is exciting, but not very insightful. A proper way to get an answer to “What should I do with my website next?” question can only be found by digging through numerous GA views, often importing the data into a spreadsheet and processing it further. Only then you may have some answers.Email reporting — spending less time digging through data.A friend once brought up email reporting as a possible solution. He owns a medium-sized blog where he posts reviews of vintage camera lenses and street photography advice. It turns out that Google Analytics provides email reports that could potentially cut down on the time spent digging through data on the daily basis.Perhaps I could do better if I concentrate on building content, code and design for my websites and let the data get to me, instead of seeking it out? At least that’s what I hoped the email reporting would do: give me the numbers every week or so. I’ve never found the constant stream of traffic reports that useful anyways.The dream: simple, usable email reporting.Google Analytics’ proprietary email reporting: not very simple, not very valuable.Everything sounded fantastic at the start. Google is an all-powerful tech giant that can whip out amazing software. I’ve got a decade’s worth of programming experience & industry know-how. This is just an email report — should be super-easy! Right?No. First of all, Google has been revamping its Analytics software for the past few years practically non-stop. Hence finding good instructions with correct screenshots on the web is a challenge. After some digging it became evident that I’d have to create a custom dashboard that can then be sent as a PDF attachment to my email at a frequency of my choosing. Making such dashboard is a lot of work, and if it isn’t properly designed to cater to my application, I’ll be getting misleading reports, every time. Which isn’t good.I have to say that PDF reports look great with the graphics and all, although I’d have to wait for them to download and open in a very mobile un-friendly way: zoom, scroll, zoom, scroll…Long story short, GA email reporting can be an incredibly powerful feature, but to set it up correctly you’d have to do a data requirements inventory on your web property and get it right. Which isn’t simple.An easier, better way to get Google Analytics email reports.Disclaimer: the product I’m about to recommend was built by my startup.The tool is called Archie.AI. It’s free and easy to set up, you can get it here: https://www.archie.ai/email-reporting-for-google-analyticsOne of the advantages of Google Analytics that becomes a drawback later on is the way it presents data. Always cut-dry facts, with zero opinions. Which is perfect if you have a data analyst on your payroll. That person would take those facts and let you know what she thinks it all means and what your next steps should be.My team and I have been working on an algorithm that could perform that very task: interpret and suggest, according to available data. The code that does that runs thousands of queries every day, answering questions like “Predict my next week’s traffic.” or “How do I increase my traffic?” This tool is part of a larger suite of medium to advanced Google Analytics AI enhancements: Archie.AI.After trying the email reporting tool that comes with Google Analytics and chatting with some of our clients we decided to use our natural language generation platform to create simple, curated email reports. The goal was to select about seven key metrics and generate insights with predictions and human-like advice. Then send it every seven days, just before the week’s start.Besides giving human-like opinions and advice on your data we made sure our tool does not require any work on your end, besides clicking “Log in with Google” and selecting the property you’d like to track. You can also add conversion tracking with dollar (or whatever your currency is) value to get some e-commerce or KPI reports — but that’s up to you.The setup process for Google Analytics email reporting with Archie.AI. Simple.After tapping those three buttons you would get your first report instantly and all consequent reports every Sunday night (EST). The emails are all text, but the key points are highlighted to get your attention and the entire thing consists of algorithmic interpretations that can help you drive your decisions much better than any fancy graph could.Although it’s a part of a larger suite of tools available with full Archie.AI membership we decided to make it 100% free, leaving the choice up to you on whether you want to upgrade or not.This is a fairly new product and we’re constantly looking for your feedback. If you’ve got some advice, criticism or ideas — please don’t hesitate to let us know. In any case, follow this link to try it out.🍻An easier way to get Google Analytics email reports was originally published in Archie.AI on Medium, where people are continuing the conversation by highlighting and responding to this story.\n"
     ]
    }
   ],
   "source": [
    "for entry2 in archie_ai.entries:\n",
    "    for content in entry2.content:\n",
    "        soup = BeautifulSoup(content.value, 'html.parser')\n",
    "        print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keith Boesky, former president of Tomb Raider publisher Eidos and a frequent adviser to game companies at Boesky & Co., has died from cancer. Read More\n",
      "Former Bungie CEO Harold Ryan showed everybody how to go big or go home earlier this month. He announced that his ProbablyMonsters is announcing it has raised $18.8 million for the company’s two triple-A game studios. Ryan is going to need a lot more money than that to pull off not one but two ambitious triple-A projects in an age when there are a…Read More\n",
      "I spoke with Drew Henry, senior vice president at Arm, about the growing IoT ecosystem's compute demands and the impact that could have on climate change.Read More\n",
      "Tilt Five announced two new tabletop AR game partners with Tabletopia and Monocle Society.Read More\n",
      "Paradox Interactive and Harebrained Schemes announced the Heavy Metal expansion for mech combat game Battletech will go live on November 21.Read More\n",
      "Age of Wonders: Planetfall's first expansion is Revelations, and it launches November 19 for PC, PlayStation 4, and Xbox One.Read More\n",
      "Blacklisted Chinese telecoms equipment giant Huawei is in early-stage talks with some U.S. telecoms companies about licensing its 5G network technology.Read More\n",
      "Join this VB Live event for a look at the predictions that came true, the hype that fizzled, and what's next for the AI, CX, and chatbot technology.Read More\n",
      "Fortnite is getting one of its most important upgrades ever. Epic is adding spatial audio to the battle royale shooter to give players more tactical info.Read More\n",
      "Sonic & Knuckles is what happens when you make the best out of a bad situation. The classic Genesis game is now 25 years old.Read More\n",
      "A group of Brown University researchers wants to bring hand tracking to smartphone augmented reality using off-the-shelf hardware and open source software.Read More\n",
      "Biparitsan group condemns Blizzard and Apple for making moves at the behest of the Chinese government in relation to Hong Kong.Read More\n",
      "Google is giving more hardware dedicated chips for on-device machine learning, but services like Google Assistant still rely on the cloud. Here's why.Read More\n",
      "The NVM Express specification for solid state drives arrived eight years ago. So where’s all the adoption? Western Digital's Eric Pike explores.Read More\n",
      "For workstations and servers, it's getting hard not to justify the relatively low price/premium for NVMe versus the older SATA.Read More\n",
      "There’s a pathway to 5G that promises much of the technology’s value on existing 4G LTE networks for those who make the right upgrades.Read More\n",
      "After a long demo, I got a chance to talk with Respawn about the fun and challenge of creating its own slice of Star Wars material.Read More\n",
      "Google parent company Alphabet's Wing today said that it's kicked off a drone delivery pilot in Virginia for select residents.Read More\n",
      "5G is about to make better use of GPUs than ever before, thanks to innovations that will enable multiple users to share cloud-based graphics hardware.Read More\n",
      "Live Caption and Recorder on the Pixel 4 and Pixel 4 XL show that Google wants to rule offline natural language processing.Read More\n",
      "Apple TV devices were designed to help users cut the cord from cable companies. Now an Apple TV app for Roku lets users cut the cord with Apple hardware.Read More\n",
      "Will Dean is known as the creator of Tough Mudder. Now, he has gone digital with Electronic Theatre -- immersive group gaming experiences in physical rooms.Read More\n",
      "Star Wars Jedi: Fallen Order is a potentailly excellent entry in the long history of the series. We played the first 3.5 hours. Listen to our thoughts.Read More\n",
      "Riot Games announced on its 10th anniversary that it created new games, films, and animated series in the hopes of overcoming The Innovator's Dilemma.Read More\n",
      "If you think your AI product is groundbreaking and delivers real-world results, you could be one of 14 companies on the main stage at Transform 2020.Read More\n",
      "Saber Interactive announces today that it's buying Bigmoon Entertainment, the makers of games such as Dakar 18, Demons Age, and Police Simulator: Patrol DutyRead More\n",
      "Taking lessons from the success of the Overwatch League, Activision has revamped the structure of its esports competition in the Call of Duty League.Read More\n",
      "There are four aspects that dictate AI technologies be ethically designed: the dilemma, the impact, adoption, and institutionalization.Read More\n"
     ]
    }
   ],
   "source": [
    "for entry2 in venture_beat.entries:\n",
    "    for content in entry2.content:\n",
    "        soup = BeautifulSoup(content.value, 'html.parser')\n",
    "        print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the text in the above `feedparser` collections seems to look really good with no processing after the fact. It looks like we're at the point that we can save this text off and start working on our NLP portion of the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Actually, now that I say that, I need to make this notebook available in my repository and convert this code into actual *usuable* code within my **ai_news_writer** application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
